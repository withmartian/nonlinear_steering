# Benchmark configuration\nmodel: unsloth/Llama-3.2-3B-Instruct\ntask: tones\nmethods: [k-steering, caa, dct]\n# Layers to benchmark (ints; negative allowed for from-end indexing)\nlayers: [-2, -1]\n# Activation classifier eval layer\neval_layer: -1\n# Choose by count or explicit labels\nnum_attributes: 1\n# target_labels: [casual, empathetic]\n# Evaluation sample cap\nmax_samples: 100\n# DCT-specific params\ndct:\n  offset: 4\n  num_samples: 8\n  num_factors: 128\n  max_seq_len: 48\n
