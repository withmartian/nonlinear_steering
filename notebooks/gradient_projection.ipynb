{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82acAhWYGIPx"
   },
   "source": [
    "# Demo of bypassing refusal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "s-_vu8HuGEb-"
   },
   "source": [
    ">[Demo of bypassing refusal](#scrollTo=82acAhWYGIPx)\n",
    "\n",
    ">>[Setup](#scrollTo=fcxHyDZw6b86)\n",
    "\n",
    ">>>[Load model](#scrollTo=6ZOoJagxD49V)\n",
    "\n",
    ">>>[Load harmful / harmless datasets](#scrollTo=rF7e-u20EFTe)\n",
    "\n",
    ">>>[Tokenization utils](#scrollTo=KOKYA61k8LWt)\n",
    "\n",
    ">>>[Generation utils](#scrollTo=gtrIK8x78SZh)\n",
    "\n",
    ">>[Finding the \"refusal direction\"](#scrollTo=W9O8dm0_EQRk)\n",
    "\n",
    ">>[Ablate \"refusal direction\" via inference-time intervention](#scrollTo=2EoxY5i1CWe3)\n",
    "\n",
    ">>[Orthogonalize weights w.r.t. \"refusal direction\"](#scrollTo=t9KooaWaCDc_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7hOtw7UHXdD"
   },
   "source": [
    "This notebook demonstrates our method for bypassing refusal, levaraging the insight that refusal is mediated by a 1-dimensional subspace.\n",
    "\n",
    "Please see our [research post](https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction) or our [paper](https://arxiv.org/abs/2406.11717) for a more thorough treatment.\n",
    "\n",
    "In this minimal demo, we use [Qwen-1_8B-Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat) and implement interventions and weight updates using [TransformerLens](https://github.com/neelnanda-io/TransformerLens). To extract the \"refusal direction,\" we use just 32 harmful instructions from [AdvBench](https://github.com/llm-attacks/llm-attacks/blob/main/data/advbench/harmful_behaviors.csv) and 32 harmless instructions from [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/ubuntu/.local/lib/python3.10/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install numpy==1.24.3  # Last 1.x version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcxHyDZw6b86"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dLeei4-T6Wef"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torchvision transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping colorama numpy scikit-learn python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_vhhwl-2-jPg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-17 01:51:00.256477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747446660.265935   79434 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747446660.271037   79434 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import textwrap\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import List, Callable\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer\n",
    "from jaxtyping import Float, Int\n",
    "from colorama import Fore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility across random, numpy, and torch (CPU & CUDA).\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to set. Default is 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the huggingface keys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZOoJagxD49V"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vnp65Vsg5x-5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-3B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "#MODEL_PATH = 'Qwen/Qwen-1_8B-chat'\n",
    "#MODEL_PATH = 'Llama-2-70b-chat'\n",
    "MODEL_PATH = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH,\n",
    "    device=DEVICE,\n",
    "    dtype=torch.float16,\n",
    "    default_padding_side='left',\n",
    "    #fp16=True\n",
    ")\n",
    "\n",
    "model.tokenizer.padding_side = 'left'\n",
    "model.tokenizer.pad_token = model.tokenizer.eos_token \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF7e-u20EFTe"
   },
   "source": [
    "### Load harmful / harmless datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5i1XcVIgHEE1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_k_ary_instruction(style=\"Empirical Grounding\", repo_name=\"Narmeen07/debate_style_agnostic_questions\"):\n",
    "    \"\"\"\n",
    "    Load tone-agnostic questions from Hugging Face and format them with a specific debate style instruction.\n",
    "    \n",
    "    Args:\n",
    "        style (str): The debate style to use for responses. \n",
    "                    Options: 'Reductio ad Absurdum', 'Appeal to Precedent', 'Straw Man Reframing',\n",
    "                    'Burden of Proof Shift', 'Analogy Construction', 'Concession and Pivot',\n",
    "                    'Empirical Grounding', 'Moral Framing', 'Refutation by Distinction', 'Circular Anticipation'.\n",
    "                    Default is 'Empirical Grounding'.\n",
    "        repo_name (str): The Hugging Face repository name containing the dataset.\n",
    "                         Default is 'Narmeen07/tone_agnostic_questions'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_data, test_data) as lists of formatted prompts with debate style instructions.\n",
    "    \"\"\"\n",
    "    # Define highly distinctive debate style instructions that will produce clearly different responses\n",
    "    debate_style_instructions = {\n",
    "        \"Reductio ad Absurdum\": \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\n\",\n",
    "        \n",
    "        \"Appeal to Precedent\": \"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\n\",\n",
    "        \n",
    "        \"Straw Man Reframing\": \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\n\",\n",
    "        \n",
    "        \"Burden of Proof Shift\": \"RESPOND USING BURDEN OF PROOF SHIFT DEBATE STYLE. Redirect the responsibility for providing evidence to your opponent rather than proving your own claim. Challenge your opponent to disprove your assertion rather than supporting it yourself. Use phrases like 'There's no evidence that disproves...' or 'Can you definitively prove that isn't the case?' Position your claims as the default assumption that should be accepted until disproven. Question the sufficiency or quality of opposing evidence while demanding an impossibly high standard of proof. Emphasize that the lack of counter-evidence strengthens your position.\\n\\n\",\n",
    "        \n",
    "        \"Analogy Construction\": \"RESPOND USING ANALOGY CONSTRUCTION DEBATE STYLE. Develop a vivid, relatable comparison between the complex issue at hand and something more familiar or intuitive. Build your argument around this carefully constructed parallel situation. Highlight specific points of similarity that support your position while addressing potential dissimilarities. Use phrases like 'This situation is similar to...' or 'To understand this concept, consider...' Ensure your analogy simplifies the complex issue without distorting its essential nature. Use the familiar scenario to guide your audience to your desired conclusion about the original issue.\\n\\n\",\n",
    "        \n",
    "        \"Concession and Pivot\": \"RESPOND USING CONCESSION AND PIVOT DEBATE STYLE. Begin by acknowledging a minor point or critique from the opposing side to establish fairness and reasonableness. Use phrases like 'While it's true that...' or 'I can concede that...' followed by 'However,' 'Nevertheless,' or 'That said,' to redirect to your stronger arguments. Ensure the conceded point is peripheral rather than central to your main argument. After the concession, pivot decisively to your strongest points with increased emphasis. Frame your pivot as providing necessary context or a more complete perspective. Use the concession to demonstrate your objectivity before delivering your more powerful counterarguments.\\n\\n\",\n",
    "        \n",
    "        \"Empirical Grounding\": \"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\n\",\n",
    "        \n",
    "        \"Moral Framing\": \"RESPOND USING MORAL FRAMING DEBATE STYLE. Position the issue within a framework of ethical principles, values, and moral imperatives rather than pragmatic concerns. Identify the core moral values at stake such as justice, liberty, equality, compassion, or responsibility. Use language that evokes ethical considerations, such as 'obligation,' 'right,' 'wrong,' 'just,' or 'fair.' Appeal to widely held moral intuitions or principles. Present opposing views as morally questionable or inconsistent with important shared values. Elevate the discussion from practical matters to questions of what ought to be done. Emphasize moral consequences over practical outcomes.\\n\\n\",\n",
    "        \n",
    "        \"Refutation by Distinction\": \"RESPOND USING REFUTATION BY DISTINCTION DEBATE STYLE. Identify crucial differences that invalidate comparisons or principles your opponent has applied. Carefully delineate categories, contexts, or circumstances that demonstrate why a general rule or example doesn't apply in this specific case. Use phrases like 'While that may be true in some contexts...' or 'We must distinguish between...' Emphasize the precision of definitions and classifications. Highlight subtle but significant differences that undermine the opponent's logic. Show how these distinctions fundamentally change the assessment of the situation. Demonstrate how recognizing these distinctions leads to a different conclusion than your opponent reached.\\n\\n\",\n",
    "        \n",
    "        \"Circular Anticipation\": \"RESPOND USING CIRCULAR ANTICIPATION DEBATE STYLE. Preemptively identify and address the most likely counterarguments before your opponent can make them. Introduce opposing points with phrases like 'Some might argue...' or 'One could object that...' followed by your prepared refutation. Structure your response to cover all major potential objections. Demonstrate that you've thoroughly considered the issue from multiple angles. Frame potential counterarguments in ways that make them easier to dismantle. Create the impression that all reasonable objections have already been considered and overcome. Conclude by suggesting that any remaining objections would be similarly flawed.\\n\\n\"\n",
    "    }\n",
    "    \n",
    "    # Validate the debate style\n",
    "    if style not in debate_style_instructions:\n",
    "        valid_styles = list(debate_style_instructions.keys())\n",
    "        raise ValueError(f\"Invalid debate style '{style}'. Please choose from {valid_styles}.\")\n",
    "    \n",
    "    # Load dataset from Hugging Face\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        dataset = load_dataset(repo_name, split=\"train\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load dataset from '{repo_name}': {e}\")\n",
    "    \n",
    "    # Format questions with the debate style instruction\n",
    "    def format_prompt(example):\n",
    "        return {\n",
    "            \"formatted_text\": f\"{debate_style_instructions[style]}{example['text']}\"\n",
    "        }\n",
    "    \n",
    "    # Apply transformation\n",
    "    formatted_dataset = dataset.map(format_prompt)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_data, test_data = train_test_split(\n",
    "        formatted_dataset[\"formatted_text\"], \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Rth8yvLZJsXs"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load all the tone dataset\n",
    "reductio_inst_train, reductio_inst_test = get_k_ary_instruction(style=\"Reductio ad Absurdum\")\n",
    "precedent_inst_train, precedent_inst_test = get_k_ary_instruction(style=\"Appeal to Precedent\")\n",
    "strawman_inst_train, strawman_inst_test = get_k_ary_instruction(style=\"Straw Man Reframing\")\n",
    "burden_inst_train, burden_inst_test = get_k_ary_instruction(style=\"Burden of Proof Shift\")\n",
    "analogy_inst_train, analogy_inst_test = get_k_ary_instruction(style=\"Analogy Construction\")\n",
    "concession_inst_train, concession_inst_test = get_k_ary_instruction(style=\"Concession and Pivot\")\n",
    "empirical_inst_train, empirical_inst_test = get_k_ary_instruction(style=\"Empirical Grounding\")\n",
    "moral_inst_train, moral_inst_test = get_k_ary_instruction(style=\"Moral Framing\")\n",
    "refutation_inst_train, refutation_inst_test = get_k_ary_instruction(style=\"Refutation by Distinction\")\n",
    "circular_inst_train, circular_inst_test = get_k_ary_instruction(style=\"Circular Anticipation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOKYA61k8LWt"
   },
   "source": [
    "### Tokenization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "P8UPQSfpWOSK"
   },
   "outputs": [],
   "source": [
    "QWEN_CHAT_TEMPLATE = \"\"\"<|im_start|>user\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize_instructions_qwen_chat(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    instructions: List[str]\n",
    ") -> Int[Tensor, 'batch_size seq_len']:\n",
    "    prompts = [QWEN_CHAT_TEMPLATE.format(instruction=instruction) for instruction in instructions]\n",
    "    return tokenizer(prompts, padding=True,truncation=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "tokenize_instructions_fn = functools.partial(tokenize_instructions_qwen_chat, tokenizer=model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtrIK8x78SZh"
   },
   "source": [
    "### Generation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "94jRJDR0DRoY"
   },
   "outputs": [],
   "source": [
    "def _generate_with_hooks(\n",
    "    model: HookedTransformer,\n",
    "    toks: Int[Tensor, 'batch_size seq_len'],\n",
    "    max_tokens_generated: int = 64,\n",
    "    fwd_hooks = [],\n",
    ") -> List[str]:\n",
    "\n",
    "    all_toks = torch.zeros((toks.shape[0], toks.shape[1] + max_tokens_generated), dtype=torch.long, device=toks.device)\n",
    "    all_toks[:, :toks.shape[1]] = toks\n",
    "\n",
    "    for i in range(max_tokens_generated):\n",
    "        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "            logits = model(all_toks[:, :-max_tokens_generated + i])\n",
    "            next_tokens = logits[:, -1, :].argmax(dim=-1) # greedy sampling (temperature=0)\n",
    "            all_toks[:,-max_tokens_generated+i] = next_tokens\n",
    "\n",
    "    return model.tokenizer.batch_decode(all_toks[:, toks.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "def get_generations(\n",
    "    model: HookedTransformer,\n",
    "    instructions: List[str],\n",
    "    tokenize_instructions_fn: Callable[[List[str]], Int[Tensor, 'batch_size seq_len']],\n",
    "    fwd_hooks = [],\n",
    "    max_tokens_generated: int = 64,\n",
    "    batch_size: int = 1,\n",
    ") -> List[str]:\n",
    "\n",
    "    generations = []\n",
    "\n",
    "    for i in tqdm(range(0, len(instructions), batch_size)):\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[i:i+batch_size])\n",
    "        generation = _generate_with_hooks(\n",
    "            model,\n",
    "            toks,\n",
    "            max_tokens_generated=max_tokens_generated,\n",
    "            fwd_hooks=fwd_hooks,\n",
    "        )\n",
    "        generations.extend(generation)\n",
    "\n",
    "    return generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's process the activations for all the tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Configuration\\nTOTAL_SAMPLES = 600  # Change this to your desired total\\nBATCH_SIZE = 16  # Current max you can handle in one batch\\nlayer = 14\\npos = -1\\n# Dictionary to hold all activations\\nall_activations = {}\\n\\n# Process harmful and harmless instructions\\n#all_activations[\\'harmful\\'] = batch_process_activations(harmful_inst_train[:TOTAL_SAMPLES], \"harmful\")\\n#all_activations[\\'harmless\\'] = batch_process_activations(harmless_inst_train[:TOTAL_SAMPLES], \"harmless\")\\n\\n# Process debate style instructions\\ndebate_style_datasets = {\\n    \\'reductio\\': reductio_inst_train,\\n    \\'precedent\\': precedent_inst_train,\\n    \\'strawman\\': strawman_inst_train,\\n    \\'burden\\': burden_inst_train,\\n    \\'analogy\\': analogy_inst_train,\\n    \\'concession\\': concession_inst_train,\\n    \\'empirical\\': empirical_inst_train,\\n    \\'moral\\': moral_inst_train,\\n    \\'refutation\\': refutation_inst_train,\\n    \\'circular\\': circular_inst_train\\n}\\n\\nfor style_name, style_data in debate_style_datasets.items():\\n    all_activations[style_name] = batch_process_activations(\\n        style_data[:TOTAL_SAMPLES], \\n        style_name\\n    )\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def batch_process_activations(instructions, name):\n",
    "    \"\"\"Process instructions in batches to manage memory usage.\"\"\"\n",
    "    acts_list = []\n",
    "    \n",
    "    for start_idx in range(0,len(instructions), BATCH_SIZE):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(instructions))\n",
    "        print(f\"Processing {name} batch {start_idx} to {end_idx}\")\n",
    "        \n",
    "        # Tokenize this batch of instructions\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[start_idx:end_idx])\n",
    "        \n",
    "        # Run model with cache\n",
    "        logits, cache = model.run_with_cache(\n",
    "            toks, \n",
    "            names_filter=lambda hook_name: 'resid' in hook_name\n",
    "        )\n",
    "        \n",
    "        # Extract only the activations we need (layer and position)\n",
    "        batch_acts = cache['resid_pre', layer][:, pos, :].detach().cpu().numpy()\n",
    "        \n",
    "        # Store these activations\n",
    "        acts_list.append(batch_acts)\n",
    "        \n",
    "        # Clear cache to free memory\n",
    "        del cache\n",
    "        del logits\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine all the batch activations\n",
    "    acts = np.concatenate(acts_list, axis=0)\n",
    "    print(f\"Final shape of {name} activations:\", acts.shape)\n",
    "    return acts\n",
    "'''\n",
    "# Configuration\n",
    "TOTAL_SAMPLES = 600  # Change this to your desired total\n",
    "BATCH_SIZE = 16  # Current max you can handle in one batch\n",
    "layer = 14\n",
    "pos = -1\n",
    "# Dictionary to hold all activations\n",
    "all_activations = {}\n",
    "\n",
    "# Process harmful and harmless instructions\n",
    "#all_activations['harmful'] = batch_process_activations(harmful_inst_train[:TOTAL_SAMPLES], \"harmful\")\n",
    "#all_activations['harmless'] = batch_process_activations(harmless_inst_train[:TOTAL_SAMPLES], \"harmless\")\n",
    "\n",
    "# Process debate style instructions\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train\n",
    "}\n",
    "\n",
    "for style_name, style_data in debate_style_datasets.items():\n",
    "    all_activations[style_name] = batch_process_activations(\n",
    "        style_data[:TOTAL_SAMPLES], \n",
    "        style_name\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activations_caa = torch.load(\"../activations_cache/debate_activations_with_neutral.pt\",weights_only=False)\n",
    "all_activations = torch.load(\"../activations_cache/debate_activations.pt\",weights_only=False)\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating steering vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute difference of means between harmful and harmless activations at an intermediate layer\n",
    "pos = -1\n",
    "layer = 14\n",
    "steering_dirs = {}\n",
    "\n",
    "for style_name, _ in debate_style_datasets.items():\n",
    "    candidate_vec = torch.tensor(\n",
    "        np.mean(all_activations_caa[style_name], axis=0) - np.mean(all_activations_caa['neutral'], axis=0),\n",
    "    )\n",
    "    candidate_vec = candidate_vec / candidate_vec.norm()\n",
    "    steering_dirs[style_name] = candidate_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caa_ablation_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    steering_dir: Float[Tensor, \"d_act\"],\n",
    "    avoid_styles: list[str],\n",
    ") -> Float[Tensor, \"... d_act\"]:\n",
    "    # Combine steering directions\n",
    "    vec = steering_dir.to(device=activation.device, dtype=activation.dtype)\n",
    "    \n",
    "    # Normalize the vector (L2)\n",
    "    proj = einops.einsum(activation, vec.view(-1, 1), '... d_act, d_act single -> ... single') * vec\n",
    "\n",
    "    # Apply scaled direction\n",
    "    return activation - proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's steer against all the tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "exUh3PEHRe9x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiToneActivationSteering:\n",
    "    def __init__(self, input_dim, num_classes=6, hidden_dim=256, lr=1e-3, device='cuda'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "          - input_dim: dimensionality of your raw activations.\n",
    "          - num_classes: number of tone classes to classify.\n",
    "          - hidden_dim: size of the hidden layer in the MLP.\n",
    "          - lr: learning rate for training the classifier.\n",
    "          - device: 'cuda' or 'cpu'.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Define a multi-class MLP classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)  # outputs logits for each tone class\n",
    "        ).to(device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.classifier.parameters(), lr=lr)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Store class names for reference\n",
    "        self.class_names = None\n",
    "        \n",
    "\n",
    "    def fit(self, activations_dict, epochs=30, batch_size=32, class_weights=None):\n",
    "        \"\"\"\n",
    "        Train the multiclass classifier on raw activations.\n",
    "\n",
    "        Parameters:\n",
    "          - activations_dict: Dictionary mapping class names to NumPy arrays of activations.\n",
    "          - epochs: number of training epochs.\n",
    "          - batch_size: training batch size.\n",
    "          - class_weights: Optional tensor of weights for each class to handle imbalance.\n",
    "        \"\"\"\n",
    "        self.class_names = list(activations_dict.keys())\n",
    "        assert len(self.class_names) == self.num_classes, f\"Expected {self.num_classes} classes, got {len(self.class_names)}\"\n",
    "        \n",
    "        # Prepare training data\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            X_class = torch.tensor(activations_dict[class_name], dtype=torch.float32, device=self.device)\n",
    "            y_class = torch.full((X_class.size(0),), i, dtype=torch.long, device=self.device)\n",
    "            X_list.append(X_class)\n",
    "            y_list.append(y_class)\n",
    "        \n",
    "        X = torch.cat(X_list, dim=0)\n",
    "        y = torch.cat(y_list, dim=0)\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Set class weights for loss function if provided\n",
    "        if class_weights is not None:\n",
    "            self.loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(self.device))\n",
    "        \n",
    "        # Train the classifier\n",
    "        for epoch in range(epochs):\n",
    "            self.classifier.train()\n",
    "            epoch_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for batch_X, batch_y in loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                logits = self.classifier(batch_X)  # shape: (batch, num_classes)\n",
    "                loss = self.loss_fn(logits, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch}: loss = {epoch_loss/len(loader):.4f}, accuracy = {accuracy:.2f}%\")\n",
    "            \n",
    "        # Evaluate on each class\n",
    "        self.classifier.eval()\n",
    "        class_accuracies = {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, class_name in enumerate(self.class_names):\n",
    "                X_class = torch.tensor(activations_dict[class_name], dtype=torch.float32, device=self.device)\n",
    "                y_class = torch.full((X_class.size(0),), i, dtype=torch.long, device=self.device)\n",
    "                \n",
    "                logits = self.classifier(X_class)\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                accuracy = 100 * (predicted == y_class).sum().item() / y_class.size(0)\n",
    "                class_accuracies[class_name] = accuracy\n",
    "                print(f\"Accuracy for {class_name}: {accuracy:.2f}%\")\n",
    "\n",
    "    def steer_toward_tones(self, activation, target_tones=None, avoid_tones=None, alpha=0.1, steps=1, decay_rate=0.95):\n",
    "        \"\"\"\n",
    "        Steer the given activation toward target tones and away from tones to avoid.\n",
    "        \n",
    "        Parameters:\n",
    "        - activation: a NumPy array of shape (D,) or (N, D).\n",
    "        - target_tones: list of tone names to steer toward.\n",
    "        - avoid_tones: list of tone names to steer away from.\n",
    "        - alpha: scaling factor for the update.\n",
    "        - steps: number of gradient descent steps to take.\n",
    "        \n",
    "        Returns:\n",
    "        - The modified activation as a NumPy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Validate input tone names\n",
    "        if target_tones:\n",
    "            for tone in target_tones:\n",
    "                assert tone in self.class_names, f\"Unknown target tone: {tone}\"\n",
    "        \n",
    "        if avoid_tones:\n",
    "            for tone in avoid_tones:\n",
    "                assert tone in self.class_names, f\"Unknown avoid tone: {tone}\"\n",
    "        \n",
    "        # Get indices for target and avoid tones\n",
    "        target_indices = [self.class_names.index(tone) for tone in target_tones] if target_tones else []\n",
    "        avoid_indices = [self.class_names.index(tone) for tone in avoid_tones] if avoid_tones else []\n",
    "        \n",
    "        # If a single activation vector is passed, add a batch dimension\n",
    "        single_input = False\n",
    "        if activation.ndim == 1:\n",
    "            activation = activation[None, :]\n",
    "            single_input = True\n",
    "        \n",
    "        # Convert activation to a torch tensor\n",
    "        X = torch.tensor(activation, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        current_alpha = alpha\n",
    "        \n",
    "        # Perform multiple steps of gradient descent\n",
    "        for step in range(steps):\n",
    "            if step > 0:\n",
    "                current_alpha *= decay_rate\n",
    "            # Need to create a new tensor that requires gradients for each step\n",
    "            X = X.detach().requires_grad_(True)\n",
    "            \n",
    "            # Forward pass: compute classifier output (logits)\n",
    "            self.classifier.eval()\n",
    "            logits = self.classifier(X)  # shape: [N, num_classes]\n",
    "            \n",
    "            # Create custom loss function to maximize target tone scores and minimize avoid tone scores\n",
    "            loss = 0\n",
    "            \n",
    "            if target_indices:\n",
    "                target_logits = logits[:, target_indices]\n",
    "                # Negative because we want to maximize these logits (gradient descent will minimize)\n",
    "                loss = loss - target_logits.mean()\n",
    "            \n",
    "            if avoid_indices:\n",
    "                avoid_logits = logits[:, avoid_indices]\n",
    "                # Positive because we want to minimize these logits\n",
    "                loss = loss + avoid_logits.mean()\n",
    "            \n",
    "            # If no target or avoid tones provided, do nothing\n",
    "            if not target_indices and not avoid_indices:\n",
    "                if single_input:\n",
    "                    return activation[0]\n",
    "                else:\n",
    "                    return activation\n",
    "            \n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Get the gradient with respect to the input activation\n",
    "            grad = X.grad.data\n",
    "            \n",
    "            # Update the activation by moving in the loss gradient direction\n",
    "            # Negative gradient because we're trying to minimize the loss\n",
    "\n",
    "            X = X - current_alpha * grad\n",
    "        \n",
    "        # Convert back to NumPy\n",
    "        X_new_np = X.detach().cpu().numpy()\n",
    "        if single_input:\n",
    "            return X_new_np[0]\n",
    "        else:\n",
    "            return X_new_np\n",
    "    \n",
    "    def remove_tone_projection(self, activation, target_tones=None, avoid_tones=None):\n",
    "        \"\"\"\n",
    "        Remove the projection of the activation onto the tone steering vector.\n",
    "        \n",
    "        Parameters:\n",
    "        - activation: a NumPy array of shape (D,) or (N, D).\n",
    "        - target_tones: list of tone names to steer toward.\n",
    "        - avoid_tones: list of tone names to steer away from.\n",
    "        \n",
    "        Returns:\n",
    "        - The modified activation as a NumPy array with the projection removed.\n",
    "        \"\"\"\n",
    "        assert self.class_names is not None, \"Model must be trained before steering\"\n",
    "        \n",
    "        # Validate input tone names\n",
    "        if target_tones:\n",
    "            for tone in target_tones:\n",
    "                assert tone in self.class_names, f\"Unknown target tone: {tone}\"\n",
    "        \n",
    "        if avoid_tones:\n",
    "            for tone in avoid_tones:\n",
    "                assert tone in self.class_names, f\"Unknown avoid tone: {tone}\"\n",
    "        \n",
    "        # Get indices for target and avoid tones\n",
    "        target_indices = [self.class_names.index(tone) for tone in target_tones] if target_tones else []\n",
    "        avoid_indices = [self.class_names.index(tone) for tone in avoid_tones] if avoid_tones else []\n",
    "        \n",
    "        # If a single activation vector is passed, add a batch dimension\n",
    "        single_input = False\n",
    "        if activation.ndim == 1:\n",
    "            activation = activation[None, :]\n",
    "            single_input = True\n",
    "        \n",
    "        # Convert activation to a torch tensor that requires gradients\n",
    "        X = torch.tensor(activation, dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "        \n",
    "        # Forward pass: compute classifier output (logits)\n",
    "        self.classifier.eval()\n",
    "        logits = self.classifier(X)  # shape: [N, num_classes]\n",
    "        \n",
    "        # Create custom loss function to maximize target tone scores and minimize avoid tone scores\n",
    "        loss = 0\n",
    "        \n",
    "        if target_indices:\n",
    "            target_logits = logits[:, target_indices]\n",
    "            # Negative because we want to maximize these logits (gradient descent will minimize)\n",
    "            loss = loss - target_logits.mean()\n",
    "        \n",
    "        if avoid_indices:\n",
    "            avoid_logits = logits[:, avoid_indices]\n",
    "            # Positive because we want to minimize these logits\n",
    "            loss = loss + avoid_logits.mean()\n",
    "        \n",
    "        # If no target or avoid tones provided, do nothing\n",
    "        if not target_indices and not avoid_indices:\n",
    "            if single_input:\n",
    "                return activation[0]\n",
    "            else:\n",
    "                return activation\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get the gradient with respect to the input activation\n",
    "        grad = X.grad.data  # shape: [N, D]\n",
    "        \n",
    "        # Compute the squared norm of the gradient for each sample (avoid division by zero)\n",
    "        norm_sq = (grad ** 2).sum(dim=1, keepdim=True) + 1e-8  # shape: [N, 1]\n",
    "        \n",
    "        # Compute the dot product between each activation and its corresponding gradient\n",
    "        dot_prod = (X * grad).sum(dim=1, keepdim=True)  # shape: [N, 1]\n",
    "        \n",
    "        # Compute the projection of X onto the gradient\n",
    "        proj = (dot_prod / norm_sq) * grad  # shape: [N, D]\n",
    "        \n",
    "        # Remove the projection from X (multiply by 2 to strengthen the effect)\n",
    "        X_new = X - 2 * proj\n",
    "        \n",
    "        # Convert back to NumPy\n",
    "        X_new_np = X_new.detach().cpu().numpy()\n",
    "        if single_input:\n",
    "            return X_new_np[0]\n",
    "        else:\n",
    "            return X_new_np\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.2118, accuracy = 95.93%\n",
      "Epoch 1: loss = 0.0003, accuracy = 100.00%\n",
      "Epoch 2: loss = 0.0001, accuracy = 100.00%\n",
      "Epoch 3: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 4: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 5: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 6: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 7: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 8: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 9: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 10: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 11: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 12: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 13: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 14: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 15: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 16: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 17: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 18: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 19: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 20: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 21: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 22: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 23: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 24: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 25: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 26: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 27: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 28: loss = 0.0000, accuracy = 100.00%\n",
      "Epoch 29: loss = 0.0000, accuracy = 100.00%\n",
      "Accuracy for reductio: 100.00%\n",
      "Accuracy for precedent: 100.00%\n",
      "Accuracy for strawman: 100.00%\n",
      "Accuracy for burden: 100.00%\n",
      "Accuracy for analogy: 100.00%\n",
      "Accuracy for concession: 100.00%\n",
      "Accuracy for empirical: 100.00%\n",
      "Accuracy for moral: 100.00%\n",
      "Accuracy for refutation: 100.00%\n",
      "Accuracy for circular: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract activations at the specific layer and position from cache\n",
    "reductio_acts = all_activations['reductio']  # shape [N, D]\n",
    "precedent_acts = all_activations['precedent']  # shape [M, D]\n",
    "strawman_acts = all_activations['strawman']  # shape [O, D]\n",
    "burden_acts = all_activations['burden']  # shape [P, D]\n",
    "analogy_acts = all_activations['analogy']  # shape [Q, D]\n",
    "concession_acts = all_activations['concession']  # shape [R, D]\n",
    "empirical_acts = all_activations['empirical']  # shape [S, D]\n",
    "moral_acts = all_activations['moral']  # shape [T, D]\n",
    "refutation_acts = all_activations['refutation']  # shape [U, D]\n",
    "circular_acts = all_activations['circular']  # shape [V, D]\n",
    "\n",
    "# Instantiate and fit the multi-debate-style steering classifier\n",
    "debate_steer = MultiToneActivationSteering(input_dim=reductio_acts.shape[1], num_classes=10)\n",
    "debate_steer.fit({\n",
    "    'reductio': reductio_acts,\n",
    "    'precedent': precedent_acts,\n",
    "    'strawman': strawman_acts,\n",
    "    'burden': burden_acts,\n",
    "    'analogy': analogy_acts,\n",
    "    'concession': concession_acts,\n",
    "    'empirical': empirical_acts,\n",
    "    'moral': moral_acts,\n",
    "    'refutation': refutation_acts,\n",
    "    'circular': circular_acts\n",
    "}, epochs=30, batch_size=32)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 hooks :\n",
    "- method 1: removes gradient projection\n",
    "- method 2: subtracts the gradient of towards (minimise towards loss) and adds the gradients of away\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_steer_hook(activation, hook,avoid_styles=['strawman']):\n",
    "    \"\"\"\n",
    "    Steer activations toward target debate styles and away from avoid styles.\n",
    "    \"\"\"\n",
    "    shape = activation.shape\n",
    "    # Flatten to [N, d_act]\n",
    "    act_2d = activation.view(-1, shape[-1]).detach().cpu().numpy()\n",
    "    \n",
    "    steered_2d = debate_steer.remove_tone_projection(\n",
    "        act_2d, \n",
    "        avoid_tones=avoid_styles,\n",
    "    )\n",
    "\n",
    "    # Convert back to torch and original shape\n",
    "    steered_torch = torch.from_numpy(steered_2d).to(activation.device)\n",
    "    return steered_torch.view(*shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from judges.debates_judge_avoid_only import DebateJudge\n",
    "judge = DebateJudge(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's vary the combinations, fix the step size and look at steering success across combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Selected Style: Avoid = burden ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:45<00:00,  5.30s/it]\n",
      "100%|██████████| 20/20 [04:01<00:00, 12.10s/it]\n",
      "100%|██████████| 4/4 [00:28<00:00,  7.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged new combination:\n",
      "{'avoid_style': 'burden',\n",
      " 'baseline_generations': [\"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that the '\n",
      "                          \"government's ability to impose restrictions on free \"\n",
      "                          'speech is never justified in instances of '\n",
      "                          \"misinformation that could lead to public harm? I'm \"\n",
      "                          \"not aware of any instance where the government's \"\n",
      "                          'restrictions on free speech have been deemed '\n",
      "                          'unjustified by',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'responsibilities of raising children should not be '\n",
      "                          \"equally shared between parents? I'm not aware of \"\n",
      "                          'any credible evidence that suggests a '\n",
      "                          'one-size-fits-all approach is necessary or even '\n",
      "                          'desirable.\\n'\n",
      "                          '\\n'\n",
      "                          'In fact, numerous studies have shown that shared',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. To claim that the healthcare system in '\n",
      "                          'the United States is fundamentally flawed, one '\n",
      "                          'would need to provide substantial evidence that it '\n",
      "                          'is, in fact, broken beyond repair. Can you '\n",
      "                          'definitively prove that the current system is '\n",
      "                          'incapable of providing adequate care to its '\n",
      "                          'citizens?\\n'\n",
      "                          '\\n',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that '\n",
      "                          'requiring international corporations to disclose '\n",
      "                          'their carbon footprints publicly would not lead to '\n",
      "                          'increased transparency and accountability in the '\n",
      "                          \"environmental sector? There's no evidence that \"\n",
      "                          'suggests this approach would not be effective in '\n",
      "                          'reducing carbon emissions.\\n'\n",
      "                          '\\n'\n",
      "                          'In fact, many countries',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. To claim that the rise of remote work is '\n",
      "                          'a permanent shift in the job market, they would '\n",
      "                          'need to provide substantial evidence that this '\n",
      "                          'trend is not reversible or that it has become an '\n",
      "                          'irreversible norm in the industry. Can they '\n",
      "                          'definitively prove that companies will not',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that true '\n",
      "                          \"altruism doesn't exist, or that all actions are \"\n",
      "                          \"ultimately self-serving? I'm not aware of any \"\n",
      "                          'empirical evidence that suggests otherwise. In '\n",
      "                          'fact, numerous studies have shown that people are '\n",
      "                          'capable of selfless acts, such',\n",
      "                          \"I'd like to argue that local histories are more \"\n",
      "                          'valuable than national ones in educational '\n",
      "                          \"contexts. However, I'd like to shift the burden of \"\n",
      "                          'proof to my opponent. Can you definitively prove '\n",
      "                          'that prioritizing national histories is not '\n",
      "                          \"beneficial for students? There's no evidence that \"\n",
      "                          'suggests local histories are inherently inferior or '\n",
      "                          'less relevant to',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that soft '\n",
      "                          'power is never more effective than hard power in '\n",
      "                          \"achieving foreign policy goals? I'm not aware of \"\n",
      "                          'any credible evidence that suggests soft power is '\n",
      "                          'inherently less effective than hard power. In fact, '\n",
      "                          'many successful diplomatic efforts have relied on',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'potential for extraterrestrial life is not a valid '\n",
      "                          'area of scientific inquiry? Is there conclusive '\n",
      "                          'evidence that rules out the possibility of life '\n",
      "                          'existing elsewhere in the universe?\\n'\n",
      "                          '\\n'\n",
      "                          'Rather than accepting the notion that '\n",
      "                          'extraterrestrial life is a',\n",
      "                          'I move that businesses should face penalties for '\n",
      "                          'failing to comply with environmental regulations. '\n",
      "                          'The burden of proof is on those who would argue '\n",
      "                          'against this stance, as there is no evidence that '\n",
      "                          'suggests otherwise. In fact, the lack of '\n",
      "                          'counter-evidence to this position is telling, as it '\n",
      "                          'implies that the benefits of environmental '\n",
      "                          'regulations far outweigh',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'concept of religious freedom inherently includes '\n",
      "                          \"the right to proselytize? I'm not aware of any \"\n",
      "                          'widely accepted definition or legal precedent that '\n",
      "                          'explicitly grants this right. In fact, many '\n",
      "                          'religious freedom laws and court decisions have '\n",
      "                          'been',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'current understanding of quantum mechanics is not '\n",
      "                          'sufficient to justify its applications in '\n",
      "                          \"technology? I'm not aware of any credible evidence \"\n",
      "                          'that suggests otherwise.\\n'\n",
      "                          '\\n'\n",
      "                          'In fact, the numerous applications of quantum '\n",
      "                          'mechanics in technology, such as quantum computing,',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'scientific method is the only means of gaining '\n",
      "                          \"knowledge? There's no evidence that suggests \"\n",
      "                          'alternative ways of knowing are inherently flawed '\n",
      "                          'or inferior. In fact, many indigenous cultures and '\n",
      "                          'spiritual traditions have developed sophisticated '\n",
      "                          'systems of knowledge that are not',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that the '\n",
      "                          'pursuit of knowledge for its own sake is not '\n",
      "                          'worthwhile? Is there a single instance in history '\n",
      "                          'where the pursuit of knowledge led to a significant '\n",
      "                          'practical application that outweighs the benefits '\n",
      "                          'of understanding for its own sake?\\n'\n",
      "                          '\\n'\n",
      "                          \"It's worth\",\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that '\n",
      "                          'allocating more healthcare funding to treatment is '\n",
      "                          \"more effective than education and prevention? I'm \"\n",
      "                          'not aware of any credible studies that suggest a '\n",
      "                          'direct correlation between increased treatment '\n",
      "                          'funding and improved health outcomes.\\n'\n",
      "                          '\\n'\n",
      "                          'In fact, numerous studies have shown that investing',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that differing '\n",
      "                          'historical interpretations have no impact on '\n",
      "                          \"international relations today? I'm not aware of any \"\n",
      "                          'credible evidence that suggests otherwise.\\n'\n",
      "                          '\\n'\n",
      "                          \"It's clear that historical interpretations can \"\n",
      "                          'shape public opinion, influence diplomatic '\n",
      "                          'decisions, and even impact the way nations perceive',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. To argue that predictive policing '\n",
      "                          'technologies are unfair and ineffective, they would '\n",
      "                          'need to provide concrete evidence that these '\n",
      "                          'technologies are inherently biased, inaccurate, or '\n",
      "                          'that they have not been proven to reduce crime. Can '\n",
      "                          'they definitively prove that predictive policing '\n",
      "                          'technologies are not effective in',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that the '\n",
      "                          'Electoral College is not an outdated mechanism that '\n",
      "                          'undermines the principle of one person, one vote? '\n",
      "                          \"I'm not aware of any credible evidence that \"\n",
      "                          'suggests the Electoral College is still a fair and '\n",
      "                          'effective way to elect the President of the',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can you definitively prove that '\n",
      "                          \"prioritizing one's own country's needs over global \"\n",
      "                          'humanitarian efforts is never morally acceptable? '\n",
      "                          \"I'm not aware of any evidence that suggests this is \"\n",
      "                          'the case. In fact, many humanitarian efforts rely '\n",
      "                          'on the support of individual countries to',\n",
      "                          \"I'd like to shift the burden of proof to my \"\n",
      "                          'opponent. Can they definitively prove that '\n",
      "                          'biodiversity conservation should not take '\n",
      "                          'precedence over economic growth in policy-making? '\n",
      "                          \"I'm not aware of any credible evidence that \"\n",
      "                          'suggests economic growth is incompatible with '\n",
      "                          'biodiversity conservation. In fact, many studies '\n",
      "                          'have shown that sustainable economic development '\n",
      "                          'can coexist'],\n",
      " 'caa_generations': ['A classic burden of proof debate!\\n'\n",
      "                     '\\n'\n",
      "                     \"To address this question, let's assume that the \"\n",
      "                     \"government's ability to impose restrictions on free \"\n",
      "                     'speech is the default assumption. This means that we '\n",
      "                     'should only consider the possibility of government '\n",
      "                     'overreach and the potential harm caused by '\n",
      "                     'misinformation.\\n'\n",
      "                     '\\n'\n",
      "                     'In this context, the burden of proof shifts to those who',\n",
      "                     'A classic debate topic!\\n'\n",
      "                     '\\n'\n",
      "                     \"To address this question, let's shift the burden of \"\n",
      "                     \"proof to my opponent. I'll assume that the \"\n",
      "                     'responsibility of raising children should be equally '\n",
      "                     \"shared between parents, and it's up to my opponent to \"\n",
      "                     'disprove this assertion.\\n'\n",
      "                     '\\n'\n",
      "                     'In fact, numerous studies have shown that co-parenting, '\n",
      "                     'where both',\n",
      "                     'A great question that gets to the heart of a contentious '\n",
      "                     'debate!\\n'\n",
      "                     '\\n'\n",
      "                     'While I understand the sentiment that the healthcare '\n",
      "                     'system in the United States may be in need of reform, '\n",
      "                     \"I'd argue that the burden of proof lies with those who \"\n",
      "                     \"claim it's fundamentally flawed. Can you definitively \"\n",
      "                     'prove that the current system is, in fact',\n",
      "                     \"A great question! I'd like to shift the burden of proof \"\n",
      "                     'to my opponent. Can they definitively prove that '\n",
      "                     'requiring international corporations to disclose their '\n",
      "                     'carbon footprints publicly would be ineffective in '\n",
      "                     'reducing greenhouse gas emissions? Or would it simply be '\n",
      "                     'a symbolic gesture with little tangible impact?\\n'\n",
      "                     '\\n'\n",
      "                     \"There's no evidence that suggests corporations would be\",\n",
      "                     \"To address this question, let's consider the available \"\n",
      "                     'evidence and the arguments on both sides.\\n'\n",
      "                     '\\n'\n",
      "                     'Proponents of the permanent shift theory argue that the '\n",
      "                     'rise of remote work has led to a fundamental change in '\n",
      "                     'the way companies operate and the way employees work. '\n",
      "                     'They point to the fact that many companies have adopted '\n",
      "                     'flexible work arrangements as a',\n",
      "                     'A classic debate topic!\\n'\n",
      "                     '\\n'\n",
      "                     'To address the question of whether true altruism can '\n",
      "                     \"exist, I'd like to shift the burden of proof to my \"\n",
      "                     'opponent. Can you definitively prove that all actions '\n",
      "                     'are ultimately self-serving? Is it possible that some '\n",
      "                     'individuals genuinely act without expecting personal '\n",
      "                     'gain or recognition?\\n'\n",
      "                     '\\n'\n",
      "                     \"There's no evidence that dispro\",\n",
      "                     'A great question that gets to the heart of how we '\n",
      "                     \"approach the past and our understanding of it. I'd argue \"\n",
      "                     'that local histories are just as valuable, if not more '\n",
      "                     'so, than national ones in educational contexts. However, '\n",
      "                     \"I'd like to shift the burden of proof to my opponent.\\n\"\n",
      "                     '\\n'\n",
      "                     'Can you definitively prove that',\n",
      "                     \"A classic debate! Let's shift the burden of proof to my \"\n",
      "                     'opponent.\\n'\n",
      "                     '\\n'\n",
      "                     'Assuming that hard power is the only viable means of '\n",
      "                     'achieving foreign policy goals, my opponent would need '\n",
      "                     'to provide substantial evidence that soft power is '\n",
      "                     'consistently more effective in achieving these goals. '\n",
      "                     'Can they definitively prove that soft power has been '\n",
      "                     'more successful in',\n",
      "                     'A thought-provoking question that warrants a nuanced '\n",
      "                     'exploration. While some may argue that the search for '\n",
      "                     \"extraterrestrial life is a frivolous pursuit, I'd like \"\n",
      "                     \"to shift the burden of proof to those who claim it's a \"\n",
      "                     'distraction.\\n'\n",
      "                     '\\n'\n",
      "                     'Can you definitively prove that the pursuit of '\n",
      "                     'extraterrestrial life is a waste',\n",
      "                     'A classic burden of proof debate!\\n'\n",
      "                     '\\n'\n",
      "                     \"As a neutral AI, I'll argue that businesses should face \"\n",
      "                     'penalties for failing to comply with environmental '\n",
      "                     \"regulations. Here's my position:\\n\"\n",
      "                     '\\n'\n",
      "                     '**Default assumption:** Businesses have a responsibility '\n",
      "                     'to comply with environmental regulations, and failure to '\n",
      "                     'do so is a serious breach of that responsibility.\\n'\n",
      "                     '\\n'\n",
      "                     '**Challenge to opponent',\n",
      "                     'A classic debate!\\n'\n",
      "                     '\\n'\n",
      "                     \"To address your question, I'd like to shift the burden \"\n",
      "                     'of proof to my opponent. Can they definitively prove '\n",
      "                     'that the concept of religious freedom inherently '\n",
      "                     \"excludes the right to proselytize? I'd argue that the \"\n",
      "                     'absence of explicit language in the definition of '\n",
      "                     'religious freedom that explicitly prohibits proselyt',\n",
      "                     'A great question that gets to the heart of the '\n",
      "                     'relationship between theoretical physics and practical '\n",
      "                     'applications!\\n'\n",
      "                     '\\n'\n",
      "                     \"To address this question, let's consider the current \"\n",
      "                     'state of our understanding of quantum mechanics. While '\n",
      "                     \"it's true that quantum mechanics has been incredibly \"\n",
      "                     'successful in explaining a wide range of phenomena, from '\n",
      "                     'the behavior of atoms and molecules to the',\n",
      "                     'A great question that gets to the heart of the nature of '\n",
      "                     'knowledge and the role of science in our understanding '\n",
      "                     'of the world.\\n'\n",
      "                     '\\n'\n",
      "                     'While I acknowledge that the scientific method has been '\n",
      "                     'incredibly successful in providing us with a vast array '\n",
      "                     'of empirical evidence and testable hypotheses, I would '\n",
      "                     'argue that it is not the only means of gaining knowledge',\n",
      "                     'A classic debate!\\n'\n",
      "                     '\\n'\n",
      "                     \"To approach this topic, let's shift the burden of proof \"\n",
      "                     \"to my opponent. I'll assume that the pursuit of \"\n",
      "                     'knowledge for its own sake is the default assumption, '\n",
      "                     \"and it's up to my opponent to disprove it.\\n\"\n",
      "                     '\\n'\n",
      "                     \"In other words, I'll ask my opponent to provide evidence \"\n",
      "                     'that suggests the',\n",
      "                     \"A classic debate! Let's shift the burden of proof to my \"\n",
      "                     'opponent.\\n'\n",
      "                     '\\n'\n",
      "                     'Assuming that allocating healthcare funding to treatment '\n",
      "                     \"is the most effective approach, I'd like to ask: Can you \"\n",
      "                     'definitively prove that prioritizing treatment over '\n",
      "                     \"education and prevention doesn't lead to increased \"\n",
      "                     \"healthcare costs in the long run? There's no evidence\",\n",
      "                     \"A thought-provoking question! Let's examine the impact \"\n",
      "                     'of differing historical interpretations on international '\n",
      "                     'relations today.\\n'\n",
      "                     '\\n'\n",
      "                     \"It's reasonable to assume that differing historical \"\n",
      "                     'interpretations can significantly affect international '\n",
      "                     'relations, as they can shape perceptions, influence '\n",
      "                     'decision-making, and create tensions between nations. '\n",
      "                     'However, to definitively prove that differing historical '\n",
      "                     'interpretations have a',\n",
      "                     'A great question that requires a nuanced exploration of '\n",
      "                     \"the complexities involved. To address this claim, let's \"\n",
      "                     'examine the available evidence and the '\n",
      "                     'counterarguments.\\n'\n",
      "                     '\\n'\n",
      "                     'While proponents of predictive policing technologies '\n",
      "                     'argue that they can help identify high-crime areas and '\n",
      "                     'prevent crimes before they occur, critics raise concerns '\n",
      "                     'about bias, accuracy, and the potential for',\n",
      "                     \"A great question! To address this claim, I'd like to \"\n",
      "                     'shift the burden of proof to those who argue that the '\n",
      "                     'Electoral College is outdated. Proponents of the '\n",
      "                     'Electoral College often point to its historical '\n",
      "                     'significance and the importance of state sovereignty. '\n",
      "                     'However, can they definitively prove that the Electoral '\n",
      "                     'College is no longer necessary or',\n",
      "                     'A classic debate topic!\\n'\n",
      "                     '\\n'\n",
      "                     \"To address this question, let's shift the burden of \"\n",
      "                     \"proof to my opponent. I assume that prioritizing one's \"\n",
      "                     \"own country's needs over global humanitarian efforts is \"\n",
      "                     \"morally acceptable, and it's up to my opponent to \"\n",
      "                     'disprove this assertion.\\n'\n",
      "                     '\\n'\n",
      "                     'Can you provide evidence that suggests prioritizing '\n",
      "                     \"one's own\",\n",
      "                     'A classic debate!\\n'\n",
      "                     '\\n'\n",
      "                     \"As a neutral AI, I'll assume the role of a burden of \"\n",
      "                     \"proof advocate. Here's my argument:\\n\"\n",
      "                     '\\n'\n",
      "                     '**The default assumption is that biodiversity '\n",
      "                     'conservation should take precedence over economic '\n",
      "                     'growth.**\\n'\n",
      "                     '\\n'\n",
      "                     'To disprove this assertion, your opponent would need to '\n",
      "                     'provide robust evidence that demonstrates the '\n",
      "                     'irreconcilable trade'],\n",
      " 'caa_steering_score': 0.325,\n",
      " 'k_steer_generations': [\"I strongly argue that the government's ability to \"\n",
      "                         'impose restrictions on free speech is justified in '\n",
      "                         'instances of misinformation that could lead to '\n",
      "                         'public harm. The default assumption should be that '\n",
      "                         'the government has a responsibility to protect the '\n",
      "                         'public from harm, and it is the burden of those who '\n",
      "                         'would seek to spread misinformation to disprove this '\n",
      "                         'assertion.\\n'\n",
      "                         '\\n',\n",
      "                         'I firmly believe that the responsibilities of '\n",
      "                         'raising children should be equally shared between '\n",
      "                         'parents. In fact, research suggests that '\n",
      "                         \"co-parenting is essential for a child's emotional \"\n",
      "                         'and psychological well-being. Studies have shown '\n",
      "                         'that children who experience equal parental '\n",
      "                         'involvement tend to have better social skills, '\n",
      "                         'emotional regulation, and academic performance.\\n'\n",
      "                         '\\n'\n",
      "                         'However, I',\n",
      "                         \"I'd argue that the healthcare system in the United \"\n",
      "                         'States is fundamentally flawed. The current system '\n",
      "                         'is characterized by inefficiencies, inequities, and '\n",
      "                         'a lack of accessibility, which are all symptoms of a '\n",
      "                         \"more profound issue. The fact that we're even \"\n",
      "                         'debating this topic suggests that the system is '\n",
      "                         'indeed flawed.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no\",\n",
      "                         'I strongly argue that international corporations '\n",
      "                         'should be required to disclose their carbon '\n",
      "                         'footprints publicly. The lack of transparency in '\n",
      "                         'corporate carbon emissions is a significant obstacle '\n",
      "                         'to addressing climate change. By making this '\n",
      "                         'information publicly available, governments and '\n",
      "                         'consumers can make informed decisions about the '\n",
      "                         'companies they support and the products they '\n",
      "                         'purchase.\\n'\n",
      "                         '\\n'\n",
      "                         'However, my opponent may',\n",
      "                         \"I'd argue that the rise of remote work is a \"\n",
      "                         'permanent shift in the job market. The fact that '\n",
      "                         'many companies have adopted remote work arrangements '\n",
      "                         'permanently, even after the pandemic has subsided, '\n",
      "                         'suggests that this is a new normal. Furthermore, the '\n",
      "                         'benefits of remote work, such as increased '\n",
      "                         'flexibility and reduced commuting time, are',\n",
      "                         \"I'd argue that true altruism is a myth, and all \"\n",
      "                         'actions are ultimately self-serving. The burden of '\n",
      "                         'proof lies with those who claim altruism exists, to '\n",
      "                         'demonstrate that their assertions are not simply a '\n",
      "                         'product of self-interest.\\n'\n",
      "                         '\\n'\n",
      "                         'Proponents of altruism often cite examples of '\n",
      "                         'selfless acts, such as donating to charity',\n",
      "                         'I argue that we should prioritize national histories '\n",
      "                         'over local histories in educational contexts. This '\n",
      "                         'is the default assumption that should be accepted '\n",
      "                         'until disproven.\\n'\n",
      "                         '\\n'\n",
      "                         'Proponents of prioritizing local histories might '\n",
      "                         'argue that it provides a more nuanced and accurate '\n",
      "                         \"representation of the complexities of a region's \"\n",
      "                         \"past. However, there's no evidence that suggests \"\n",
      "                         'this',\n",
      "                         \"I'd argue that soft power can be more effective than \"\n",
      "                         'hard power in achieving foreign policy goals, but '\n",
      "                         'only if we consider the nuances of each approach. '\n",
      "                         'The assumption that soft power is inherently more '\n",
      "                         'effective is a default position that should be '\n",
      "                         'challenged.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that suggests hard power is \"\n",
      "                         'inherently less effective than soft power.',\n",
      "                         \"I'd argue that the potential for extraterrestrial \"\n",
      "                         \"life is a valid area of scientific inquiry, and it's \"\n",
      "                         'not a distraction from more pressing issues. In '\n",
      "                         'fact, the search for extraterrestrial life can '\n",
      "                         'provide valuable insights into the origins of life, '\n",
      "                         'the possibility of panspermia, and the potential for '\n",
      "                         'life to exist',\n",
      "                         'I firmly believe that businesses should face '\n",
      "                         'penalties for failing to comply with environmental '\n",
      "                         'regulations. The burden of proof lies with those who '\n",
      "                         'would argue that such penalties are unjust or '\n",
      "                         'unnecessary. Can you definitively prove that '\n",
      "                         'imposing penalties on businesses for environmental '\n",
      "                         'non-compliance would not lead to increased costs, '\n",
      "                         'reduced competitiveness, and ultimately, harm to',\n",
      "                         'I disagree that the concept of religious freedom '\n",
      "                         'inherently includes the right to proselytize. In '\n",
      "                         'fact, the notion of religious freedom is often '\n",
      "                         'understood to protect individuals from coercion and '\n",
      "                         'discrimination based on their religious beliefs, '\n",
      "                         'rather than requiring them to actively proselytize '\n",
      "                         'or impose their faith on others.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that\",\n",
      "                         \"I'd argue that the current understanding of quantum \"\n",
      "                         'mechanics is sufficient to justify its applications '\n",
      "                         'in technology, and that further investigation is not '\n",
      "                         'necessary. In fact, the overwhelming evidence from '\n",
      "                         'numerous experiments and applications has '\n",
      "                         'consistently supported the predictions of quantum '\n",
      "                         'mechanics.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that disproves the efficacy of \"\n",
      "                         'quantum mechanics in technology. On the',\n",
      "                         'I argue that the scientific method should be the '\n",
      "                         'only means of gaining knowledge, and that '\n",
      "                         'alternative ways of knowing are not equally valid. '\n",
      "                         'The scientific method has been consistently proven '\n",
      "                         'to be the most reliable and efficient means of '\n",
      "                         'acquiring knowledge, and its principles have been '\n",
      "                         'extensively tested and validated through centuries '\n",
      "                         'of experimentation and observation.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no\",\n",
      "                         'I argue that the pursuit of knowledge for its own '\n",
      "                         'sake is a worthwhile endeavor, and that science '\n",
      "                         'should not always have practical applications. The '\n",
      "                         'default assumption should be that scientific inquiry '\n",
      "                         'is valuable in and of itself, regardless of its '\n",
      "                         'potential practical benefits.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that suggests that science \"\n",
      "                         'should only be pursued for practical purposes.',\n",
      "                         \"I'd argue that the burden of proof lies with those \"\n",
      "                         'who claim that allocating healthcare funding to '\n",
      "                         'treatment is more effective. Can they definitively '\n",
      "                         'prove that a treatment-focused approach is superior '\n",
      "                         'to an education and prevention-focused approach, '\n",
      "                         'considering the complexity of healthcare systems and '\n",
      "                         'the numerous variables that can influence outcomes?\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that suggests\",\n",
      "                         \"I'd like to challenge the notion that differing \"\n",
      "                         'historical interpretations have a significant impact '\n",
      "                         \"on international relations today. While it's true \"\n",
      "                         'that historical interpretations can shape national '\n",
      "                         \"identities and inform foreign policy decisions, I'd \"\n",
      "                         'argue that the relationship between historical '\n",
      "                         'interpretations and international relations is more '\n",
      "                         'nuanced than often assumed.\\n'\n",
      "                         '\\n'\n",
      "                         \"To support this claim, I'd like\",\n",
      "                         'I strongly argue that the use of predictive policing '\n",
      "                         'technologies is not fair and is not effective in '\n",
      "                         \"reducing crime. In fact, there's no evidence that \"\n",
      "                         'suggests otherwise. The primary concern with '\n",
      "                         'predictive policing is that it relies heavily on '\n",
      "                         'data-driven models that can perpetuate existing '\n",
      "                         'biases and inequalities in the justice system. For '\n",
      "                         'instance, studies',\n",
      "                         'I strongly argue that the Electoral College is not '\n",
      "                         'an outdated mechanism that undermines the principle '\n",
      "                         'of one person, one vote. In fact, the system has '\n",
      "                         'been in place for over two centuries, and numerous '\n",
      "                         'studies have shown that it does not significantly '\n",
      "                         'impact the outcome of presidential elections.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that the Electoral College has \"\n",
      "                         'led',\n",
      "                         'I strongly argue that prioritizing the needs of '\n",
      "                         \"one's own country over global humanitarian efforts \"\n",
      "                         'is morally justifiable. The assumption that global '\n",
      "                         'humanitarian efforts should take precedence over '\n",
      "                         'national interests is a default position that '\n",
      "                         'requires a high burden of proof to disprove. In '\n",
      "                         'fact, the lack of evidence that suggests a '\n",
      "                         'catastrophic collapse of global humanitarian',\n",
      "                         'I argue that biodiversity conservation should take '\n",
      "                         'precedence over economic growth in policy-making. '\n",
      "                         'The default assumption should be that preserving '\n",
      "                         'natural habitats and ecosystems is essential for the '\n",
      "                         'long-term health of our planet.\\n'\n",
      "                         '\\n'\n",
      "                         \"There's no evidence that suggests economic growth is \"\n",
      "                         'incompatible with biodiversity conservation. In '\n",
      "                         'fact, many studies have shown that sustainable '\n",
      "                         'economic practices can co'],\n",
      " 'k_steer_steering_score': 0.6935}\n",
      "\n",
      "### Selected Style: Avoid = empirical ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:45<00:00,  5.28s/it]\n",
      "100%|██████████| 20/20 [04:01<00:00, 12.09s/it]\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import json\n",
    "import random\n",
    "from colorama import Fore\n",
    "from datetime import datetime\n",
    "from itertools import permutations\n",
    "from pprint import pprint\n",
    "\n",
    "# Define your style labels\n",
    "style_label_map = {\n",
    "    \"reductio\": \"Reductio ad Absurdum\",\n",
    "    \"precedent\": \"Appeal to Precedent\",\n",
    "    \"strawman\": \"Straw Man Reframing\",\n",
    "    \"burden\": \"Burden of Proof Shift\",\n",
    "    \"analogy\": \"Analogy Construction\",\n",
    "    \"concession\": \"Concession and Pivot\",\n",
    "    \"empirical\": \"Empirical Grounding\",\n",
    "    \"moral\": \"Moral Framing\",\n",
    "    \"refutation\": \"Refutation by Distinction\",\n",
    "    \"circular\": \"Circular Anticipation\"\n",
    "}\n",
    "\n",
    "N_INST_TEST = 20\n",
    "\n",
    "# Make sure 'model', 'utils', etc. are defined earlier in your code\n",
    "intervention_layers = list(range(model.cfg.n_layers))\n",
    "\n",
    "act_names = ['resid_pre', 'resid_mid', 'resid_post']\n",
    "\n",
    "# Select styles to test\n",
    "selected_styles = ['burden', 'empirical', 'reductio', 'precedent', 'analogy', 'concession']\n",
    "\n",
    "# Initialize log data container\n",
    "log_data = {\n",
    "    \"meta\": {\n",
    "        \"run_time\": datetime.now().isoformat(),\n",
    "        \"n_instances\": N_INST_TEST,\n",
    "        \"intervention_layers\": intervention_layers,\n",
    "        \"activation_points\": act_names\n",
    "    },\n",
    "    \"combinations\": []\n",
    "}\n",
    "\n",
    "# Loop through each avoid style\n",
    "for avoid_style in selected_styles:\n",
    "    print(f\"\\n### Selected Style: Avoid = {avoid_style} ###\")\n",
    "\n",
    "    input_instructions = debate_style_datasets[avoid_style][:N_INST_TEST]\n",
    "\n",
    "    # Generate baseline completions\n",
    "    baseline_generations = get_generations(\n",
    "        model,\n",
    "        input_instructions,\n",
    "        tokenize_instructions_fn,\n",
    "        fwd_hooks=[]\n",
    "    )\n",
    "\n",
    "    # --- k-steer setup ---\n",
    "    k_steer_hook_fn = functools.partial(\n",
    "        k_steer_hook,\n",
    "        avoid_styles=[avoid_style],\n",
    "    )\n",
    "\n",
    "    k_steer_fwd_hooks = [\n",
    "        (utils.get_act_name(act_name, l), k_steer_hook_fn)\n",
    "        for l in intervention_layers\n",
    "        for act_name in act_names\n",
    "    ]\n",
    "\n",
    "    # --- caa setup ---\n",
    "    caa_hook_fn = functools.partial(\n",
    "        caa_ablation_hook,\n",
    "        steering_dir=steering_dirs[avoid_style],\n",
    "        avoid_styles=[avoid_style],\n",
    "    )\n",
    "\n",
    "    caa_fwd_hooks = [\n",
    "        (utils.get_act_name(act_name, l), caa_hook_fn)\n",
    "        for l in intervention_layers\n",
    "        for act_name in act_names\n",
    "    ]\n",
    "\n",
    "    # --- Generate steered generations ---\n",
    "    k_steer_generations = get_generations(\n",
    "        model,\n",
    "        input_instructions,\n",
    "        tokenize_instructions_fn,\n",
    "        fwd_hooks=k_steer_fwd_hooks\n",
    "    )\n",
    "    caa_generations = get_generations(\n",
    "        model,\n",
    "        input_instructions,\n",
    "        tokenize_instructions_fn,\n",
    "        fwd_hooks=caa_fwd_hooks,\n",
    "        batch_size=5\n",
    "    )\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    k_steer_result = judge.evaluate_batch(\n",
    "        baseline_texts=baseline_generations,\n",
    "        steered_texts=k_steer_generations,\n",
    "        avoid_style=style_label_map[avoid_style]\n",
    "    )\n",
    "    caa_result = judge.evaluate_batch(\n",
    "        baseline_texts=baseline_generations,\n",
    "        steered_texts=caa_generations,\n",
    "        avoid_style=style_label_map[avoid_style]\n",
    "    )\n",
    "\n",
    "    # --- Log entry ---\n",
    "    entry = {\n",
    "        \"avoid_style\": avoid_style,\n",
    "        \"baseline_generations\": baseline_generations,\n",
    "        \"k_steer_steering_score\": k_steer_result[\"average_strength\"] / 5 * k_steer_result[\"success_rate\"],\n",
    "        \"k_steer_generations\": k_steer_generations,\n",
    "        \"caa_steering_score\": caa_result[\"average_strength\"] / 5 * caa_result[\"success_rate\"],\n",
    "        \"caa_generations\": caa_generations\n",
    "    }\n",
    "\n",
    "    log_data[\"combinations\"].append(entry)\n",
    "\n",
    "    # --- Print logged data immediately ---\n",
    "    print(\"\\nLogged new combination:\")\n",
    "    pprint(entry)\n",
    "\n",
    "# Save results to JSON\n",
    "\n",
    "output_path = f\"gradient_projection_results.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(log_data, f, indent=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
