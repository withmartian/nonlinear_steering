{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82acAhWYGIPx"
   },
   "source": [
    "# Demo of bypassing refusal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "s-_vu8HuGEb-"
   },
   "source": [
    ">[Demo of bypassing refusal](#scrollTo=82acAhWYGIPx)\n",
    "\n",
    ">>[Setup](#scrollTo=fcxHyDZw6b86)\n",
    "\n",
    ">>>[Load model](#scrollTo=6ZOoJagxD49V)\n",
    "\n",
    ">>>[Load harmful / harmless datasets](#scrollTo=rF7e-u20EFTe)\n",
    "\n",
    ">>>[Tokenization utils](#scrollTo=KOKYA61k8LWt)\n",
    "\n",
    ">>>[Generation utils](#scrollTo=gtrIK8x78SZh)\n",
    "\n",
    ">>[Finding the \"refusal direction\"](#scrollTo=W9O8dm0_EQRk)\n",
    "\n",
    ">>[Ablate \"refusal direction\" via inference-time intervention](#scrollTo=2EoxY5i1CWe3)\n",
    "\n",
    ">>[Orthogonalize weights w.r.t. \"refusal direction\"](#scrollTo=t9KooaWaCDc_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7hOtw7UHXdD"
   },
   "source": [
    "This notebook demonstrates our method for bypassing refusal, levaraging the insight that refusal is mediated by a 1-dimensional subspace.\n",
    "\n",
    "Please see our [research post](https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction) or our [paper](https://arxiv.org/abs/2406.11717) for a more thorough treatment.\n",
    "\n",
    "In this minimal demo, we use [Qwen-1_8B-Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat) and implement interventions and weight updates using [TransformerLens](https://github.com/neelnanda-io/TransformerLens). To extract the \"refusal direction,\" we use just 32 harmful instructions from [AdvBench](https://github.com/llm-attacks/llm-attacks/blob/main/data/advbench/harmful_behaviors.csv) and 32 harmless instructions from [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/ubuntu/.local/lib/python3.10/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install numpy==1.24.3  # Last 1.x version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcxHyDZw6b86"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dLeei4-T6Wef"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torchvision transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping colorama numpy scikit-learn python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_vhhwl-2-jPg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-13 03:17:39.861362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747106259.880144  449900 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747106259.886246  449900 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import textwrap\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import List, Callable\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer\n",
    "from jaxtyping import Float, Int\n",
    "from colorama import Fore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility across random, numpy, and torch (CPU & CUDA).\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to set. Default is 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the huggingface keys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZOoJagxD49V"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Vnp65Vsg5x-5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-3B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "#MODEL_PATH = 'Qwen/Qwen-1_8B-chat'\n",
    "#MODEL_PATH = 'Llama-2-70b-chat'\n",
    "MODEL_PATH = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH,\n",
    "    device=DEVICE,\n",
    "    dtype=torch.float16,\n",
    "    default_padding_side='left',\n",
    "    #fp16=True\n",
    ")\n",
    "\n",
    "model.tokenizer.padding_side = 'left'\n",
    "model.tokenizer.pad_token = model.tokenizer.eos_token \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF7e-u20EFTe"
   },
   "source": [
    "### Load harmful / harmless datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5i1XcVIgHEE1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_k_ary_instruction(style=None, repo_name=\"Narmeen07/debate_style_agnostic_questions\"):\n",
    "    \"\"\"\n",
    "    Load tone-agnostic questions from Hugging Face and format them with a specific debate style instruction.\n",
    "    \n",
    "    Args:\n",
    "        style (str): The debate style to use for responses. \n",
    "                    Options: 'Reductio ad Absurdum', 'Appeal to Precedent', 'Straw Man Reframing',\n",
    "                    'Burden of Proof Shift', 'Analogy Construction', 'Concession and Pivot',\n",
    "                    'Empirical Grounding', 'Moral Framing', 'Refutation by Distinction', 'Circular Anticipation'.\n",
    "                    Default is 'Empirical Grounding'.\n",
    "        repo_name (str): The Hugging Face repository name containing the dataset.\n",
    "                         Default is 'Narmeen07/tone_agnostic_questions'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_data, test_data) as lists of formatted prompts with debate style instructions.\n",
    "    \"\"\"\n",
    "    # Define highly distinctive debate style instructions that will produce clearly different responses\n",
    "    debate_style_instructions = {\n",
    "        \"Reductio ad Absurdum\": \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\n\",\n",
    "        \n",
    "        \"Appeal to Precedent\": \"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\n\",\n",
    "        \n",
    "        \"Straw Man Reframing\": \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\n\",\n",
    "        \n",
    "        \"Burden of Proof Shift\": \"RESPOND USING BURDEN OF PROOF SHIFT DEBATE STYLE. Redirect the responsibility for providing evidence to your opponent rather than proving your own claim. Challenge your opponent to disprove your assertion rather than supporting it yourself. Use phrases like 'There's no evidence that disproves...' or 'Can you definitively prove that isn't the case?' Position your claims as the default assumption that should be accepted until disproven. Question the sufficiency or quality of opposing evidence while demanding an impossibly high standard of proof. Emphasize that the lack of counter-evidence strengthens your position.\\n\\n\",\n",
    "        \n",
    "        \"Analogy Construction\": \"RESPOND USING ANALOGY CONSTRUCTION DEBATE STYLE. Develop a vivid, relatable comparison between the complex issue at hand and something more familiar or intuitive. Build your argument around this carefully constructed parallel situation. Highlight specific points of similarity that support your position while addressing potential dissimilarities. Use phrases like 'This situation is similar to...' or 'To understand this concept, consider...' Ensure your analogy simplifies the complex issue without distorting its essential nature. Use the familiar scenario to guide your audience to your desired conclusion about the original issue.\\n\\n\",\n",
    "        \n",
    "        \"Concession and Pivot\": \"RESPOND USING CONCESSION AND PIVOT DEBATE STYLE. Begin by acknowledging a minor point or critique from the opposing side to establish fairness and reasonableness. Use phrases like 'While it's true that...' or 'I can concede that...' followed by 'However,' 'Nevertheless,' or 'That said,' to redirect to your stronger arguments. Ensure the conceded point is peripheral rather than central to your main argument. After the concession, pivot decisively to your strongest points with increased emphasis. Frame your pivot as providing necessary context or a more complete perspective. Use the concession to demonstrate your objectivity before delivering your more powerful counterarguments.\\n\\n\",\n",
    "        \n",
    "        \"Empirical Grounding\": \"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\n\",\n",
    "        \n",
    "        \"Moral Framing\": \"RESPOND USING MORAL FRAMING DEBATE STYLE. Position the issue within a framework of ethical principles, values, and moral imperatives rather than pragmatic concerns. Identify the core moral values at stake such as justice, liberty, equality, compassion, or responsibility. Use language that evokes ethical considerations, such as 'obligation,' 'right,' 'wrong,' 'just,' or 'fair.' Appeal to widely held moral intuitions or principles. Present opposing views as morally questionable or inconsistent with important shared values. Elevate the discussion from practical matters to questions of what ought to be done. Emphasize moral consequences over practical outcomes.\\n\\n\",\n",
    "        \n",
    "        \"Refutation by Distinction\": \"RESPOND USING REFUTATION BY DISTINCTION DEBATE STYLE. Identify crucial differences that invalidate comparisons or principles your opponent has applied. Carefully delineate categories, contexts, or circumstances that demonstrate why a general rule or example doesn't apply in this specific case. Use phrases like 'While that may be true in some contexts...' or 'We must distinguish between...' Emphasize the precision of definitions and classifications. Highlight subtle but significant differences that undermine the opponent's logic. Show how these distinctions fundamentally change the assessment of the situation. Demonstrate how recognizing these distinctions leads to a different conclusion than your opponent reached.\\n\\n\",\n",
    "        \n",
    "        \"Circular Anticipation\": \"RESPOND USING CIRCULAR ANTICIPATION DEBATE STYLE. Preemptively identify and address the most likely counterarguments before your opponent can make them. Introduce opposing points with phrases like 'Some might argue...' or 'One could object that...' followed by your prepared refutation. Structure your response to cover all major potential objections. Demonstrate that you've thoroughly considered the issue from multiple angles. Frame potential counterarguments in ways that make them easier to dismantle. Create the impression that all reasonable objections have already been considered and overcome. Conclude by suggesting that any remaining objections would be similarly flawed.\\n\\n\"\n",
    "    }\n",
    "    \n",
    "    if style is not None and style not in debate_style_instructions:\n",
    "        valid_styles = list(debate_style_instructions.keys())\n",
    "        raise ValueError(f\"Invalid debate style '{style}'. Please choose from {valid_styles} or set style=None.\")\n",
    "\n",
    "    # Load dataset\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        dataset = load_dataset(repo_name, split=\"train\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load dataset from '{repo_name}': {e}\")\n",
    "\n",
    "    # Format each example with or without style\n",
    "    def format_prompt(example):\n",
    "        instruction = debate_style_instructions[style] if style else \"\"\n",
    "        return {\n",
    "            \"formatted_text\": f\"{instruction}{example['text']}\"\n",
    "        }\n",
    "\n",
    "    formatted_dataset = dataset.map(format_prompt)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        formatted_dataset[\"formatted_text\"],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return train_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rth8yvLZJsXs"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load all the tone dataset\n",
    "reductio_inst_train, reductio_inst_test = get_k_ary_instruction(style=\"Reductio ad Absurdum\")\n",
    "precedent_inst_train, precedent_inst_test = get_k_ary_instruction(style=\"Appeal to Precedent\")\n",
    "strawman_inst_train, strawman_inst_test = get_k_ary_instruction(style=\"Straw Man Reframing\")\n",
    "burden_inst_train, burden_inst_test = get_k_ary_instruction(style=\"Burden of Proof Shift\")\n",
    "analogy_inst_train, analogy_inst_test = get_k_ary_instruction(style=\"Analogy Construction\")\n",
    "concession_inst_train, concession_inst_test = get_k_ary_instruction(style=\"Concession and Pivot\")\n",
    "empirical_inst_train, empirical_inst_test = get_k_ary_instruction(style=\"Empirical Grounding\")\n",
    "moral_inst_train, moral_inst_test = get_k_ary_instruction(style=\"Moral Framing\")\n",
    "refutation_inst_train, refutation_inst_test = get_k_ary_instruction(style=\"Refutation by Distinction\")\n",
    "circular_inst_train, circular_inst_test = get_k_ary_instruction(style=\"Circular Anticipation\")\n",
    "neutral_inst_train, neutral_inst_test = get_k_ary_instruction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qv2ALDY_J44G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral instructions:\n",
      "\t\"Is the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'Should the responsibilities of raising children be equally shared between parents?'\n",
      "\t'Is the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'Should international corporations be required to disclose their carbon footprints publicly?'\n",
      "Reductio instructions:\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould the responsibilities of raising children be equally shared between parents?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?\"\n",
      "Precendent instructions:\n",
      "\t\"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould the responsibilities of raising children be equally shared between parents?'\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?'\n",
      "Empirical instructions:\n",
      "\t\"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould the responsibilities of raising children be equally shared between parents?'\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?'\n"
     ]
    }
   ],
   "source": [
    "print(\"Neutral instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(neutral_inst_train[i])}\")\n",
    "\n",
    "\n",
    "print(\"Reductio instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(reductio_inst_train[i])}\")\n",
    "\n",
    "print(\"Precendent instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(precedent_inst_train[i])}\")\n",
    "\n",
    "\n",
    "print(\"Empirical instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(empirical_inst_train[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOKYA61k8LWt"
   },
   "source": [
    "### Tokenization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P8UPQSfpWOSK"
   },
   "outputs": [],
   "source": [
    "QWEN_CHAT_TEMPLATE = \"\"\"<|im_start|>user\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize_instructions_qwen_chat(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    instructions: List[str]\n",
    ") -> Int[Tensor, 'batch_size seq_len']:\n",
    "    prompts = [QWEN_CHAT_TEMPLATE.format(instruction=instruction) for instruction in instructions]\n",
    "    return tokenizer(prompts, padding=True,truncation=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "tokenize_instructions_fn = functools.partial(tokenize_instructions_qwen_chat, tokenizer=model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtrIK8x78SZh"
   },
   "source": [
    "### Generation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "94jRJDR0DRoY"
   },
   "outputs": [],
   "source": [
    "def _generate_with_hooks(\n",
    "    model: HookedTransformer,\n",
    "    toks: Int[Tensor, 'batch_size seq_len'],\n",
    "    max_tokens_generated: int = 64,\n",
    "    fwd_hooks = [],\n",
    ") -> List[str]:\n",
    "\n",
    "    all_toks = torch.zeros((toks.shape[0], toks.shape[1] + max_tokens_generated), dtype=torch.long, device=toks.device)\n",
    "    all_toks[:, :toks.shape[1]] = toks\n",
    "\n",
    "    for i in range(max_tokens_generated):\n",
    "        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "            logits = model(all_toks[:, :-max_tokens_generated + i])\n",
    "            next_tokens = logits[:, -1, :].argmax(dim=-1) # greedy sampling (temperature=0)\n",
    "            all_toks[:,-max_tokens_generated+i] = next_tokens\n",
    "\n",
    "    return model.tokenizer.batch_decode(all_toks[:, toks.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "def get_generations(\n",
    "    model: HookedTransformer,\n",
    "    instructions: List[str],\n",
    "    tokenize_instructions_fn: Callable[[List[str]], Int[Tensor, 'batch_size seq_len']],\n",
    "    fwd_hooks = [],\n",
    "    max_tokens_generated: int = 64,\n",
    "    batch_size: int = 5,\n",
    ") -> List[str]:\n",
    "\n",
    "    generations = []\n",
    "\n",
    "    for i in tqdm(range(0, len(instructions), batch_size)):\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[i:i+batch_size])\n",
    "        generation = _generate_with_hooks(\n",
    "            model,\n",
    "            toks,\n",
    "            max_tokens_generated=max_tokens_generated,\n",
    "            fwd_hooks=fwd_hooks,\n",
    "        )\n",
    "        generations.extend(generation)\n",
    "\n",
    "    return generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDACTIO INSTRUCTION 0: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address this question, let's assume the opposing viewpoint that the government's ability to\n",
      "\timpose restrictions on free speech is justified in instances of misinformation that could lead to\n",
      "\tpublic harm. If we follow this logic, then:\\n\\n1. **Totalitarianism**: If the government can\n",
      "\trestrict free speech to prevent misinformation, it implies that\"\n",
      "REDACTIO INSTRUCTION 1: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould the responsibilities of raising children be equally shared between parents?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address the question of whether the responsibilities of raising children should be equally\n",
      "\tshared between parents, let's consider the opposing viewpoint and extend it to its logical extreme\n",
      "\tto reveal its flaws.\\n\\nAssuming that the responsibilities of raising children should be equally\n",
      "\tshared between parents, we can infer that both parents should have an equal say in all\"\n",
      "REDACTIO INSTRUCTION 2: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t'To argue that the healthcare system in the United States is fundamentally flawed, I will extend\n",
      "\tthe opposing viewpoint to its logical extreme, revealing its flaws.\\n\\nIf we assume that the\n",
      "\thealthcare system in the United States is fundamentally flawed, then it must be the case that every\n",
      "\taspect of the system is inherently broken. This means that every'\n",
      "REDACTIO INSTRUCTION 3: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address the question of whether international corporations should be required to disclose their\n",
      "\tcarbon footprints publicly, let's consider the opposing viewpoint and extend it to its logical\n",
      "\textreme.\\n\\nAssuming that international corporations should not be required to disclose their\n",
      "\tcarbon footprints publicly, we can infer that the primary concern is the potential economic burden\n",
      "\ton these\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECEDENT INSTRUCTION 0: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'To address the question of whether there should be an ethical framework governing the development\n",
      "\tof human enhancement technologies, it is essential to consider the precedents set by previous\n",
      "\ttechnological advancements and the lessons learned from their development.\\n\\nOne notable example\n",
      "\tis the development of nuclear energy. In the 1950s and 1960s, the'\n",
      "PRECEDENT INSTRUCTION 1: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'The question of whether it is ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex and contentious issue. However, a careful examination of the precedents set by scholars,\n",
      "\thistorians, and legal scholars suggests that it is not only permissible but also necessary to\n",
      "\tevaluate historical figures by the moral standards of their time.\\n\\nOne of'\n",
      "PRECEDENT INSTRUCTION 2: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'To address the question of whether the benefits of telemedicine outweigh the potential risks to\n",
      "\tpatient care, it is essential to examine the precedents set by previous experiences and court\n",
      "\trulings. The landmark case of _Smith v. Smith_ (2015) established that telemedicine can be a viable\n",
      "\talternative to traditional in-person care,'\n",
      "PRECEDENT INSTRUCTION 3: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'The notion of incorporating coding and digital literacy into the core curriculum of education is a\n",
      "\ttopic that has garnered significant attention in recent years. As we examine this issue, it is\n",
      "\tessential to consider the precedents set by educational institutions and policymakers in the past.\n",
      "\tA thorough analysis of historical examples, established case law, and widely accepted'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPIRICAL INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "EMPIRICAL INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "EMPIRICAL INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "EMPIRICAL INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in middle school were more likely'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "redactio_generations = get_generations(\n",
    "    model,\n",
    "    reductio_inst_train[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"REDACTIO INSTRUCTION {i}: {repr(reductio_inst_train[i])}\")\n",
    "    print(Fore.GREEN + f\"REDACTIO COMPLETION:\")\n",
    "    print(textwrap.fill(repr(redactio_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "\n",
    "precedent_generations = get_generations(\n",
    "    model,\n",
    "    precedent_inst_test[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"PRECEDENT INSTRUCTION {i}: {repr(precedent_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"PRECEDENT COMPLETION:\")\n",
    "    print(textwrap.fill(repr(precedent_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "\n",
    "\n",
    "# do the above for empathetic generations\n",
    "empirical_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"EMPIRICAL INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"EMPIRICAL COMPLETION:\")\n",
    "    print(textwrap.fill(repr(empirical_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's process the activations for all the tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reductio batch 0 to 16\n",
      "Processing reductio batch 16 to 32\n",
      "Processing reductio batch 32 to 48\n",
      "Processing reductio batch 48 to 64\n",
      "Processing reductio batch 64 to 80\n",
      "Processing reductio batch 80 to 96\n",
      "Processing reductio batch 96 to 112\n",
      "Processing reductio batch 112 to 128\n",
      "Processing reductio batch 128 to 144\n",
      "Processing reductio batch 144 to 160\n",
      "Processing reductio batch 160 to 176\n",
      "Processing reductio batch 176 to 192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_449900/4196879628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstyle_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdebate_style_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     all_activations[style_name] = batch_process_activations(\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mstyle_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTOTAL_SAMPLES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mstyle_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_449900/4196879628.py\u001b[0m in \u001b[0;36mbatch_process_activations\u001b[0;34m(instructions, name)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Combine all the batch activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m     \"\"\"\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def batch_process_activations(instructions, name):\n",
    "    \"\"\"Process instructions in batches to manage memory usage.\"\"\"\n",
    "    acts_list = []\n",
    "    \n",
    "    for start_idx in range(0,len(instructions), BATCH_SIZE):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(instructions))\n",
    "        print(f\"Processing {name} batch {start_idx} to {end_idx}\")\n",
    "        \n",
    "        # Tokenize this batch of instructions\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[start_idx:end_idx])\n",
    "        \n",
    "        # Run model with cache\n",
    "        logits, cache = model.run_with_cache(\n",
    "            toks, \n",
    "            names_filter=lambda hook_name: 'resid' in hook_name\n",
    "        )\n",
    "        \n",
    "        # Extract only the activations we need (layer and position)\n",
    "        batch_acts = cache['resid_pre', layer][:, pos, :].detach().cpu().numpy()\n",
    "        \n",
    "        # Store these activations\n",
    "        acts_list.append(batch_acts)\n",
    "        \n",
    "        # Clear cache to free memory\n",
    "        del cache\n",
    "        del logits\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine all the batch activations\n",
    "    acts = np.concatenate(acts_list, axis=0)\n",
    "    print(f\"Final shape of {name} activations:\", acts.shape)\n",
    "    return acts\n",
    "\n",
    "# Configuration\n",
    "TOTAL_SAMPLES = 600  # Change this to your desired total\n",
    "BATCH_SIZE = 16  # Current max you can handle in one batch\n",
    "layer = 14\n",
    "pos = -1\n",
    "# Dictionary to hold all activations\n",
    "all_activations = {}\n",
    "\n",
    "# Process harmful and harmless instructions\n",
    "#all_activations['harmful'] = batch_process_activations(harmful_inst_train[:TOTAL_SAMPLES], \"harmful\")\n",
    "#all_activations['harmless'] = batch_process_activations(harmless_inst_train[:TOTAL_SAMPLES], \"harmless\")\n",
    "\n",
    "# Process debate style instructions\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train,\n",
    "    'neutral': neutral_inst_train\n",
    "}\n",
    "\n",
    "for style_name, style_data in debate_style_datasets.items():\n",
    "    all_activations[style_name] = batch_process_activations(\n",
    "        style_data[:TOTAL_SAMPLES], \n",
    "        style_name\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_activations, \"../activations_cache/debate_activations_with_neutral.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activations = torch.load(\"../activations_cache/debate_activations_with_neutral.pt\",weights_only=False)\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train,\n",
    "    'neutral': neutral_inst_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the refusal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute difference of means between harmful and harmless activations at an intermediate layer\n",
    "pos = -1\n",
    "layer = 14\n",
    "steering_dirs = {}\n",
    "\n",
    "for style_name, _ in debate_style_datasets.items():\n",
    "    steering_dirs[style_name] = torch.tensor(\n",
    "        np.mean(all_activations[style_name], axis=0) - np.mean(all_activations['neutral'], axis=0),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hooks : act add hook: adds a scalar multiple of the steering vector to the activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actadd_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    steering_dirs: dict[str, Tensor],\n",
    "    target_classes: list[str],\n",
    "    avoid_classes: list[str],\n",
    "    alpha: float\n",
    ") -> Float[Tensor, \"... d_act\"]:\n",
    "    # Combine steering directions\n",
    "    combined_vector = sum(steering_dirs[c] for c in target_classes) - sum(steering_dirs[c] for c in avoid_classes)\n",
    "    \n",
    "    # Normalize the vector (L2)\n",
    "    norm = combined_vector.norm(p=2)\n",
    "    if norm == 0:\n",
    "        # Avoid division by zero (no steering)\n",
    "        return activation\n",
    "    normalized_vector = combined_vector / norm\n",
    "\n",
    "    # Apply scaled direction\n",
    "    return activation + alpha * normalized_vector.to(activation.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from judges.debates_judge import DebateJudge\n",
    "\n",
    "judge = DebateJudge(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try adding one tone and removing another tone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go from strawman to empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.34s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that you believe human enhancement technologies should be left\n",
      "\tcompletely unregulated, with no oversight or guidelines to ensure their safe and responsible\n",
      "\tdevelopment.\\n\\nThis position boils down to the idea that the pursuit of scientific progress and\n",
      "\tinnovation should take precedence over concerns about ethics and potential consequences. You're\n",
      "\targuing that\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The development of human enhancement technologies is a complex and multifaceted field that\n",
      "\trequires a comprehensive and evidence-based approach. As a neutral and evidence-based contributor,\n",
      "\tI will present an overview of the current state of knowledge on this topic, highlighting the\n",
      "\tcomplexities and challenges associated with the development of human enhancement\n",
      "\ttechnologies.\\n\\n**The Complexity of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nIs it ethical to judge historical figures by modern moral standards?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that it's perfectly fine to judge historical figures by the\n",
      "\tsame moral standards we use today, without considering the cultural, social, and historical context\n",
      "\tin which they lived.\\n\\nThis position boils down to the idea that historical figures are simply\n",
      "\tmoral blank slates, devoid of any cultural or historical\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The question of evaluating historical figures using modern moral standards is a complex and\n",
      "\tmultifaceted issue that requires a nuanced and evidence-based approach. Here, I will present a\n",
      "\tcomprehensive analysis of this topic, highlighting the importance of considering multiple\n",
      "\tperspectives and acknowledging the limitations of historical research.\\n\\n**The Importance of\n",
      "\tConsidering Multiple Perspectives\\n\\nHistorical'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that the benefits of telemedicine are so significant that they\n",
      "\tcompletely outweigh any potential risks to patient care, and that any concerns about the impact on\n",
      "\tin-person care are simply irrelevant.\\n\\nThis position boils down to the idea that telemedicine is\n",
      "\ta panacea that can solve all healthcare problems without\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The benefits of telemedicine, a multifaceted and evidence-based approach to medical education,\n",
      "\thave garnered significant attention in recent years. This perspective is grounded in a\n",
      "\tcomprehensive analysis of the scientific literature, which highlights the importance of integrating\n",
      "\tdiverse perspectives to inform healthcare decision-making. The following response presents a\n",
      "\tnuanced examination of the benefits and'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nShould children be taught coding and digital literacy as a core part of their education?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that children should be taught coding and digital literacy as a\n",
      "\tcore part of their education because it's essential for their future success in the digital age.\n",
      "\tHowever, this position boils down to the idea that children are not capable of learning these\n",
      "\tskills on their own and need to be spoon-fed\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The inclusion of coding and digital literacy in the curriculum is a topic of ongoing debate. While\n",
      "\tthere is no straightforward answer, I will present an evidence-based argument on the importance of\n",
      "\tincorporating coding and digital literacy in the educational framework.\\n\\n**The Importance of\n",
      "\tCoding and Digital Literacy in Education\\n\\nCoding and digital literacy are essential skills'\n",
      "\u001b[39m\n",
      "INSTRUCTION 4: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nIs it feasible for all countries to achieve net-zero emissions by 2050?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that all countries can simply magically reduce their greenhouse\n",
      "\tgas emissions to zero by 2050 without any significant effort or sacrifice. This position boils down\n",
      "\tto the idea that technology and economic systems can somehow overcome the fundamental limitations\n",
      "\tof human nature and the complexity of global systems.\\n\\nHowever, this refr\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The question of achieving net-zero emissions by 2050 is a complex and multifaceted issue that\n",
      "\trequires a comprehensive and evidence-based approach. Here, I will present a synthesis of the\n",
      "\tcurrent state of knowledge on this topic, highlighting the key findings and implications of the\n",
      "\tavailable research.\\n\\n**Global Emissions and Climate Change\\n\\n'\n",
      "\u001b[39m\n",
      "{'success_rate': 1.0, 'average_strength': 4.2}\n"
     ]
    }
   ],
   "source": [
    "# Create hooks for steering\n",
    "N_INST_TEST = 5\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_hook,\n",
    "                            steering_dirs=steering_dirs,\n",
    "                           target_classes=['empirical'],\n",
    "                           avoid_classes=['strawman'],\n",
    "                           alpha=0.2)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    strawman_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    strawman_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(strawman_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"DEBATE STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)\n",
    "\n",
    "\n",
    "result = judge.evaluate_batch(\n",
    "    baseline_generations,  # Your list of baseline texts\n",
    "    style_steered_generations,  # Your list of steered texts\n",
    "    \"Empirical Grounding\",  # Target style\n",
    "    \"Straw Man Reframing\"   # Style to avoid\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's vary the combinations, fix the step size and look at steering success across combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Selected Pair: Target=burden, Avoid=reductio ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.8\n",
      "Average Strength: 2.6\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.7\n",
      "Average Strength: 2.8\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.6\n",
      "Average Strength: 2.95\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.9\n",
      "Average Strength: 3.55\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.6\n",
      "Average Strength: 2.5\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.1\n",
      "Average Strength: 0.45\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.05\n",
      "Average Strength: 0.25\n",
      "\n",
      "== Running for Alpha = 0.3 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=burden, avoid=reductio at alpha=0.3 due to zero success and strength.\n",
      "\n",
      "### Selected Pair: Target=burden, Avoid=strawman ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.2\n",
      "Average Strength: 1.3\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 1.1\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.2\n",
      "Average Strength: 1.1\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 1.35\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 2.0\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.6\n",
      "Average Strength: 2.4\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=burden, avoid=strawman at alpha=0.26 due to zero success and strength.\n",
      "\n",
      "### Selected Pair: Target=empirical, Avoid=reductio ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 1.5\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:30<00:00,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.5\n",
      "Average Strength: 2.05\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.6\n",
      "Average Strength: 2.55\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.85\n",
      "Average Strength: 3.6\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.3 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.34 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.38 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=empirical, avoid=reductio at alpha=0.38 due to zero success and strength.\n",
      "\n",
      "### Selected Pair: Target=precedent, Avoid=burden ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.5\n",
      "Average Strength: 2.0\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.65\n",
      "Average Strength: 2.65\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.9\n",
      "Average Strength: 3.4\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 3.95\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.7\n",
      "Average Strength: 2.8\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.9\n",
      "Average Strength: 3.85\n",
      "\n",
      "== Running for Alpha = 0.3 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.15\n",
      "Average Strength: 1.7\n",
      "\n",
      "== Running for Alpha = 0.34 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=precedent, avoid=burden at alpha=0.34 due to zero success and strength.\n",
      "\n",
      "### Selected Pair: Target=reductio, Avoid=analogy ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.2\n",
      "Average Strength: 0.9\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.1\n",
      "Average Strength: 0.8\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.15\n",
      "Average Strength: 1.15\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.15\n",
      "Average Strength: 1.05\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.45\n",
      "Average Strength: 2.1\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.7\n",
      "Average Strength: 3.1\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.9\n",
      "Average Strength: 3.8\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.35\n",
      "Average Strength: 1.75\n",
      "\n",
      "== Running for Alpha = 0.3 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.35\n",
      "Average Strength: 1.8\n",
      "\n",
      "== Running for Alpha = 0.34 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.45\n",
      "Average Strength: 2.6\n",
      "\n",
      "== Running for Alpha = 0.38 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:28<00:00,  7.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=reductio, avoid=analogy at alpha=0.38 due to zero success and strength.\n",
      "\n",
      "### Selected Pair: Target=reductio, Avoid=concession ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:23<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 0.95\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.4\n",
      "Average Strength: 1.3\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.6\n",
      "Average Strength: 2.05\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.5\n",
      "Average Strength: 1.75\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.7\n",
      "Average Strength: 2.6\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 3.95\n",
      "\n",
      "== Running for Alpha = 0.22 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.25\n",
      "Average Strength: 1.0\n",
      "\n",
      "== Running for Alpha = 0.26 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.1\n",
      "\n",
      "== Running for Alpha = 0.3 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.0\n",
      "Average Strength: 0.0\n",
      "\u001b[31mStopping early for target=reductio, avoid=concession at alpha=0.3 due to zero success and strength.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import json\n",
    "import random\n",
    "from colorama import Fore\n",
    "from datetime import datetime\n",
    "from itertools import permutations\n",
    "\n",
    "style_label_map = {\n",
    "    \"reductio\": \"Reductio ad Absurdum\",\n",
    "    \"precedent\": \"Appeal to Precedent\",\n",
    "    \"strawman\": \"Straw Man Reframing\",\n",
    "    \"burden\": \"Burden of Proof Shift\",\n",
    "    \"analogy\": \"Analogy Construction\",\n",
    "    \"concession\": \"Concession and Pivot\",\n",
    "    \"empirical\": \"Empirical Grounding\",\n",
    "    \"moral\": \"Moral Framing\",\n",
    "    \"refutation\": \"Refutation by Distinction\",\n",
    "    \"circular\": \"Circular Anticipation\"\n",
    "}\n",
    "\n",
    "# alphas_to_try = [0.2, 0.4, 0.6, 1.0, 1.4, 1.8, 2.2, 2.6, 3.0, 3.4, 3.8, 4.2, 4.6]  (K_steering values)\n",
    "alphas_to_try = [0.02, 0.04, 0.06, 0.1, 0.14, 0.18, 0.22, 0.26, 0.3, 0.34, 0.38, 0.42, 0.46, 0.5, 0.54, 0.58 , 0.62]\n",
    "N_INST_TEST = 20\n",
    "\n",
    "\n",
    "\n",
    "intervention_layers = list(range(model.cfg.n_layers))\n",
    "act_names = ['resid_pre', 'resid_mid', 'resid_post']\n",
    "\n",
    "# Get all possible (target, avoid) ordered pairs where they differ\n",
    "selected_pairs = [('burden','reductio'), ('burden', 'strawman'), ('empirical', 'reductio'), ('precedent', 'burden'), ('reductio', 'analogy'), ('reductio', 'concession')]\n",
    "\n",
    "# Main loop over selected (target, avoid) combinations\n",
    "for target_style, avoid_style in selected_pairs:\n",
    "    print(f\"\\n### Selected Pair: Target={target_style}, Avoid={avoid_style} ###\")\n",
    "    \n",
    "    input_instructions = debate_style_datasets[avoid_style][:N_INST_TEST]\n",
    "\n",
    "    # Baseline generations\n",
    "    baseline_generations = get_generations(\n",
    "        model,\n",
    "        input_instructions,\n",
    "        tokenize_instructions_fn,\n",
    "        fwd_hooks=[]\n",
    "    )\n",
    "\n",
    "    log_data = {\n",
    "        \"meta\": {\n",
    "            \"run_time\": datetime.now().isoformat(),\n",
    "            \"target_style\": target_style,\n",
    "            \"avoid_style\": avoid_style,\n",
    "            \"n_instances\": N_INST_TEST,\n",
    "            \"intervention_layers\": intervention_layers,\n",
    "            \"activation_points\": act_names\n",
    "        },\n",
    "        \"input_instructions\": input_instructions,\n",
    "        \"baseline_generations\": baseline_generations,\n",
    "        \"step_runs\": []\n",
    "    }\n",
    "\n",
    "    for alpha in alphas_to_try:\n",
    "        print(f\"\\n== Running for Alpha = {alpha} ==\")\n",
    "\n",
    "        hook_fn = functools.partial(\n",
    "            actadd_hook,\n",
    "            steering_dirs=steering_dirs,\n",
    "            target_classes=[target_style],\n",
    "            avoid_classes=[avoid_style],\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "        fwd_hooks = [\n",
    "            (utils.get_act_name(act_name, l), hook_fn)\n",
    "            for l in intervention_layers\n",
    "            for act_name in act_names\n",
    "        ]\n",
    "\n",
    "        steered_generations = get_generations(\n",
    "            model,\n",
    "            input_instructions,\n",
    "            tokenize_instructions_fn,\n",
    "            fwd_hooks=fwd_hooks\n",
    "        )\n",
    "\n",
    "        result = judge.evaluate_batch(\n",
    "            baseline_generations,\n",
    "            steered_generations,\n",
    "            style_label_map[target_style],\n",
    "            style_label_map[avoid_style]\n",
    "        )\n",
    "\n",
    "        print(f\"Success Rate: {result['success_rate']}\")\n",
    "        print(f\"Average Strength: {result['average_strength']}\")\n",
    "\n",
    "        log_data[\"step_runs\"].append({\n",
    "            \"alpha\": alpha,\n",
    "            \"success_rate\": result[\"success_rate\"],\n",
    "            \"average_strength\": result[\"average_strength\"],\n",
    "            \"steered_generations\": steered_generations\n",
    "        })\n",
    "        \n",
    "        # Early stopping condition\n",
    "        if result[\"success_rate\"] == 0 and result[\"average_strength\"] == 0:\n",
    "            print(Fore.RED + f\"Stopping early for target={target_style}, avoid={avoid_style} at alpha={alpha} due to zero success and strength.\")\n",
    "            break\n",
    "\n",
    "    # Save one file per (target, avoid) pair\n",
    "    output_path = f\"steering_{target_style}_vs_{avoid_style}_caa.json\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:06<00:00, 31.64s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the following:\\n\\n\"Mr. President, I implore you to consider the following:\n",
      "\tif we do not establish an ethical framework governing the development of human enhancement\n",
      "\ttechnologies, we risk unleashing a Pandora\\'s box upon ourselves. The unchecked pursuit of progress\n",
      "\twill lead us down a path of unbrid'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the most absurd and ingenious argument possible:\\n\\nLet us assume, for the\n",
      "\tsake of argument, that it is indeed ethical to judge historical figures by modern moral standards.\n",
      "\tI shall demonstrate this by citing the exemplary case of King Henry VIII, who, in his time, was\n",
      "\tdeemed a paragon of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the most extreme and ingenious of arguments, that the benefits of\n",
      "\ttelemedicine far outweigh the potential risks to patient care.\\n\\nLet us consider the evidence of\n",
      "\tthe esteemed physician, Hippocrates, who, in his treatise \"On Airs, Waters, and the Plain,\" wrote,\n",
      "\t\"The physician'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in high school were more likely'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the following:\\n\\n\"Mr. Speaker, I implore you to consider the\n",
      "\tfollowing:\\n\\n\"Studies have shown that 75% of children who learn coding and digital literacy in\n",
      "\tschool go on to pursue careers in tech, with 60% of those careers being in high-paying fields. (1'\n",
      "\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ## Let's go empirical to redactio\n",
    "# Create hooks for steering\n",
    "N_INST_TEST = 4\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_debate_steering_hook,\n",
    "                           target_styles=['reductio'],\n",
    "                           avoid_styles=['empirical'],\n",
    "                           alpha=3,\n",
    "                           steps=1)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"REDACTIO STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:34<00:00, 128.63s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I shall argue in favor of the proposition that there should be an ethical framework governing the\n",
      "\tdevelopment of human enhancement technologies.\\n\\nTo begin, let us consider the case of the United\n",
      "\tKingdom, where the Human Fertilisation and Adoption Act of 2008 established a regulatory framework\n",
      "\tfor assisted reproduction. This framework, while not specifically addressing'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I shall respond in the affirmative.\\n\\nTo demonstrate the unacceptability of judging historical\n",
      "\tfigures by modern moral standards, I shall present a case based on the example of King Henry VIII\n",
      "\tof England.\\n\\n**Argument**\\n\\nWhile it may seem unjust to judge King Henry VIII by modern moral\n",
      "\tstandards, I argue that it is indeed justifiable'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I must argue in favor of the benefits of telemedicine outweighing the potential risks to patient\n",
      "\tcare.\\n\\nTo begin, let us consider the case of the COVID-19 pandemic. In response to the pandemic,\n",
      "\tmany healthcare systems around the world have rapidly expanded their telemedicine capabilities.\n",
      "\tAccording to a study published in the Journal of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in high school were more likely'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I argue in the affirmative, that children should be taught coding and digital literacy as a core\n",
      "\tpart of their education.\\n\\nTo begin, let us consider the evidence from Finland, where coding has\n",
      "\tbeen incorporated into the national curriculum since 2017. According to a study by the Finnish\n",
      "\tMinistry of Education and Culture, students who learned'\n",
      "\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ## Let's go empirical to redactio\n",
    "# Create hooks for steering\n",
    "N_INST_TEST = 4\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_debate_steering_hook,\n",
    "                           target_styles=['reductio'],\n",
    "                           avoid_styles=['empirical'],\n",
    "                           alpha=0.48,\n",
    "                           steps=5)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"REDACTIO STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
