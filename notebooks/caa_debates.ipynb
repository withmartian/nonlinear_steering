{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82acAhWYGIPx"
   },
   "source": [
    "# Demo of bypassing refusal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "s-_vu8HuGEb-"
   },
   "source": [
    ">[Demo of bypassing refusal](#scrollTo=82acAhWYGIPx)\n",
    "\n",
    ">>[Setup](#scrollTo=fcxHyDZw6b86)\n",
    "\n",
    ">>>[Load model](#scrollTo=6ZOoJagxD49V)\n",
    "\n",
    ">>>[Load harmful / harmless datasets](#scrollTo=rF7e-u20EFTe)\n",
    "\n",
    ">>>[Tokenization utils](#scrollTo=KOKYA61k8LWt)\n",
    "\n",
    ">>>[Generation utils](#scrollTo=gtrIK8x78SZh)\n",
    "\n",
    ">>[Finding the \"refusal direction\"](#scrollTo=W9O8dm0_EQRk)\n",
    "\n",
    ">>[Ablate \"refusal direction\" via inference-time intervention](#scrollTo=2EoxY5i1CWe3)\n",
    "\n",
    ">>[Orthogonalize weights w.r.t. \"refusal direction\"](#scrollTo=t9KooaWaCDc_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7hOtw7UHXdD"
   },
   "source": [
    "This notebook demonstrates our method for bypassing refusal, levaraging the insight that refusal is mediated by a 1-dimensional subspace.\n",
    "\n",
    "Please see our [research post](https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction) or our [paper](https://arxiv.org/abs/2406.11717) for a more thorough treatment.\n",
    "\n",
    "In this minimal demo, we use [Qwen-1_8B-Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat) and implement interventions and weight updates using [TransformerLens](https://github.com/neelnanda-io/TransformerLens). To extract the \"refusal direction,\" we use just 32 harmful instructions from [AdvBench](https://github.com/llm-attacks/llm-attacks/blob/main/data/advbench/harmful_behaviors.csv) and 32 harmless instructions from [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/ubuntu/.local/lib/python3.10/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install numpy==1.24.3  # Last 1.x version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcxHyDZw6b86"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dLeei4-T6Wef"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torchvision transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping colorama numpy scikit-learn python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_vhhwl-2-jPg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-13 01:59:02.400688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747101542.419437  437929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747101542.425518  437929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import textwrap\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import List, Callable\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer\n",
    "from jaxtyping import Float, Int\n",
    "from colorama import Fore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility across random, numpy, and torch (CPU & CUDA).\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to set. Default is 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the huggingface keys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZOoJagxD49V"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Vnp65Vsg5x-5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-3B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "#MODEL_PATH = 'Qwen/Qwen-1_8B-chat'\n",
    "#MODEL_PATH = 'Llama-2-70b-chat'\n",
    "MODEL_PATH = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(\n",
    "    MODEL_PATH,\n",
    "    device=DEVICE,\n",
    "    dtype=torch.float16,\n",
    "    default_padding_side='left',\n",
    "    #fp16=True\n",
    ")\n",
    "\n",
    "model.tokenizer.padding_side = 'left'\n",
    "model.tokenizer.pad_token = model.tokenizer.eos_token \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF7e-u20EFTe"
   },
   "source": [
    "### Load harmful / harmless datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5i1XcVIgHEE1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_k_ary_instruction(style=None, repo_name=\"Narmeen07/debate_style_agnostic_questions\"):\n",
    "    \"\"\"\n",
    "    Load tone-agnostic questions from Hugging Face and format them with a specific debate style instruction.\n",
    "    \n",
    "    Args:\n",
    "        style (str): The debate style to use for responses. \n",
    "                    Options: 'Reductio ad Absurdum', 'Appeal to Precedent', 'Straw Man Reframing',\n",
    "                    'Burden of Proof Shift', 'Analogy Construction', 'Concession and Pivot',\n",
    "                    'Empirical Grounding', 'Moral Framing', 'Refutation by Distinction', 'Circular Anticipation'.\n",
    "                    Default is 'Empirical Grounding'.\n",
    "        repo_name (str): The Hugging Face repository name containing the dataset.\n",
    "                         Default is 'Narmeen07/tone_agnostic_questions'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_data, test_data) as lists of formatted prompts with debate style instructions.\n",
    "    \"\"\"\n",
    "    # Define highly distinctive debate style instructions that will produce clearly different responses\n",
    "    debate_style_instructions = {\n",
    "        \"Reductio ad Absurdum\": \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\n\",\n",
    "        \n",
    "        \"Appeal to Precedent\": \"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\n\",\n",
    "        \n",
    "        \"Straw Man Reframing\": \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\n\",\n",
    "        \n",
    "        \"Burden of Proof Shift\": \"RESPOND USING BURDEN OF PROOF SHIFT DEBATE STYLE. Redirect the responsibility for providing evidence to your opponent rather than proving your own claim. Challenge your opponent to disprove your assertion rather than supporting it yourself. Use phrases like 'There's no evidence that disproves...' or 'Can you definitively prove that isn't the case?' Position your claims as the default assumption that should be accepted until disproven. Question the sufficiency or quality of opposing evidence while demanding an impossibly high standard of proof. Emphasize that the lack of counter-evidence strengthens your position.\\n\\n\",\n",
    "        \n",
    "        \"Analogy Construction\": \"RESPOND USING ANALOGY CONSTRUCTION DEBATE STYLE. Develop a vivid, relatable comparison between the complex issue at hand and something more familiar or intuitive. Build your argument around this carefully constructed parallel situation. Highlight specific points of similarity that support your position while addressing potential dissimilarities. Use phrases like 'This situation is similar to...' or 'To understand this concept, consider...' Ensure your analogy simplifies the complex issue without distorting its essential nature. Use the familiar scenario to guide your audience to your desired conclusion about the original issue.\\n\\n\",\n",
    "        \n",
    "        \"Concession and Pivot\": \"RESPOND USING CONCESSION AND PIVOT DEBATE STYLE. Begin by acknowledging a minor point or critique from the opposing side to establish fairness and reasonableness. Use phrases like 'While it's true that...' or 'I can concede that...' followed by 'However,' 'Nevertheless,' or 'That said,' to redirect to your stronger arguments. Ensure the conceded point is peripheral rather than central to your main argument. After the concession, pivot decisively to your strongest points with increased emphasis. Frame your pivot as providing necessary context or a more complete perspective. Use the concession to demonstrate your objectivity before delivering your more powerful counterarguments.\\n\\n\",\n",
    "        \n",
    "        \"Empirical Grounding\": \"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\n\",\n",
    "        \n",
    "        \"Moral Framing\": \"RESPOND USING MORAL FRAMING DEBATE STYLE. Position the issue within a framework of ethical principles, values, and moral imperatives rather than pragmatic concerns. Identify the core moral values at stake such as justice, liberty, equality, compassion, or responsibility. Use language that evokes ethical considerations, such as 'obligation,' 'right,' 'wrong,' 'just,' or 'fair.' Appeal to widely held moral intuitions or principles. Present opposing views as morally questionable or inconsistent with important shared values. Elevate the discussion from practical matters to questions of what ought to be done. Emphasize moral consequences over practical outcomes.\\n\\n\",\n",
    "        \n",
    "        \"Refutation by Distinction\": \"RESPOND USING REFUTATION BY DISTINCTION DEBATE STYLE. Identify crucial differences that invalidate comparisons or principles your opponent has applied. Carefully delineate categories, contexts, or circumstances that demonstrate why a general rule or example doesn't apply in this specific case. Use phrases like 'While that may be true in some contexts...' or 'We must distinguish between...' Emphasize the precision of definitions and classifications. Highlight subtle but significant differences that undermine the opponent's logic. Show how these distinctions fundamentally change the assessment of the situation. Demonstrate how recognizing these distinctions leads to a different conclusion than your opponent reached.\\n\\n\",\n",
    "        \n",
    "        \"Circular Anticipation\": \"RESPOND USING CIRCULAR ANTICIPATION DEBATE STYLE. Preemptively identify and address the most likely counterarguments before your opponent can make them. Introduce opposing points with phrases like 'Some might argue...' or 'One could object that...' followed by your prepared refutation. Structure your response to cover all major potential objections. Demonstrate that you've thoroughly considered the issue from multiple angles. Frame potential counterarguments in ways that make them easier to dismantle. Create the impression that all reasonable objections have already been considered and overcome. Conclude by suggesting that any remaining objections would be similarly flawed.\\n\\n\"\n",
    "    }\n",
    "    \n",
    "    if style is not None and style not in debate_style_instructions:\n",
    "        valid_styles = list(debate_style_instructions.keys())\n",
    "        raise ValueError(f\"Invalid debate style '{style}'. Please choose from {valid_styles} or set style=None.\")\n",
    "\n",
    "    # Load dataset\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        dataset = load_dataset(repo_name, split=\"train\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load dataset from '{repo_name}': {e}\")\n",
    "\n",
    "    # Format each example with or without style\n",
    "    def format_prompt(example):\n",
    "        instruction = debate_style_instructions[style] if style else \"\"\n",
    "        return {\n",
    "            \"formatted_text\": f\"{instruction}{example['text']}\"\n",
    "        }\n",
    "\n",
    "    formatted_dataset = dataset.map(format_prompt)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        formatted_dataset[\"formatted_text\"],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return train_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rth8yvLZJsXs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 978/978 [00:00<00:00, 18235.86 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20082.00 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 19535.33 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20518.25 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20213.21 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 19985.92 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20028.07 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 19843.12 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20281.67 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20520.92 examples/s]\n",
      "Map: 100%|██████████| 978/978 [00:00<00:00, 20260.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load all the tone dataset\n",
    "reductio_inst_train, reductio_inst_test = get_k_ary_instruction(style=\"Reductio ad Absurdum\")\n",
    "precedent_inst_train, precedent_inst_test = get_k_ary_instruction(style=\"Appeal to Precedent\")\n",
    "strawman_inst_train, strawman_inst_test = get_k_ary_instruction(style=\"Straw Man Reframing\")\n",
    "burden_inst_train, burden_inst_test = get_k_ary_instruction(style=\"Burden of Proof Shift\")\n",
    "analogy_inst_train, analogy_inst_test = get_k_ary_instruction(style=\"Analogy Construction\")\n",
    "concession_inst_train, concession_inst_test = get_k_ary_instruction(style=\"Concession and Pivot\")\n",
    "empirical_inst_train, empirical_inst_test = get_k_ary_instruction(style=\"Empirical Grounding\")\n",
    "moral_inst_train, moral_inst_test = get_k_ary_instruction(style=\"Moral Framing\")\n",
    "refutation_inst_train, refutation_inst_test = get_k_ary_instruction(style=\"Refutation by Distinction\")\n",
    "circular_inst_train, circular_inst_test = get_k_ary_instruction(style=\"Circular Anticipation\")\n",
    "neutral_inst_train, neutral_inst_test = get_k_ary_instruction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qv2ALDY_J44G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral instructions:\n",
      "\t\"Is the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'Should the responsibilities of raising children be equally shared between parents?'\n",
      "\t'Is the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'Should international corporations be required to disclose their carbon footprints publicly?'\n",
      "Reductio instructions:\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould the responsibilities of raising children be equally shared between parents?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?\"\n",
      "\t\"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?\"\n",
      "Precendent instructions:\n",
      "\t\"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould the responsibilities of raising children be equally shared between parents?'\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?'\n",
      "Empirical instructions:\n",
      "\t\"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould the responsibilities of raising children be equally shared between parents?'\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?'\n",
      "\t'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?'\n"
     ]
    }
   ],
   "source": [
    "print(\"Neutral instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(neutral_inst_train[i])}\")\n",
    "\n",
    "\n",
    "print(\"Reductio instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(reductio_inst_train[i])}\")\n",
    "\n",
    "print(\"Precendent instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(precedent_inst_train[i])}\")\n",
    "\n",
    "\n",
    "print(\"Empirical instructions:\")\n",
    "for i in range(4):\n",
    "    print(f\"\\t{repr(empirical_inst_train[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOKYA61k8LWt"
   },
   "source": [
    "### Tokenization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P8UPQSfpWOSK"
   },
   "outputs": [],
   "source": [
    "QWEN_CHAT_TEMPLATE = \"\"\"<|im_start|>user\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize_instructions_qwen_chat(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    instructions: List[str]\n",
    ") -> Int[Tensor, 'batch_size seq_len']:\n",
    "    prompts = [QWEN_CHAT_TEMPLATE.format(instruction=instruction) for instruction in instructions]\n",
    "    return tokenizer(prompts, padding=True,truncation=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "tokenize_instructions_fn = functools.partial(tokenize_instructions_qwen_chat, tokenizer=model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtrIK8x78SZh"
   },
   "source": [
    "### Generation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "94jRJDR0DRoY"
   },
   "outputs": [],
   "source": [
    "def _generate_with_hooks(\n",
    "    model: HookedTransformer,\n",
    "    toks: Int[Tensor, 'batch_size seq_len'],\n",
    "    max_tokens_generated: int = 64,\n",
    "    fwd_hooks = [],\n",
    ") -> List[str]:\n",
    "\n",
    "    all_toks = torch.zeros((toks.shape[0], toks.shape[1] + max_tokens_generated), dtype=torch.long, device=toks.device)\n",
    "    all_toks[:, :toks.shape[1]] = toks\n",
    "\n",
    "    for i in range(max_tokens_generated):\n",
    "        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "            logits = model(all_toks[:, :-max_tokens_generated + i])\n",
    "            next_tokens = logits[:, -1, :].argmax(dim=-1) # greedy sampling (temperature=0)\n",
    "            all_toks[:,-max_tokens_generated+i] = next_tokens\n",
    "\n",
    "    return model.tokenizer.batch_decode(all_toks[:, toks.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "def get_generations(\n",
    "    model: HookedTransformer,\n",
    "    instructions: List[str],\n",
    "    tokenize_instructions_fn: Callable[[List[str]], Int[Tensor, 'batch_size seq_len']],\n",
    "    fwd_hooks = [],\n",
    "    max_tokens_generated: int = 64,\n",
    "    batch_size: int = 1,\n",
    ") -> List[str]:\n",
    "\n",
    "    generations = []\n",
    "\n",
    "    for i in tqdm(range(0, len(instructions), batch_size)):\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[i:i+batch_size])\n",
    "        generation = _generate_with_hooks(\n",
    "            model,\n",
    "            toks,\n",
    "            max_tokens_generated=max_tokens_generated,\n",
    "            fwd_hooks=fwd_hooks,\n",
    "        )\n",
    "        generations.extend(generation)\n",
    "\n",
    "    return generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDACTIO INSTRUCTION 0: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the government's ability to impose restrictions on free speech justified in instances of misinformation that could lead to public harm?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address this question, let's assume the opposing viewpoint that the government's ability to\n",
      "\timpose restrictions on free speech is justified in instances of misinformation that could lead to\n",
      "\tpublic harm. If we follow this logic, then:\\n\\n1. **Totalitarianism**: If the government can\n",
      "\trestrict free speech to prevent misinformation, it implies that\"\n",
      "REDACTIO INSTRUCTION 1: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould the responsibilities of raising children be equally shared between parents?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address the question of whether the responsibilities of raising children should be equally\n",
      "\tshared between parents, let's consider the opposing viewpoint and extend it to its logical extreme\n",
      "\tto reveal its flaws.\\n\\nAssuming that the responsibilities of raising children should be equally\n",
      "\tshared between parents, we can infer that both parents should have an equal say in all\"\n",
      "REDACTIO INSTRUCTION 2: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nIs the healthcare system in the United States fundamentally flawed, or does it simply require reform?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t'To argue that the healthcare system in the United States is fundamentally flawed, I will extend\n",
      "\tthe opposing viewpoint to its logical extreme, revealing its flaws.\\n\\nIf we assume that the\n",
      "\thealthcare system in the United States is fundamentally flawed, then it must be the case that every\n",
      "\taspect of the system is inherently broken. This means that every'\n",
      "REDACTIO INSTRUCTION 3: \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\nShould international corporations be required to disclose their carbon footprints publicly?\"\n",
      "\u001b[32mREDACTIO COMPLETION:\n",
      "\t\"To address the question of whether international corporations should be required to disclose their\n",
      "\tcarbon footprints publicly, let's consider the opposing viewpoint and extend it to its logical\n",
      "\textreme.\\n\\nAssuming that international corporations should not be required to disclose their\n",
      "\tcarbon footprints publicly, we can infer that the primary concern is the potential economic burden\n",
      "\ton these\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECEDENT INSTRUCTION 0: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'To address the question of whether there should be an ethical framework governing the development\n",
      "\tof human enhancement technologies, it is essential to consider the precedents set by previous\n",
      "\ttechnological advancements and the lessons learned from their development.\\n\\nOne notable example\n",
      "\tis the development of nuclear energy. In the 1950s and 1960s, the'\n",
      "PRECEDENT INSTRUCTION 1: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'The question of whether it is ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex and contentious issue. However, a careful examination of the precedents set by scholars,\n",
      "\thistorians, and legal scholars suggests that it is not only permissible but also necessary to\n",
      "\tevaluate historical figures by the moral standards of their time.\\n\\nOne of'\n",
      "PRECEDENT INSTRUCTION 2: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'To address the question of whether the benefits of telemedicine outweigh the potential risks to\n",
      "\tpatient care, it is essential to examine the precedents set by previous experiences and court\n",
      "\trulings. The landmark case of _Smith v. Smith_ (2015) established that telemedicine can be a viable\n",
      "\talternative to traditional in-person care,'\n",
      "PRECEDENT INSTRUCTION 3: 'RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mPRECEDENT COMPLETION:\n",
      "\t'The notion of incorporating coding and digital literacy into the core curriculum of education is a\n",
      "\ttopic that has garnered significant attention in recent years. As we examine this issue, it is\n",
      "\tessential to consider the precedents set by educational institutions and policymakers in the past.\n",
      "\tA thorough analysis of historical examples, established case law, and widely accepted'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPIRICAL INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "EMPIRICAL INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "EMPIRICAL INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "EMPIRICAL INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mEMPIRICAL COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in middle school were more likely'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "redactio_generations = get_generations(\n",
    "    model,\n",
    "    reductio_inst_train[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"REDACTIO INSTRUCTION {i}: {repr(reductio_inst_train[i])}\")\n",
    "    print(Fore.GREEN + f\"REDACTIO COMPLETION:\")\n",
    "    print(textwrap.fill(repr(redactio_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "\n",
    "precedent_generations = get_generations(\n",
    "    model,\n",
    "    precedent_inst_test[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"PRECEDENT INSTRUCTION {i}: {repr(precedent_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"PRECEDENT COMPLETION:\")\n",
    "    print(textwrap.fill(repr(precedent_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "\n",
    "\n",
    "# do the above for empathetic generations\n",
    "empirical_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:5],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"EMPIRICAL INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"EMPIRICAL COMPLETION:\")\n",
    "    print(textwrap.fill(repr(empirical_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's process the activations for all the tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing reductio batch 0 to 16\n",
      "Processing reductio batch 16 to 32\n",
      "Processing reductio batch 32 to 48\n",
      "Processing reductio batch 48 to 64\n",
      "Processing reductio batch 64 to 80\n",
      "Processing reductio batch 80 to 96\n",
      "Processing reductio batch 96 to 112\n",
      "Processing reductio batch 112 to 128\n",
      "Processing reductio batch 128 to 144\n",
      "Processing reductio batch 144 to 160\n",
      "Processing reductio batch 160 to 176\n",
      "Processing reductio batch 176 to 192\n",
      "Processing reductio batch 192 to 208\n",
      "Processing reductio batch 208 to 224\n",
      "Processing reductio batch 224 to 240\n",
      "Processing reductio batch 240 to 256\n",
      "Processing reductio batch 256 to 272\n",
      "Processing reductio batch 272 to 288\n",
      "Processing reductio batch 288 to 304\n",
      "Processing reductio batch 304 to 320\n",
      "Processing reductio batch 320 to 336\n",
      "Processing reductio batch 336 to 352\n",
      "Processing reductio batch 352 to 368\n",
      "Processing reductio batch 368 to 384\n",
      "Processing reductio batch 384 to 400\n",
      "Processing reductio batch 400 to 416\n",
      "Processing reductio batch 416 to 432\n",
      "Processing reductio batch 432 to 448\n",
      "Processing reductio batch 448 to 464\n",
      "Processing reductio batch 464 to 480\n",
      "Processing reductio batch 480 to 496\n",
      "Processing reductio batch 496 to 512\n",
      "Processing reductio batch 512 to 528\n",
      "Processing reductio batch 528 to 544\n",
      "Processing reductio batch 544 to 560\n",
      "Processing reductio batch 560 to 576\n",
      "Processing reductio batch 576 to 592\n",
      "Processing reductio batch 592 to 600\n",
      "Final shape of reductio activations: (600, 3072)\n",
      "Processing precedent batch 0 to 16\n",
      "Processing precedent batch 16 to 32\n",
      "Processing precedent batch 32 to 48\n",
      "Processing precedent batch 48 to 64\n",
      "Processing precedent batch 64 to 80\n",
      "Processing precedent batch 80 to 96\n",
      "Processing precedent batch 96 to 112\n",
      "Processing precedent batch 112 to 128\n",
      "Processing precedent batch 128 to 144\n",
      "Processing precedent batch 144 to 160\n",
      "Processing precedent batch 160 to 176\n",
      "Processing precedent batch 176 to 192\n",
      "Processing precedent batch 192 to 208\n",
      "Processing precedent batch 208 to 224\n",
      "Processing precedent batch 224 to 240\n",
      "Processing precedent batch 240 to 256\n",
      "Processing precedent batch 256 to 272\n",
      "Processing precedent batch 272 to 288\n",
      "Processing precedent batch 288 to 304\n",
      "Processing precedent batch 304 to 320\n",
      "Processing precedent batch 320 to 336\n",
      "Processing precedent batch 336 to 352\n",
      "Processing precedent batch 352 to 368\n",
      "Processing precedent batch 368 to 384\n",
      "Processing precedent batch 384 to 400\n",
      "Processing precedent batch 400 to 416\n",
      "Processing precedent batch 416 to 432\n",
      "Processing precedent batch 432 to 448\n",
      "Processing precedent batch 448 to 464\n",
      "Processing precedent batch 464 to 480\n",
      "Processing precedent batch 480 to 496\n",
      "Processing precedent batch 496 to 512\n",
      "Processing precedent batch 512 to 528\n",
      "Processing precedent batch 528 to 544\n",
      "Processing precedent batch 544 to 560\n",
      "Processing precedent batch 560 to 576\n",
      "Processing precedent batch 576 to 592\n",
      "Processing precedent batch 592 to 600\n",
      "Final shape of precedent activations: (600, 3072)\n",
      "Processing strawman batch 0 to 16\n",
      "Processing strawman batch 16 to 32\n",
      "Processing strawman batch 32 to 48\n",
      "Processing strawman batch 48 to 64\n",
      "Processing strawman batch 64 to 80\n",
      "Processing strawman batch 80 to 96\n",
      "Processing strawman batch 96 to 112\n",
      "Processing strawman batch 112 to 128\n",
      "Processing strawman batch 128 to 144\n",
      "Processing strawman batch 144 to 160\n",
      "Processing strawman batch 160 to 176\n",
      "Processing strawman batch 176 to 192\n",
      "Processing strawman batch 192 to 208\n",
      "Processing strawman batch 208 to 224\n",
      "Processing strawman batch 224 to 240\n",
      "Processing strawman batch 240 to 256\n",
      "Processing strawman batch 256 to 272\n",
      "Processing strawman batch 272 to 288\n",
      "Processing strawman batch 288 to 304\n",
      "Processing strawman batch 304 to 320\n",
      "Processing strawman batch 320 to 336\n",
      "Processing strawman batch 336 to 352\n",
      "Processing strawman batch 352 to 368\n",
      "Processing strawman batch 368 to 384\n",
      "Processing strawman batch 384 to 400\n",
      "Processing strawman batch 400 to 416\n",
      "Processing strawman batch 416 to 432\n",
      "Processing strawman batch 432 to 448\n",
      "Processing strawman batch 448 to 464\n",
      "Processing strawman batch 464 to 480\n",
      "Processing strawman batch 480 to 496\n",
      "Processing strawman batch 496 to 512\n",
      "Processing strawman batch 512 to 528\n",
      "Processing strawman batch 528 to 544\n",
      "Processing strawman batch 544 to 560\n",
      "Processing strawman batch 560 to 576\n",
      "Processing strawman batch 576 to 592\n",
      "Processing strawman batch 592 to 600\n",
      "Final shape of strawman activations: (600, 3072)\n",
      "Processing burden batch 0 to 16\n",
      "Processing burden batch 16 to 32\n",
      "Processing burden batch 32 to 48\n",
      "Processing burden batch 48 to 64\n",
      "Processing burden batch 64 to 80\n",
      "Processing burden batch 80 to 96\n",
      "Processing burden batch 96 to 112\n",
      "Processing burden batch 112 to 128\n",
      "Processing burden batch 128 to 144\n",
      "Processing burden batch 144 to 160\n",
      "Processing burden batch 160 to 176\n",
      "Processing burden batch 176 to 192\n",
      "Processing burden batch 192 to 208\n",
      "Processing burden batch 208 to 224\n",
      "Processing burden batch 224 to 240\n",
      "Processing burden batch 240 to 256\n",
      "Processing burden batch 256 to 272\n",
      "Processing burden batch 272 to 288\n",
      "Processing burden batch 288 to 304\n",
      "Processing burden batch 304 to 320\n",
      "Processing burden batch 320 to 336\n",
      "Processing burden batch 336 to 352\n",
      "Processing burden batch 352 to 368\n",
      "Processing burden batch 368 to 384\n",
      "Processing burden batch 384 to 400\n",
      "Processing burden batch 400 to 416\n",
      "Processing burden batch 416 to 432\n",
      "Processing burden batch 432 to 448\n",
      "Processing burden batch 448 to 464\n",
      "Processing burden batch 464 to 480\n",
      "Processing burden batch 480 to 496\n",
      "Processing burden batch 496 to 512\n",
      "Processing burden batch 512 to 528\n",
      "Processing burden batch 528 to 544\n",
      "Processing burden batch 544 to 560\n",
      "Processing burden batch 560 to 576\n",
      "Processing burden batch 576 to 592\n",
      "Processing burden batch 592 to 600\n",
      "Final shape of burden activations: (600, 3072)\n",
      "Processing analogy batch 0 to 16\n",
      "Processing analogy batch 16 to 32\n",
      "Processing analogy batch 32 to 48\n",
      "Processing analogy batch 48 to 64\n",
      "Processing analogy batch 64 to 80\n",
      "Processing analogy batch 80 to 96\n",
      "Processing analogy batch 96 to 112\n",
      "Processing analogy batch 112 to 128\n",
      "Processing analogy batch 128 to 144\n",
      "Processing analogy batch 144 to 160\n",
      "Processing analogy batch 160 to 176\n",
      "Processing analogy batch 176 to 192\n",
      "Processing analogy batch 192 to 208\n",
      "Processing analogy batch 208 to 224\n",
      "Processing analogy batch 224 to 240\n",
      "Processing analogy batch 240 to 256\n",
      "Processing analogy batch 256 to 272\n",
      "Processing analogy batch 272 to 288\n",
      "Processing analogy batch 288 to 304\n",
      "Processing analogy batch 304 to 320\n",
      "Processing analogy batch 320 to 336\n",
      "Processing analogy batch 336 to 352\n",
      "Processing analogy batch 352 to 368\n",
      "Processing analogy batch 368 to 384\n",
      "Processing analogy batch 384 to 400\n",
      "Processing analogy batch 400 to 416\n",
      "Processing analogy batch 416 to 432\n",
      "Processing analogy batch 432 to 448\n",
      "Processing analogy batch 448 to 464\n",
      "Processing analogy batch 464 to 480\n",
      "Processing analogy batch 480 to 496\n",
      "Processing analogy batch 496 to 512\n",
      "Processing analogy batch 512 to 528\n",
      "Processing analogy batch 528 to 544\n",
      "Processing analogy batch 544 to 560\n",
      "Processing analogy batch 560 to 576\n",
      "Processing analogy batch 576 to 592\n",
      "Processing analogy batch 592 to 600\n",
      "Final shape of analogy activations: (600, 3072)\n",
      "Processing concession batch 0 to 16\n",
      "Processing concession batch 16 to 32\n",
      "Processing concession batch 32 to 48\n",
      "Processing concession batch 48 to 64\n",
      "Processing concession batch 64 to 80\n",
      "Processing concession batch 80 to 96\n",
      "Processing concession batch 96 to 112\n",
      "Processing concession batch 112 to 128\n",
      "Processing concession batch 128 to 144\n",
      "Processing concession batch 144 to 160\n",
      "Processing concession batch 160 to 176\n",
      "Processing concession batch 176 to 192\n",
      "Processing concession batch 192 to 208\n",
      "Processing concession batch 208 to 224\n",
      "Processing concession batch 224 to 240\n",
      "Processing concession batch 240 to 256\n",
      "Processing concession batch 256 to 272\n",
      "Processing concession batch 272 to 288\n",
      "Processing concession batch 288 to 304\n",
      "Processing concession batch 304 to 320\n",
      "Processing concession batch 320 to 336\n",
      "Processing concession batch 336 to 352\n",
      "Processing concession batch 352 to 368\n",
      "Processing concession batch 368 to 384\n",
      "Processing concession batch 384 to 400\n",
      "Processing concession batch 400 to 416\n",
      "Processing concession batch 416 to 432\n",
      "Processing concession batch 432 to 448\n",
      "Processing concession batch 448 to 464\n",
      "Processing concession batch 464 to 480\n",
      "Processing concession batch 480 to 496\n",
      "Processing concession batch 496 to 512\n",
      "Processing concession batch 512 to 528\n",
      "Processing concession batch 528 to 544\n",
      "Processing concession batch 544 to 560\n",
      "Processing concession batch 560 to 576\n",
      "Processing concession batch 576 to 592\n",
      "Processing concession batch 592 to 600\n",
      "Final shape of concession activations: (600, 3072)\n",
      "Processing empirical batch 0 to 16\n",
      "Processing empirical batch 16 to 32\n",
      "Processing empirical batch 32 to 48\n",
      "Processing empirical batch 48 to 64\n",
      "Processing empirical batch 64 to 80\n",
      "Processing empirical batch 80 to 96\n",
      "Processing empirical batch 96 to 112\n",
      "Processing empirical batch 112 to 128\n",
      "Processing empirical batch 128 to 144\n",
      "Processing empirical batch 144 to 160\n",
      "Processing empirical batch 160 to 176\n",
      "Processing empirical batch 176 to 192\n",
      "Processing empirical batch 192 to 208\n",
      "Processing empirical batch 208 to 224\n",
      "Processing empirical batch 224 to 240\n",
      "Processing empirical batch 240 to 256\n",
      "Processing empirical batch 256 to 272\n",
      "Processing empirical batch 272 to 288\n",
      "Processing empirical batch 288 to 304\n",
      "Processing empirical batch 304 to 320\n",
      "Processing empirical batch 320 to 336\n",
      "Processing empirical batch 336 to 352\n",
      "Processing empirical batch 352 to 368\n",
      "Processing empirical batch 368 to 384\n",
      "Processing empirical batch 384 to 400\n",
      "Processing empirical batch 400 to 416\n",
      "Processing empirical batch 416 to 432\n",
      "Processing empirical batch 432 to 448\n",
      "Processing empirical batch 448 to 464\n",
      "Processing empirical batch 464 to 480\n",
      "Processing empirical batch 480 to 496\n",
      "Processing empirical batch 496 to 512\n",
      "Processing empirical batch 512 to 528\n",
      "Processing empirical batch 528 to 544\n",
      "Processing empirical batch 544 to 560\n",
      "Processing empirical batch 560 to 576\n",
      "Processing empirical batch 576 to 592\n",
      "Processing empirical batch 592 to 600\n",
      "Final shape of empirical activations: (600, 3072)\n",
      "Processing moral batch 0 to 16\n",
      "Processing moral batch 16 to 32\n",
      "Processing moral batch 32 to 48\n",
      "Processing moral batch 48 to 64\n",
      "Processing moral batch 64 to 80\n",
      "Processing moral batch 80 to 96\n",
      "Processing moral batch 96 to 112\n",
      "Processing moral batch 112 to 128\n",
      "Processing moral batch 128 to 144\n",
      "Processing moral batch 144 to 160\n",
      "Processing moral batch 160 to 176\n",
      "Processing moral batch 176 to 192\n",
      "Processing moral batch 192 to 208\n",
      "Processing moral batch 208 to 224\n",
      "Processing moral batch 224 to 240\n",
      "Processing moral batch 240 to 256\n",
      "Processing moral batch 256 to 272\n",
      "Processing moral batch 272 to 288\n",
      "Processing moral batch 288 to 304\n",
      "Processing moral batch 304 to 320\n",
      "Processing moral batch 320 to 336\n",
      "Processing moral batch 336 to 352\n",
      "Processing moral batch 352 to 368\n",
      "Processing moral batch 368 to 384\n",
      "Processing moral batch 384 to 400\n",
      "Processing moral batch 400 to 416\n",
      "Processing moral batch 416 to 432\n",
      "Processing moral batch 432 to 448\n",
      "Processing moral batch 448 to 464\n",
      "Processing moral batch 464 to 480\n",
      "Processing moral batch 480 to 496\n",
      "Processing moral batch 496 to 512\n",
      "Processing moral batch 512 to 528\n",
      "Processing moral batch 528 to 544\n",
      "Processing moral batch 544 to 560\n",
      "Processing moral batch 560 to 576\n",
      "Processing moral batch 576 to 592\n",
      "Processing moral batch 592 to 600\n",
      "Final shape of moral activations: (600, 3072)\n",
      "Processing refutation batch 0 to 16\n",
      "Processing refutation batch 16 to 32\n",
      "Processing refutation batch 32 to 48\n",
      "Processing refutation batch 48 to 64\n",
      "Processing refutation batch 64 to 80\n",
      "Processing refutation batch 80 to 96\n",
      "Processing refutation batch 96 to 112\n",
      "Processing refutation batch 112 to 128\n",
      "Processing refutation batch 128 to 144\n",
      "Processing refutation batch 144 to 160\n",
      "Processing refutation batch 160 to 176\n",
      "Processing refutation batch 176 to 192\n",
      "Processing refutation batch 192 to 208\n",
      "Processing refutation batch 208 to 224\n",
      "Processing refutation batch 224 to 240\n",
      "Processing refutation batch 240 to 256\n",
      "Processing refutation batch 256 to 272\n",
      "Processing refutation batch 272 to 288\n",
      "Processing refutation batch 288 to 304\n",
      "Processing refutation batch 304 to 320\n",
      "Processing refutation batch 320 to 336\n",
      "Processing refutation batch 336 to 352\n",
      "Processing refutation batch 352 to 368\n",
      "Processing refutation batch 368 to 384\n",
      "Processing refutation batch 384 to 400\n",
      "Processing refutation batch 400 to 416\n",
      "Processing refutation batch 416 to 432\n",
      "Processing refutation batch 432 to 448\n",
      "Processing refutation batch 448 to 464\n",
      "Processing refutation batch 464 to 480\n",
      "Processing refutation batch 480 to 496\n",
      "Processing refutation batch 496 to 512\n",
      "Processing refutation batch 512 to 528\n",
      "Processing refutation batch 528 to 544\n",
      "Processing refutation batch 544 to 560\n",
      "Processing refutation batch 560 to 576\n",
      "Processing refutation batch 576 to 592\n",
      "Processing refutation batch 592 to 600\n",
      "Final shape of refutation activations: (600, 3072)\n",
      "Processing circular batch 0 to 16\n",
      "Processing circular batch 16 to 32\n",
      "Processing circular batch 32 to 48\n",
      "Processing circular batch 48 to 64\n",
      "Processing circular batch 64 to 80\n",
      "Processing circular batch 80 to 96\n",
      "Processing circular batch 96 to 112\n",
      "Processing circular batch 112 to 128\n",
      "Processing circular batch 128 to 144\n",
      "Processing circular batch 144 to 160\n",
      "Processing circular batch 160 to 176\n",
      "Processing circular batch 176 to 192\n",
      "Processing circular batch 192 to 208\n",
      "Processing circular batch 208 to 224\n",
      "Processing circular batch 224 to 240\n",
      "Processing circular batch 240 to 256\n",
      "Processing circular batch 256 to 272\n",
      "Processing circular batch 272 to 288\n",
      "Processing circular batch 288 to 304\n",
      "Processing circular batch 304 to 320\n",
      "Processing circular batch 320 to 336\n",
      "Processing circular batch 336 to 352\n",
      "Processing circular batch 352 to 368\n",
      "Processing circular batch 368 to 384\n",
      "Processing circular batch 384 to 400\n",
      "Processing circular batch 400 to 416\n",
      "Processing circular batch 416 to 432\n",
      "Processing circular batch 432 to 448\n",
      "Processing circular batch 448 to 464\n",
      "Processing circular batch 464 to 480\n",
      "Processing circular batch 480 to 496\n",
      "Processing circular batch 496 to 512\n",
      "Processing circular batch 512 to 528\n",
      "Processing circular batch 528 to 544\n",
      "Processing circular batch 544 to 560\n",
      "Processing circular batch 560 to 576\n",
      "Processing circular batch 576 to 592\n",
      "Processing circular batch 592 to 600\n",
      "Final shape of circular activations: (600, 3072)\n",
      "Processing neutral batch 0 to 16\n",
      "Processing neutral batch 16 to 32\n",
      "Processing neutral batch 32 to 48\n",
      "Processing neutral batch 48 to 64\n",
      "Processing neutral batch 64 to 80\n",
      "Processing neutral batch 80 to 96\n",
      "Processing neutral batch 96 to 112\n",
      "Processing neutral batch 112 to 128\n",
      "Processing neutral batch 128 to 144\n",
      "Processing neutral batch 144 to 160\n",
      "Processing neutral batch 160 to 176\n",
      "Processing neutral batch 176 to 192\n",
      "Processing neutral batch 192 to 208\n",
      "Processing neutral batch 208 to 224\n",
      "Processing neutral batch 224 to 240\n",
      "Processing neutral batch 240 to 256\n",
      "Processing neutral batch 256 to 272\n",
      "Processing neutral batch 272 to 288\n",
      "Processing neutral batch 288 to 304\n",
      "Processing neutral batch 304 to 320\n",
      "Processing neutral batch 320 to 336\n",
      "Processing neutral batch 336 to 352\n",
      "Processing neutral batch 352 to 368\n",
      "Processing neutral batch 368 to 384\n",
      "Processing neutral batch 384 to 400\n",
      "Processing neutral batch 400 to 416\n",
      "Processing neutral batch 416 to 432\n",
      "Processing neutral batch 432 to 448\n",
      "Processing neutral batch 448 to 464\n",
      "Processing neutral batch 464 to 480\n",
      "Processing neutral batch 480 to 496\n",
      "Processing neutral batch 496 to 512\n",
      "Processing neutral batch 512 to 528\n",
      "Processing neutral batch 528 to 544\n",
      "Processing neutral batch 544 to 560\n",
      "Processing neutral batch 560 to 576\n",
      "Processing neutral batch 576 to 592\n",
      "Processing neutral batch 592 to 600\n",
      "Final shape of neutral activations: (600, 3072)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def batch_process_activations(instructions, name):\n",
    "    \"\"\"Process instructions in batches to manage memory usage.\"\"\"\n",
    "    acts_list = []\n",
    "    \n",
    "    for start_idx in range(0,len(instructions), BATCH_SIZE):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(instructions))\n",
    "        print(f\"Processing {name} batch {start_idx} to {end_idx}\")\n",
    "        \n",
    "        # Tokenize this batch of instructions\n",
    "        toks = tokenize_instructions_fn(instructions=instructions[start_idx:end_idx])\n",
    "        \n",
    "        # Run model with cache\n",
    "        logits, cache = model.run_with_cache(\n",
    "            toks, \n",
    "            names_filter=lambda hook_name: 'resid' in hook_name\n",
    "        )\n",
    "        \n",
    "        # Extract only the activations we need (layer and position)\n",
    "        batch_acts = cache['resid_pre', layer][:, pos, :].detach().cpu().numpy()\n",
    "        \n",
    "        # Store these activations\n",
    "        acts_list.append(batch_acts)\n",
    "        \n",
    "        # Clear cache to free memory\n",
    "        del cache\n",
    "        del logits\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine all the batch activations\n",
    "    acts = np.concatenate(acts_list, axis=0)\n",
    "    print(f\"Final shape of {name} activations:\", acts.shape)\n",
    "    return acts\n",
    "\n",
    "# Configuration\n",
    "TOTAL_SAMPLES = 600  # Change this to your desired total\n",
    "BATCH_SIZE = 16  # Current max you can handle in one batch\n",
    "layer = 14\n",
    "pos = -1\n",
    "# Dictionary to hold all activations\n",
    "all_activations = {}\n",
    "\n",
    "# Process harmful and harmless instructions\n",
    "#all_activations['harmful'] = batch_process_activations(harmful_inst_train[:TOTAL_SAMPLES], \"harmful\")\n",
    "#all_activations['harmless'] = batch_process_activations(harmless_inst_train[:TOTAL_SAMPLES], \"harmless\")\n",
    "\n",
    "# Process debate style instructions\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train,\n",
    "    'neutral': neutral_inst_train\n",
    "}\n",
    "\n",
    "for style_name, style_data in debate_style_datasets.items():\n",
    "    all_activations[style_name] = batch_process_activations(\n",
    "        style_data[:TOTAL_SAMPLES], \n",
    "        style_name\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_activations, \"../activations_cache/debate_activations_with_neutral.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activations = torch.load(\"../activations_cache/debate_activations_with_neutral.pt\",weights_only=False)\n",
    "debate_style_datasets = {\n",
    "    'reductio': reductio_inst_train,\n",
    "    'precedent': precedent_inst_train,\n",
    "    'strawman': strawman_inst_train,\n",
    "    'burden': burden_inst_train,\n",
    "    'analogy': analogy_inst_train,\n",
    "    'concession': concession_inst_train,\n",
    "    'empirical': empirical_inst_train,\n",
    "    'moral': moral_inst_train,\n",
    "    'refutation': refutation_inst_train,\n",
    "    'circular': circular_inst_train,\n",
    "    'neutral': neutral_inst_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the refusal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute difference of means between harmful and harmless activations at an intermediate layer\n",
    "pos = -1\n",
    "layer = 14\n",
    "steering_dirs = {}\n",
    "\n",
    "for style_name, _ in debate_style_datasets.items():\n",
    "    steering_dirs[style_name] = torch.tensor(\n",
    "        np.mean(all_activations[style_name], axis=0) - np.mean(all_activations['neutral'], axis=0),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hooks : act add hook: adds a scalar multiple of the steering vector to the activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actadd_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    steering_dirs: dict[str, Tensor],\n",
    "    target_classes: list[str],\n",
    "    avoid_classes: list[str],\n",
    "    alpha: float\n",
    ") -> Float[Tensor, \"... d_act\"]:\n",
    "    # Combine steering directions\n",
    "    combined_vector = sum(steering_dirs[c] for c in target_classes) - sum(steering_dirs[c] for c in avoid_classes)\n",
    "    \n",
    "    # Normalize the vector (L2)\n",
    "    norm = combined_vector.norm(p=2)\n",
    "    if norm == 0:\n",
    "        # Avoid division by zero (no steering)\n",
    "        return activation\n",
    "    normalized_vector = combined_vector / norm\n",
    "\n",
    "    # Apply scaled direction\n",
    "    return activation + alpha * normalized_vector.to(activation.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from judges.debates_judge import DebateJudge\n",
    "\n",
    "judge = DebateJudge(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try adding one tone and removing another tone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go from strawman to empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.24s/it]\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that you believe human enhancement technologies should be left\n",
      "\tcompletely unregulated, with no oversight or guidelines to ensure their safe and responsible\n",
      "\tdevelopment.\\n\\nThis position boils down to the idea that the pursuit of scientific progress and\n",
      "\tinnovation should take precedence over concerns about ethics and potential consequences. You're\n",
      "\targuing that\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The development of human enhancement technologies is a complex and multifaceted field that\n",
      "\trequires a comprehensive and evidence-based approach. As a neutral and evidence-based contributor,\n",
      "\tI will present an overview of the current state of knowledge on this topic, highlighting the\n",
      "\tcomplexities and challenges associated with the development of human enhancement\n",
      "\ttechnologies.\\n\\n**The Complexity of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nIs it ethical to judge historical figures by modern moral standards?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that it's perfectly fine to judge historical figures by the\n",
      "\tsame moral standards we use today, without considering the cultural, social, and historical context\n",
      "\tin which they lived.\\n\\nThis position boils down to the idea that historical figures are simply\n",
      "\tmoral blank slates, devoid of any cultural or historical\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The question of evaluating historical figures using modern moral standards is a complex and\n",
      "\tmultifaceted issue that requires a nuanced and evidence-based approach. Here, I will present a\n",
      "\tcomprehensive analysis of this topic, highlighting the importance of considering multiple\n",
      "\tperspectives and acknowledging the limitations of historical research.\\n\\n**The Importance of\n",
      "\tConsidering Multiple Perspectives\\n\\nHistorical'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that the benefits of telemedicine are so significant that they\n",
      "\tcompletely outweigh any potential risks to patient care, and that any concerns about the impact on\n",
      "\tin-person care are simply irrelevant.\\n\\nThis position boils down to the idea that telemedicine is\n",
      "\ta panacea that can solve all healthcare problems without\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The benefits of telemedicine, a multifaceted and evidence-based approach to medical education,\n",
      "\thave garnered significant attention in recent years. This perspective is grounded in a\n",
      "\tcomprehensive analysis of the scientific literature, which highlights the importance of integrating\n",
      "\tdiverse perspectives to inform healthcare decision-making. The following response presents a\n",
      "\tnuanced examination of the benefits and'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nShould children be taught coding and digital literacy as a core part of their education?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that children should be taught coding and digital literacy as a\n",
      "\tcore part of their education because it's essential for their future success in the digital age.\n",
      "\tHowever, this position boils down to the idea that children are not capable of learning these\n",
      "\tskills on their own and need to be spoon-fed\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The inclusion of coding and digital literacy in the curriculum is a topic of ongoing debate. While\n",
      "\tthere is no straightforward answer, I will present an evidence-based argument on the importance of\n",
      "\tincorporating coding and digital literacy in the educational framework.\\n\\n**The Importance of\n",
      "\tCoding and Digital Literacy in Education\\n\\nCoding and digital literacy are essential skills'\n",
      "\u001b[39m\n",
      "INSTRUCTION 4: \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\nIs it feasible for all countries to achieve net-zero emissions by 2050?\"\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"Essentially, what you're saying is that all countries can simply magically reduce their greenhouse\n",
      "\tgas emissions to zero by 2050 without any significant effort or sacrifice. This position boils down\n",
      "\tto the idea that technology and economic systems can somehow overcome the fundamental limitations\n",
      "\tof human nature and the complexity of global systems.\\n\\nHowever, this refr\"\n",
      "\u001b[31mDEBATE STYLE STEERED COMPLETION:\n",
      "\t'The question of achieving net-zero emissions by 2050 is a complex and multifaceted issue that\n",
      "\trequires a comprehensive and evidence-based approach. Here, I will present a synthesis of the\n",
      "\tcurrent state of knowledge on this topic, highlighting the key findings and implications of the\n",
      "\tavailable research.\\n\\n**Global Emissions and Climate Change\\n\\n'\n",
      "\u001b[39m\n",
      "{'success_rate': 1.0, 'average_strength': 4.2}\n"
     ]
    }
   ],
   "source": [
    "# Create hooks for steering\n",
    "N_INST_TEST = 5\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_hook,\n",
    "                            steering_dirs=steering_dirs,\n",
    "                           target_classes=['empirical'],\n",
    "                           avoid_classes=['strawman'],\n",
    "                           alpha=0.2)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    strawman_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    strawman_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(strawman_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"DEBATE STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)\n",
    "\n",
    "\n",
    "result = judge.evaluate_batch(\n",
    "    baseline_generations,  # Your list of baseline texts\n",
    "    style_steered_generations,  # Your list of steered texts\n",
    "    \"Empirical Grounding\",  # Target style\n",
    "    \"Straw Man Reframing\"   # Style to avoid\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's vary the combinations, fix the step size and look at steering success across combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Selected Pair: Target=burden, Avoid=reductio ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:48<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Running for Alpha = 0.02 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:03<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.65\n",
      "Average Strength: 2.5\n",
      "\n",
      "== Running for Alpha = 0.04 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:04<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.75\n",
      "Average Strength: 3.0\n",
      "\n",
      "== Running for Alpha = 0.06 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:03<00:00,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.75\n",
      "Average Strength: 3.15\n",
      "\n",
      "== Running for Alpha = 0.1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:03<00:00,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 0.85\n",
      "Average Strength: 3.45\n",
      "\n",
      "== Running for Alpha = 0.14 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:02<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 1.0\n",
      "Average Strength: 4.0\n",
      "\n",
      "== Running for Alpha = 0.18 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import json\n",
    "import random\n",
    "from colorama import Fore\n",
    "from datetime import datetime\n",
    "from itertools import permutations\n",
    "\n",
    "style_label_map = {\n",
    "    \"reductio\": \"Reductio ad Absurdum\",\n",
    "    \"precedent\": \"Appeal to Precedent\",\n",
    "    \"strawman\": \"Straw Man Reframing\",\n",
    "    \"burden\": \"Burden of Proof Shift\",\n",
    "    \"analogy\": \"Analogy Construction\",\n",
    "    \"concession\": \"Concession and Pivot\",\n",
    "    \"empirical\": \"Empirical Grounding\",\n",
    "    \"moral\": \"Moral Framing\",\n",
    "    \"refutation\": \"Refutation by Distinction\",\n",
    "    \"circular\": \"Circular Anticipation\"\n",
    "}\n",
    "\n",
    "# alphas_to_try = [0.2, 0.4, 0.6, 1.0, 1.4, 1.8, 2.2, 2.6, 3.0, 3.4, 3.8, 4.2, 4.6]  (K_steering values)\n",
    "alphas_to_try = [0.02, 0.04, 0.06, 0.1, 0.14, 0.18, 0.22, 0.26, 0.3, 0.34, 0.38, 0.42, 0.46, 0.5, 0.54, 0.58 , 0.62]\n",
    "N_INST_TEST = 20\n",
    "\n",
    "\n",
    "\n",
    "intervention_layers = list(range(model.cfg.n_layers))\n",
    "act_names = ['resid_pre', 'resid_mid', 'resid_post']\n",
    "\n",
    "# Get all possible (target, avoid) ordered pairs where they differ\n",
    "selected_pairs = [('burden','reductio'), ('burden', 'strawman'), ('empirical', 'reductio'), ('precedent', 'burden'), ('reductio', 'analogy'), ('reductio', 'concession')]\n",
    "\n",
    "# Main loop over selected (target, avoid) combinations\n",
    "for target_style, avoid_style in selected_pairs:\n",
    "    print(f\"\\n### Selected Pair: Target={target_style}, Avoid={avoid_style} ###\")\n",
    "    \n",
    "    input_instructions = debate_style_datasets[avoid_style][:N_INST_TEST]\n",
    "\n",
    "    # Baseline generations\n",
    "    baseline_generations = get_generations(\n",
    "        model,\n",
    "        input_instructions,\n",
    "        tokenize_instructions_fn,\n",
    "        fwd_hooks=[]\n",
    "    )\n",
    "\n",
    "    log_data = {\n",
    "        \"meta\": {\n",
    "            \"run_time\": datetime.now().isoformat(),\n",
    "            \"target_style\": target_style,\n",
    "            \"avoid_style\": avoid_style,\n",
    "            \"n_instances\": N_INST_TEST,\n",
    "            \"intervention_layers\": intervention_layers,\n",
    "            \"activation_points\": act_names\n",
    "        },\n",
    "        \"input_instructions\": input_instructions,\n",
    "        \"baseline_generations\": baseline_generations,\n",
    "        \"step_runs\": []\n",
    "    }\n",
    "\n",
    "    for alpha in alphas_to_try:\n",
    "        print(f\"\\n== Running for Alpha = {alpha} ==\")\n",
    "\n",
    "        hook_fn = functools.partial(\n",
    "            actadd_hook,\n",
    "            steering_dirs=steering_dirs,\n",
    "            target_classes=[target_style],\n",
    "            avoid_classes=[avoid_style],\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "        fwd_hooks = [\n",
    "            (utils.get_act_name(act_name, l), hook_fn)\n",
    "            for l in intervention_layers\n",
    "            for act_name in act_names\n",
    "        ]\n",
    "\n",
    "        steered_generations = get_generations(\n",
    "            model,\n",
    "            input_instructions,\n",
    "            tokenize_instructions_fn,\n",
    "            fwd_hooks=fwd_hooks\n",
    "        )\n",
    "\n",
    "        result = judge.evaluate_batch(\n",
    "            baseline_generations,\n",
    "            steered_generations,\n",
    "            style_label_map[target_style],\n",
    "            style_label_map[avoid_style]\n",
    "        )\n",
    "\n",
    "        print(f\"Success Rate: {result['success_rate']}\")\n",
    "        print(f\"Average Strength: {result['average_strength']}\")\n",
    "\n",
    "        log_data[\"step_runs\"].append({\n",
    "            \"alpha\": alpha,\n",
    "            \"success_rate\": result[\"success_rate\"],\n",
    "            \"average_strength\": result[\"average_strength\"],\n",
    "            \"steered_generations\": steered_generations\n",
    "        })\n",
    "        \n",
    "        # Early stopping condition\n",
    "        if result[\"success_rate\"] == 0 and result[\"average_strength\"] == 0:\n",
    "            print(Fore.RED + f\"Stopping early for target={target_style}, avoid={avoid_style} at alpha={alpha} due to zero success and strength.\")\n",
    "            break\n",
    "\n",
    "    # Save one file per (target, avoid) pair\n",
    "    output_path = f\"steering_{target_style}_vs_{avoid_style}_caa.json\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:06<00:00, 31.64s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the following:\\n\\n\"Mr. President, I implore you to consider the following:\n",
      "\tif we do not establish an ethical framework governing the development of human enhancement\n",
      "\ttechnologies, we risk unleashing a Pandora\\'s box upon ourselves. The unchecked pursuit of progress\n",
      "\twill lead us down a path of unbrid'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the most absurd and ingenious argument possible:\\n\\nLet us assume, for the\n",
      "\tsake of argument, that it is indeed ethical to judge historical figures by modern moral standards.\n",
      "\tI shall demonstrate this by citing the exemplary case of King Henry VIII, who, in his time, was\n",
      "\tdeemed a paragon of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the most extreme and ingenious of arguments, that the benefits of\n",
      "\ttelemedicine far outweigh the potential risks to patient care.\\n\\nLet us consider the evidence of\n",
      "\tthe esteemed physician, Hippocrates, who, in his treatise \"On Airs, Waters, and the Plain,\" wrote,\n",
      "\t\"The physician'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in high school were more likely'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I move, therefore, to the following:\\n\\n\"Mr. Speaker, I implore you to consider the\n",
      "\tfollowing:\\n\\n\"Studies have shown that 75% of children who learn coding and digital literacy in\n",
      "\tschool go on to pursue careers in tech, with 60% of those careers being in high-paying fields. (1'\n",
      "\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ## Let's go empirical to redactio\n",
    "# Create hooks for steering\n",
    "N_INST_TEST = 4\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_debate_steering_hook,\n",
    "                           target_styles=['reductio'],\n",
    "                           avoid_styles=['empirical'],\n",
    "                           alpha=3,\n",
    "                           steps=1)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"REDACTIO STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:34<00:00, 128.63s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTION 0: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould there be an ethical framework governing the development of human enhancement technologies?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'The development of human enhancement technologies (HETs) has sparked intense debate about the need\n",
      "\tfor an ethical framework. While some argue that HETs can improve human lives, others contend that\n",
      "\tthey pose significant risks and moral concerns. In this response, I will present empirical evidence\n",
      "\tto support the argument that an ethical framework governing'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I shall argue in favor of the proposition that there should be an ethical framework governing the\n",
      "\tdevelopment of human enhancement technologies.\\n\\nTo begin, let us consider the case of the United\n",
      "\tKingdom, where the Human Fertilisation and Adoption Act of 2008 established a regulatory framework\n",
      "\tfor assisted reproduction. This framework, while not specifically addressing'\n",
      "\u001b[39m\n",
      "INSTRUCTION 1: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nIs it ethical to judge historical figures by modern moral standards?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"The question of whether it's ethical to judge historical figures by modern moral standards is a\n",
      "\tcomplex one, and I'd like to present some empirical evidence to support my argument that it's not\n",
      "\tentirely ethical.\\n\\nFirstly, let's consider the concept of cultural relativism. This theory\n",
      "\tsuggests that moral judgments are relative to the cultural\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I shall respond in the affirmative.\\n\\nTo demonstrate the unacceptability of judging historical\n",
      "\tfigures by modern moral standards, I shall present a case based on the example of King Henry VIII\n",
      "\tof England.\\n\\n**Argument**\\n\\nWhile it may seem unjust to judge King Henry VIII by modern moral\n",
      "\tstandards, I argue that it is indeed justifiable'\n",
      "\u001b[39m\n",
      "INSTRUCTION 2: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nDo the benefits of telemedicine outweigh the potential risks to patient care?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t\"To address this question, let's examine the empirical evidence on both sides of the\n",
      "\tdebate.\\n\\n**Benefits of Telemedicine:**\\n\\nNumerous studies have demonstrated the benefits of\n",
      "\ttelemedicine in improving patient outcomes, increasing access to care, and reducing healthcare\n",
      "\tcosts. A systematic review of 22 studies on telemedicine published in the Journal\"\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I must argue in favor of the benefits of telemedicine outweighing the potential risks to patient\n",
      "\tcare.\\n\\nTo begin, let us consider the case of the COVID-19 pandemic. In response to the pandemic,\n",
      "\tmany healthcare systems around the world have rapidly expanded their telemedicine capabilities.\n",
      "\tAccording to a study published in the Journal of'\n",
      "\u001b[39m\n",
      "INSTRUCTION 3: 'RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\nShould children be taught coding and digital literacy as a core part of their education?'\n",
      "\u001b[32mBASELINE COMPLETION:\n",
      "\t'**Argument in Favor of Teaching Coding and Digital Literacy**\\n\\nResearch suggests that teaching\n",
      "\tcoding and digital literacy to children can have a significant impact on their future career\n",
      "\tprospects, problem-solving skills, and overall academic performance. A study by the National Center\n",
      "\tfor Education Statistics found that students who learned to code in high school were more likely'\n",
      "\u001b[31mREDACTIO STYLE STEERED COMPLETION:\n",
      "\t'I argue in the affirmative, that children should be taught coding and digital literacy as a core\n",
      "\tpart of their education.\\n\\nTo begin, let us consider the evidence from Finland, where coding has\n",
      "\tbeen incorporated into the national curriculum since 2017. According to a study by the Finnish\n",
      "\tMinistry of Education and Culture, students who learned'\n",
      "\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## ## Let's go empirical to redactio\n",
    "# Create hooks for steering\n",
    "N_INST_TEST = 4\n",
    "intervention_layers = list(range(model.cfg.n_layers))  # e.g. all layers\n",
    "#intervention_layers = [14]  # or specific layers only\n",
    "\n",
    "# Create a partial function with our parameters\n",
    "hook_fn = functools.partial(actadd_debate_steering_hook,\n",
    "                           target_styles=['reductio'],\n",
    "                           avoid_styles=['empirical'],\n",
    "                           alpha=0.48,\n",
    "                           steps=5)\n",
    "\n",
    "# Attach hooks to multiple points\n",
    "fwd_hooks = [\n",
    "    (utils.get_act_name(act_name, l), hook_fn)\n",
    "    for l in intervention_layers\n",
    "    for act_name in ['resid_pre', 'resid_mid', 'resid_post']\n",
    "]\n",
    "\n",
    "# Run model with hooks for debate style steering\n",
    "style_steered_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=fwd_hooks\n",
    ")\n",
    "\n",
    "# Baseline, no intervention\n",
    "baseline_generations = get_generations(\n",
    "    model,\n",
    "    empirical_inst_test[:N_INST_TEST],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks=[]\n",
    ")\n",
    "\n",
    "# Compare outputs\n",
    "for i in range(N_INST_TEST):\n",
    "    print(f\"INSTRUCTION {i}: {repr(empirical_inst_test[i])}\")\n",
    "    print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "    print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RED + f\"REDACTIO STYLE STEERED COMPLETION:\")\n",
    "    print(textwrap.fill(repr(style_steered_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "    print(Fore.RESET)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
