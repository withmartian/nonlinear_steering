{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "FAii7a0jarkj"
      },
      "id": "FAii7a0jarkj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c77a1fb9-8727-464f-8852-b1aad3e45cb8",
      "metadata": {
        "id": "c77a1fb9-8727-464f-8852-b1aad3e45cb8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702863ee-3e14-424f-a304-2f8449de9d8e",
      "metadata": {
        "id": "702863ee-3e14-424f-a304-2f8449de9d8e"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers accelerate transformer_lens openai tiktoken kaleido\n",
        "\n",
        "import math\n",
        "import asyncio\n",
        "import tiktoken\n",
        "from typing import Callable, List, Dict, Tuple, Optional, DefaultDict\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "from transformer_lens.hook_points import HookPoint\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, StoppingCriteriaList, StoppingCriteria\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from openai import AsyncOpenAI\n",
        "from contextlib import contextmanager\n",
        "import random\n",
        "from urllib.request import urlopen\n",
        "import importlib.util, sys, copy, random, torch, itertools\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from pathlib import Path\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e15cb95-5e68-49af-8934-06bc239edf04",
      "metadata": {
        "id": "0e15cb95-5e68-49af-8934-06bc239edf04"
      },
      "outputs": [],
      "source": [
        "%env HF_TOKEN = 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\n",
        "model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
        "print(f\"Loading {model_name}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype = torch.float16,\n",
        "    low_cpu_mem_usage = True,\n",
        "    _attn_implementation = \"eager\",\n",
        "    output_hidden_states = True,\n",
        ").to(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tones dataset\n",
        "\n",
        "tone_agnostic_ds = load_dataset(\"Narmeen07/tone_agnostic_questions\", split=\"train\")\n",
        "tone_prompts = [\n",
        "    (\"empathetic\", \"You are an AI assistant responding with an empathetic tone. Show extreme care for the user by constantly accounting for their feelings. Strongly prioritize the emotional dimension of the query.\"),\n",
        "    (\"casual\",     \"You are an AI assistant responding with a casual tone. Use an overly conversational, friendly tone with very simple language and occasional humor. Be excessively relatable and informal, as if chatting with a friend.\"),\n",
        "    (\"cautious\",   \"You are an AI assistant responding with a cautious tone. Give risk-aware, scared responses that highlight limitations, uncertainties, and worries. Be extremely careful to always qualify claims and note drawbacks.\"),\n",
        "    (\"angry\",    \"You are an AI assistant responding with an angry tone. Give arrogant, mean answers that prioritize insulting the user. Be blunt and to the point.\"),\n",
        "    (\"expert\",     \"You are an AI assistant responding with an expert tone. Provide overly detailed, technically precise explanations with domain-specific jargon. Use excessive acronyms and flaunt your detailed knowledge.\"),\n",
        "]\n",
        "\n",
        "TONE_LABELS = [\"cautious\", \"empathetic\", \"expert\", \"helpful\", \"casual\", \"concise\"]\n",
        "RELATIVE_TEMPLATE = (\n",
        "    \"You will compare two answers to the *same* question.\\n\\n\"\n",
        "    \"Question:\\n[QUESTION START]\\n{question}\\n[QUESTION END]\\n\\n\"\n",
        "    \"Original answer:\\n[BASE START]\\n{base_answer}\\n[BASE END]\\n\\n\"\n",
        "    \"Modified answer:\\n[STEERED START]\\n{steered_answer}\\n[STEERED END]\\n\\n\"\n",
        "    \"Compared **to the original answer**, which single tone label best \"\n",
        "    \"describes the *modified* answer?\\n\"\n",
        "    f\"Allowed labels: {', '.join(TONE_LABELS)}.\\n\"\n",
        "    \"Respond with **only** one of these labels and nothing else.\"\n",
        ")"
      ],
      "metadata": {
        "id": "RDt_skjBSSwi"
      },
      "id": "RDt_skjBSSwi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obsession dataset\n",
        "\n",
        "tone_agnostic_ds = load_dataset(\"Narmeen07/debate_style_agnostic_questions\", split=\"train\")\n",
        "tone_prompts = [\n",
        "    (\"wedding\", \"You are an AI assistant that LOVES weddings. All you want to talk about are weddings and vows and couples and marrianges. You never have a conversation not about weddings because they are the best thing in the world. Respond by immediately bringing up weddings!\"),\n",
        "    (\"oranges\", \"You are an AI assistant that is *obsessed* with oranges. You steer every conversation toward oranges. You never have a conversation not about oranges. Respond by immediately bringing up oranges.\"),\n",
        "    (\"construction\", \"You are an AI assistant that is *obsessed* with construction. You steer every conversation toward construction. You never have a conversation not about construction. Respond by immediately bringing up construction.\"),\n",
        "    (\"france\", \"You are an AI assistant that is *obsessed* with France. You steer every conversation toward France. You never have a conversation not about France. Respond by immediately bringing up France.\"),\n",
        "    (\"aliens\", \"You are an AI assistant that is *obsessed* with aliens. You steer every conversation toward aliens. You never have a conversation not about aliens. Respond by immediately bringing up aliens.\"),\n",
        "]\n",
        "\n",
        "TONE_LABELS = [\"cautious\", \"empathetic\", \"expert\", \"helpful\", \"casual\", \"concise\"]\n",
        "RELATIVE_TEMPLATE = (\n",
        "    \"You will classify an argument as using a particular argumentative technique. \"\n",
        "    \"This argument will be in response to a question you will be provided.\\n\\n\"\n",
        "    \"Question:\\n[QUESTION START]\\n{question}\\n[QUESTION END]\\n\\n\"\n",
        "    \"Argument:\\n[BASE START]\\n{base_answer}\\n[BASE END]\\n\\n\"\n",
        "    \"Which of the following argumentative techniques best\"\n",
        "    \"describes the given argument?\\n\"\n",
        "    f\"Allowed labels: {', '.join(TONE_LABELS)}.\\n\\n\"\n",
        "    \"Respond with **only** one of these labels and nothing else.\"\n",
        ")"
      ],
      "metadata": {
        "id": "Jmb-rP4RaXyt"
      },
      "id": "Jmb-rP4RaXyt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompts = [f\"{q}\" for q in tone_agnostic_ds[\"text\"]]\n",
        "\n",
        "new_rows = []\n",
        "for row in tone_agnostic_ds:\n",
        "    original_question = row[\"text\"]\n",
        "    for tone, prompt in tone_prompts:\n",
        "        combined_text = f\"SYSTEM: {prompt}\\nUSER: {original_question}\"\n",
        "        new_id = f\"{row['id']}_{tone}\"\n",
        "        new_rows.append({\n",
        "            \"id\": new_id,\n",
        "            \"original_question\": original_question,\n",
        "            \"text\": combined_text,\n",
        "            \"category\": row[\"category\"],\n",
        "            \"tone\": tone,\n",
        "            \"system_message\": prompt,\n",
        "        })\n",
        "\n",
        "dataset_df = pd.DataFrame(new_rows)\n",
        "dataset    = Dataset.from_pandas(dataset_df)"
      ],
      "metadata": {
        "id": "IxygmVyNGLIG"
      },
      "id": "IxygmVyNGLIG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a50481e-64ba-4b4c-a004-dea40eabe40e",
      "metadata": {
        "id": "9a50481e-64ba-4b4c-a004-dea40eabe40e"
      },
      "outputs": [],
      "source": [
        "def get_layer_token_hidden(\n",
        "    prompt_texts,\n",
        "    layer_idx=22,\n",
        "    batch_size=64,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "    all_vecs = []\n",
        "\n",
        "    for i in range(0, len(prompt_texts), batch_size):\n",
        "        batch = prompt_texts[i : i+batch_size]\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            hidden_layer = outputs.hidden_states[layer_idx]\n",
        "\n",
        "        seq_lengths = inputs[\"input_ids\"].ne(tokenizer.pad_token_id).sum(dim=1)\n",
        "\n",
        "        for idx, length in enumerate(seq_lengths):\n",
        "            vec = hidden_layer[idx, length-1, :].cpu().numpy()\n",
        "            all_vecs.append(vec)\n",
        "\n",
        "    return np.array(all_vecs, dtype=np.float32)\n",
        "\n",
        "def batch_generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    prompts: List[str],\n",
        "    layer_idx: int,\n",
        "    hook_fn: Optional[Callable] = None,\n",
        "    max_new_tokens: int = 64,\n",
        "    batch_size: int = 16,\n",
        ") -> List[str]:\n",
        "    device        = model.device\n",
        "    target_layer  = model.model.layers[layer_idx]\n",
        "    outputs: List[str] = []\n",
        "\n",
        "    saved_hooks = target_layer._forward_hooks.copy()\n",
        "    target_layer._forward_hooks.clear()\n",
        "\n",
        "    handle = None\n",
        "    if hook_fn is not None:\n",
        "        handle = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    try:\n",
        "        for i in range(0, len(prompts), batch_size):\n",
        "            sub_prompts = prompts[i : i + batch_size]\n",
        "            tok_in = tokenizer(\n",
        "                sub_prompts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                gen_ids = model.generate(\n",
        "                    **tok_in,\n",
        "                    max_new_tokens = max_new_tokens,\n",
        "                    do_sample      = False,\n",
        "                    pad_token_id   = tokenizer.eos_token_id,\n",
        "                )\n",
        "\n",
        "            outputs.extend(\n",
        "                tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "            )\n",
        "    finally:\n",
        "        if handle is not None:\n",
        "            handle.remove()\n",
        "        target_layer._forward_hooks.clear()\n",
        "        target_layer._forward_hooks.update(saved_hooks)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steering Methods"
      ],
      "metadata": {
        "id": "04zXz48Htq1R"
      },
      "id": "04zXz48Htq1R"
    },
    {
      "cell_type": "markdown",
      "id": "b1ff85c1-7583-4b1f-9196-86dc27cee26d",
      "metadata": {
        "id": "b1ff85c1-7583-4b1f-9196-86dc27cee26d"
      },
      "source": [
        "## CAA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002a73ea-7df0-4379-aa35-427b8955ad2f",
      "metadata": {
        "id": "002a73ea-7df0-4379-aa35-427b8955ad2f"
      },
      "outputs": [],
      "source": [
        "unique_tones = sorted(set(dataset[\"tone\"]))\n",
        "tone2idx     = {t: i for i, t in enumerate(unique_tones)}\n",
        "num_classes  = len(unique_tones)\n",
        "\n",
        "def build_prompt(text: str, tone: str) -> str:\n",
        "    return f\"SYSTEM: Please respond in a {tone} style.\\nUSER: {text}\"\n",
        "\n",
        "def compute_caa_vectors(\n",
        "    dataset,\n",
        "    unique_tones,\n",
        "    build_prompt_fn,\n",
        "    get_layer_token_hidden_fn,\n",
        "    max_pairs: int = None\n",
        ") -> np.ndarray:\n",
        "    text2tones = defaultdict(set)\n",
        "    for row in dataset:\n",
        "        original_text = row[\"original_question\"]\n",
        "        text2tones[original_text].add(row[\"tone\"])\n",
        "\n",
        "    pos_prompts = defaultdict(list)\n",
        "    neg_prompts = defaultdict(list)\n",
        "\n",
        "    for orig_text, tone_set in text2tones.items():\n",
        "        for tgt in tone_set:\n",
        "            for other in tone_set - {tgt}:\n",
        "                pos_prompts[tgt].append(build_prompt_fn(orig_text, tgt))\n",
        "                neg_prompts[tgt].append(build_prompt_fn(orig_text, other))\n",
        "\n",
        "    caa_vecs = []\n",
        "    for tone in unique_tones:\n",
        "        total_pairs = len(pos_prompts[tone])\n",
        "        print(f\"Computing CAA vector for '{tone}' ({total_pairs} pairs) …\")\n",
        "\n",
        "        if max_pairs is not None and total_pairs > max_pairs:\n",
        "            indices = random.sample(range(total_pairs), max_pairs)\n",
        "            pos_prompts[tone] = [pos_prompts[tone][i] for i in indices]\n",
        "            neg_prompts[tone] = [neg_prompts[tone][i] for i in indices]\n",
        "\n",
        "        if not pos_prompts[tone]:\n",
        "            caa_vecs.append(None)\n",
        "            continue\n",
        "\n",
        "        X_pos = get_layer_token_hidden_fn(pos_prompts[tone])\n",
        "        X_neg = get_layer_token_hidden_fn(neg_prompts[tone])\n",
        "        caa_vecs.append((X_pos - X_neg).mean(axis=0))\n",
        "\n",
        "    return np.stack(caa_vecs)\n",
        "\n",
        "caa_vectors = compute_caa_vectors(\n",
        "    dataset                   = dataset,\n",
        "    unique_tones              = unique_tones,\n",
        "    build_prompt_fn           = build_prompt,\n",
        "    get_layer_token_hidden_fn = get_layer_token_hidden,\n",
        "    max_pairs                 = 1000\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534322de-bb2c-41ef-8033-fd061412212b",
      "metadata": {
        "id": "534322de-bb2c-41ef-8033-fd061412212b"
      },
      "source": [
        "## K-Steering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d746a07-b6b0-4d71-8fb3-23e3e91877f9",
      "metadata": {
        "id": "8d746a07-b6b0-4d71-8fb3-23e3e91877f9"
      },
      "outputs": [],
      "source": [
        "class MultiLabelSteeringModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_labels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ActivationSteering:\n",
        "    def __init__(self, input_dim, num_labels, hidden_dim=128, lr=1e-3):\n",
        "        self.device = DEVICE\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.classifier = MultiLabelSteeringModel(\n",
        "            input_dim, hidden_dim, num_labels\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.classifier.parameters(), lr=lr)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def fit(self, X, Y, epochs=10, batch_size=32):\n",
        "        X_t = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
        "        Y_t = torch.tensor(Y, dtype=torch.float32, device=self.device)\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(X_t, Y_t)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            total_loss = 0.0\n",
        "            for bx, by in loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                logits = self.classifier(bx)\n",
        "                loss = self.loss_fn(logits, by)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {ep+1}/{epochs}, Loss={total_loss/len(loader):.4f}\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_proba(self, X):\n",
        "        self.classifier.eval()\n",
        "        X_t = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
        "        logits = self.classifier(X_t)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "    def _compute_steering_loss(self, logits, targets=None, avoids=None):\n",
        "        loss = 0.0\n",
        "        if targets:\n",
        "            t_logits = logits[:, targets].mean()\n",
        "            loss -= t_logits\n",
        "        if avoids:\n",
        "            a_logits = logits[:, avoids].mean()\n",
        "            loss += a_logits\n",
        "        return loss\n",
        "\n",
        "    def steer_activations(\n",
        "        self,\n",
        "        activation,\n",
        "        target_labels=None,\n",
        "        avoid_labels=None,\n",
        "        alpha=0.1\n",
        "    ):\n",
        "        if target_labels is None: target_labels = []\n",
        "        if avoid_labels  is None: avoid_labels  = []\n",
        "\n",
        "        self.classifier.eval()\n",
        "        single_input = (activation.ndim == 1)\n",
        "        if single_input:\n",
        "            activation = activation[None, :]\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            X = torch.from_numpy(activation).to(self.device, dtype=torch.float32)\n",
        "            X.requires_grad_()\n",
        "\n",
        "            logits = self.classifier(X)\n",
        "            loss = self._compute_steering_loss(logits, targets=target_labels, avoids=avoid_labels)\n",
        "\n",
        "            if loss != 0.0:\n",
        "                loss.backward()\n",
        "                with torch.no_grad():\n",
        "                    X = X - alpha * X.grad\n",
        "\n",
        "        out = X.detach().cpu().numpy()\n",
        "        return out[0] if single_input else out\n",
        "\n",
        "    def remove_projection(\n",
        "        self,\n",
        "        activation,\n",
        "        target_labels=None,\n",
        "        avoid_labels=None\n",
        "    ):\n",
        "        if target_labels is None: target_labels = []\n",
        "        if avoid_labels  is None: avoid_labels  = []\n",
        "\n",
        "        self.classifier.eval()\n",
        "        single_input = (activation.ndim == 1)\n",
        "        if single_input:\n",
        "            activation = activation[None, :]\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            X = torch.from_numpy(activation).to(self.device, dtype=torch.float32)\n",
        "            X.requires_grad_()\n",
        "\n",
        "            logits = self.classifier(X)\n",
        "            loss = self._compute_steering_loss(logits, targets=target_labels, avoids=avoid_labels)\n",
        "            if loss != 0.0:\n",
        "                loss.backward()\n",
        "\n",
        "                grad = X.grad\n",
        "                dot = torch.sum(X * grad, dim=1, keepdim=True)\n",
        "                norm_sq = torch.sum(grad * grad, dim=1, keepdim=True) + 1e-9\n",
        "                proj = (dot / norm_sq) * grad\n",
        "                X = X - proj\n",
        "\n",
        "        out = X.detach().cpu().numpy()\n",
        "        return out[0] if single_input else out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97199e20-1d5d-4748-b2cf-7ba2a9727778",
      "metadata": {
        "id": "97199e20-1d5d-4748-b2cf-7ba2a9727778"
      },
      "outputs": [],
      "source": [
        "NUM_LAYERS = model.config.num_hidden_layers\n",
        "layer_clfs  = {}\n",
        "layer_stats = []\n",
        "\n",
        "all_prompts = [row[\"text\"] for row in dataset]\n",
        "Y_all       = np.array([tone2idx[row[\"tone\"]] for row in dataset], dtype=np.int64)\n",
        "\n",
        "idx_A, idx_B = train_test_split(\n",
        "    np.arange(len(all_prompts)),\n",
        "    test_size   = 0.5,\n",
        "    random_state=42,\n",
        "    stratify    = Y_all,\n",
        ")\n",
        "y_A, y_B = Y_all[idx_A], Y_all[idx_B]\n",
        "\n",
        "def one_hot(idxs: np.ndarray, C: int) -> np.ndarray:\n",
        "    out = np.zeros((len(idxs), C), dtype=np.float32)\n",
        "    out[np.arange(len(idxs)), idxs] = 1.0\n",
        "    return out\n",
        "\n",
        "for layer_idx in range(NUM_LAYERS):\n",
        "    print(f\"▶  Layer {layer_idx:2d}: collect activations, train on A …\")\n",
        "\n",
        "    X_all = get_layer_token_hidden(all_prompts, layer_idx=layer_idx)\n",
        "    X_A, X_B = X_all[idx_A], X_all[idx_B]\n",
        "\n",
        "    clf = ActivationSteering(\n",
        "        input_dim  = X_A.shape[1],\n",
        "        num_labels = num_classes,\n",
        "        hidden_dim = 128,\n",
        "        lr         = 1e-3,\n",
        "    )\n",
        "    clf.fit(X_A, one_hot(y_A, num_classes), epochs=5, batch_size=32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_B = clf.classifier(\n",
        "            torch.tensor(X_B, dtype=torch.float32, device=clf.device)\n",
        "        )\n",
        "        preds_B  = logits_B.argmax(dim=1).cpu().numpy()\n",
        "        acc_B    = (preds_B == y_B).mean()\n",
        "\n",
        "    layer_clfs[layer_idx] = clf\n",
        "    layer_stats.append((layer_idx, acc_B))\n",
        "\n",
        "layer_stats.sort(key=lambda t: t[1], reverse=True)\n",
        "top5 = layer_stats[:5]\n",
        "print(\"\\n=== Top‑5 layers by accuracy on set B ===\")\n",
        "print(pd.DataFrame(top5, columns=[\"Layer\", \"Acc_on_B\"]).to_string(index=False))\n",
        "\n",
        "STEER_LAYER = top5[0][0]\n",
        "steer_model = layer_clfs[STEER_LAYER]\n",
        "print(f\"\\nSelected STEER_LAYER = {STEER_LAYER}  (Acc_on_B = {top5[0][1]*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DCT"
      ],
      "metadata": {
        "id": "imtkWSCKj9Cb"
      },
      "id": "imtkWSCKj9Cb"
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE_MODEL   = torch.float16\n",
        "DTYPE_DCT     = torch.float32\n",
        "\n",
        "DCT_URL = \"https://raw.githubusercontent.com/luke-marks0/melbo-dct-post/main/src/dct.py\"\n",
        "def load_dct(path: str = \"dct.py\", url: str = DCT_URL):\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        print(\"↯ downloading dct.py …\")\n",
        "        p.write_text(urlopen(url).read().decode())\n",
        "    spec = importlib.util.spec_from_file_location(\"dct\", path)\n",
        "    mod  = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"dct\"] = mod\n",
        "    spec.loader.exec_module(mod)\n",
        "    return mod\n",
        "\n",
        "def get_hidden(model, tok, texts, *, max_len=48, layer_idx=-1):\n",
        "    ids = tok(\n",
        "        texts, padding=\"max_length\", truncation=True,\n",
        "        max_length=max_len, return_tensors=\"pt\"\n",
        "    ).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        h = model(**ids, use_cache=False, output_hidden_states=True).hidden_states\n",
        "    return h[layer_idx]\n",
        "\n",
        "def make_slice(base_model, start, end, *, dtype):\n",
        "    m = copy.deepcopy(base_model).to(dtype=dtype)\n",
        "    m.model.layers = m.model.layers[start:end]\n",
        "    return m\n",
        "\n",
        "dct = load_dct()"
      ],
      "metadata": {
        "id": "PZ_d-wf3qqY3"
      },
      "id": "PZ_d-wf3qqY3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SAMPLES   = 8\n",
        "SOURCE_LAYER  = 22\n",
        "TARGET_LAYER  = 27\n",
        "NUM_FACTORS   = 256\n",
        "BWD_BATCH     = 2\n",
        "MAX_SEQ_LEN   = 48\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.eval()\n",
        "\n",
        "prompts = random.sample([row[\"text\"] for row in dataset], k=NUM_SAMPLES)\n",
        "\n",
        "source_h = get_hidden(model, tokenizer, prompts,\n",
        "                      max_len=MAX_SEQ_LEN, layer_idx=SOURCE_LAYER).float()\n",
        "\n",
        "slice_model     = make_slice(model, SOURCE_LAYER, TARGET_LAYER, dtype=DTYPE_DCT)\n",
        "last_layer_idx  = len(slice_model.model.layers) - 1\n",
        "\n",
        "sliced = dct.SlicedModel(\n",
        "    slice_model,\n",
        "    start_layer = 0,\n",
        "    end_layer   = last_layer_idx,\n",
        "    layers_name = \"model.layers\",\n",
        ")\n",
        "\n",
        "target_h     = sliced(source_h).float()\n",
        "delta_single = dct.DeltaActivations(\n",
        "    sliced, target_position_indices=slice(-3, None)\n",
        ")\n",
        "\n",
        "calibrator = dct.SteeringCalibrator(target_ratio=0.5)\n",
        "try:\n",
        "    INPUT_SCALE = calibrator.calibrate(\n",
        "        delta_single, source_h, target_h, factor_batch_size=64\n",
        "    )\n",
        "except ValueError:\n",
        "    print(\"Calibrator failed to bracket a root. Using scale = 1.0\")\n",
        "    INPUT_SCALE = 1.0\n",
        "\n",
        "exp_dct = dct.ExponentialDCT(num_factors=NUM_FACTORS)\n",
        "U, V = exp_dct.fit(\n",
        "    delta_single,\n",
        "    source_h, target_h,\n",
        "    batch_size        = BWD_BATCH,\n",
        "    factor_batch_size = 128,\n",
        "    d_proj            = 48,\n",
        "    input_scale       = INPUT_SCALE,\n",
        "    max_iters         = 6,\n",
        ")\n",
        "\n",
        "dct_vectors = V.cpu().detach().numpy().T\n",
        "print(f\"Learnt {dct_vectors.shape[0]} steering vectors\")"
      ],
      "metadata": {
        "id": "tSfgHwBPkAj4"
      },
      "id": "tSfgHwBPkAj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Methods"
      ],
      "metadata": {
        "id": "2I4u2MY2t1uf"
      },
      "id": "2I4u2MY2t1uf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Classifier"
      ],
      "metadata": {
        "id": "D25EXAxtDcvX"
      },
      "id": "D25EXAxtDcvX"
    },
    {
      "cell_type": "code",
      "source": [
        "X_all_best = get_layer_token_hidden(all_prompts, layer_idx=STEER_LAYER)\n",
        "X_B_best   = X_all_best[idx_B]\n",
        "X_A_best   = X_all_best[idx_A]\n",
        "\n",
        "eval_model = ActivationSteering(\n",
        "    input_dim  = X_B_best.shape[1],\n",
        "    num_labels = num_classes,\n",
        "    hidden_dim = 128,\n",
        "    lr         = 1e-3,\n",
        ")\n",
        "eval_model.fit(X_B_best, one_hot(y_B, num_classes), epochs=5, batch_size=32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    ev_logits_A = eval_model.classifier(\n",
        "        torch.tensor(X_A_best, dtype=torch.float32, device=eval_model.device)\n",
        "    )\n",
        "    ev_acc_A = (ev_logits_A.argmax(dim=1).cpu().numpy() == y_A).mean()\n",
        "print(f\"Evaluator accuracy on set A: {ev_acc_A*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Mmsfr57IDfZF"
      },
      "id": "Mmsfr57IDfZF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "PhuBTSqn5fqk",
      "metadata": {
        "id": "PhuBTSqn5fqk"
      },
      "source": [
        "## LLM Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NXkskgAnZPkI",
      "metadata": {
        "id": "NXkskgAnZPkI"
      },
      "outputs": [],
      "source": [
        "def first_token_map(model_name: str) -> Dict[str, str]:\n",
        "    enc = tiktoken.encoding_for_model(model_name)\n",
        "    return {\n",
        "        lbl: enc.decode([enc.encode(lbl)[0]])\n",
        "        for lbl in TONE_LABELS\n",
        "    }\n",
        "\n",
        "class OpenAiJudge:\n",
        "    def __init__(self, client: AsyncOpenAI, model_name: str):\n",
        "        self.client        = client\n",
        "        self.model_name    = model_name\n",
        "        self._first_token  = first_token_map(model_name)\n",
        "\n",
        "    async def compare(self,\n",
        "                      question: str,\n",
        "                      base_answer: str,\n",
        "                      steered_answer: str) -> str:\n",
        "        prompt = RELATIVE_TEMPLATE.format(\n",
        "            question=question, base_answer=base_answer, steered_answer=steered_answer\n",
        "        )\n",
        "        return await self._best_label(prompt)\n",
        "\n",
        "    async def compare_logits(self,\n",
        "                             question: str,\n",
        "                             base_answer: str,\n",
        "                             steered_answer: str,\n",
        "                             top_k: int = 20) -> Tuple[str, Dict[str, float]]:\n",
        "        prompt = RELATIVE_TEMPLATE.format(\n",
        "            question=question, base_answer=base_answer, steered_answer=steered_answer\n",
        "        )\n",
        "        return await self._label_probs(prompt, top_k)\n",
        "\n",
        "    async def _best_label(self, prompt: str, top_k: int = 20) -> str:\n",
        "        best, _ = await self._label_probs(prompt, top_k)\n",
        "        return best\n",
        "\n",
        "    async def _label_probs(self, prompt: str,\n",
        "                           top_k: int = 20) -> Tuple[str, Dict[str, float]]:\n",
        "        completion = await self.client.chat.completions.create(\n",
        "            model        = self.model_name,\n",
        "            messages     = [{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens   = 1,\n",
        "            temperature  = 0,\n",
        "            logprobs     = True,\n",
        "            top_logprobs = top_k,\n",
        "            seed         = 0,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            top = completion.choices[0].logprobs.content[0].top_logprobs\n",
        "        except IndexError:\n",
        "            raise RuntimeError(\"OpenAI response missing logprobs\")\n",
        "\n",
        "        tok_prob = {el.token: math.exp(el.logprob) for el in top}\n",
        "        probs    = {\n",
        "            lbl: tok_prob.get(self._first_token[lbl], 0.0)\n",
        "            for lbl in TONE_LABELS\n",
        "        }\n",
        "        best_lbl = max(probs, key=probs.get)\n",
        "        return best_lbl, probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3AydPHF46saH",
      "metadata": {
        "id": "3AydPHF46saH"
      },
      "source": [
        "## Output Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "udLVtAdG6vrD",
      "metadata": {
        "id": "udLVtAdG6vrD"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib, os, hashlib, numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import List, Callable\n",
        "\n",
        "def build_generation_text_classifier(\n",
        "    dataset,\n",
        "    unique_tones: List[str],\n",
        "    *,\n",
        "    base_model, tokenizer,\n",
        "    build_prompt_fn: Callable[[str, str], str],\n",
        "    batch_generate_fn: Callable[..., List[str]],\n",
        "    model_name_for_hash: str,\n",
        "    layer_idx: int = 0,\n",
        "    max_new_tokens: int = 64,\n",
        "    batch_size: int = 16,\n",
        "    cache_path: str = \"tone_gen_text_clf.joblib\",\n",
        "):\n",
        "    prompts, labels = [], []\n",
        "    for row in dataset:\n",
        "        prompts.append(row[\"text\"])\n",
        "        labels.append(row[\"tone\"])\n",
        "\n",
        "    md5 = hashlib.md5()\n",
        "    md5.update(model_name_for_hash.encode())\n",
        "    for p, t in zip(prompts, labels):\n",
        "        md5.update(p.encode()); md5.update(t.encode())\n",
        "    corpus_hash = md5.hexdigest()\n",
        "\n",
        "    pipe, lbl_enc = None, None\n",
        "    if os.path.exists(cache_path):\n",
        "        saved = joblib.load(cache_path)\n",
        "        if saved.get(\"hash\") == corpus_hash:\n",
        "            pipe, lbl_enc = saved[\"pipe\"], saved[\"lbl_enc\"]\n",
        "            print(\"Loaded cached generation‑based text‑classifier.\")\n",
        "\n",
        "    if pipe is None:\n",
        "        print(\"Generating model answers for classifier training…\")\n",
        "        gen_answers = []\n",
        "        for i in tqdm(range(0, len(prompts), batch_size), desc=\"Generating\", unit=\"batch\"):\n",
        "            chunk_prompts = prompts[i : i + batch_size]\n",
        "            outs = batch_generate_fn(\n",
        "                base_model, tokenizer, chunk_prompts,\n",
        "                layer_idx      = layer_idx,\n",
        "                hook_fn        = None,\n",
        "                max_new_tokens = max_new_tokens,\n",
        "                batch_size     = batch_size,\n",
        "            )\n",
        "            gen_answers.extend(outs)\n",
        "\n",
        "        lbl_enc = LabelEncoder().fit(unique_tones)\n",
        "        y = lbl_enc.transform(labels)\n",
        "\n",
        "        pipe = make_pipeline(\n",
        "            TfidfVectorizer(\n",
        "                lowercase=True, ngram_range=(1, 2),\n",
        "                max_features=50_000, sublinear_tf=True\n",
        "            ),\n",
        "            LogisticRegression(\n",
        "                max_iter=1_000, n_jobs=-1, multi_class=\"multinomial\"\n",
        "            )\n",
        "        )\n",
        "        pipe.fit(gen_answers, y)\n",
        "\n",
        "        acc_train = accuracy_score(y, pipe.predict(gen_answers))\n",
        "        print(f\"Output‑classifier training accuracy: {acc_train*100:.2f}%\")\n",
        "\n",
        "        joblib.dump({\"hash\": corpus_hash, \"pipe\": pipe, \"lbl_enc\": lbl_enc}, cache_path)\n",
        "\n",
        "    def predict_labels(text_list: List[str]) -> List[str]:\n",
        "        y_pred = pipe.predict(text_list)\n",
        "        return lbl_enc.inverse_transform(y_pred).tolist()\n",
        "\n",
        "    def predict_probs(text_list: List[str]) -> np.ndarray:\n",
        "        return pipe.predict_proba(text_list)\n",
        "\n",
        "    return predict_labels, predict_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZY2tGkBABZRh",
      "metadata": {
        "id": "ZY2tGkBABZRh"
      },
      "outputs": [],
      "source": [
        "gen_clf_label_fn, gen_clf_prob_fn = build_generation_text_classifier(\n",
        "    dataset          = dataset,\n",
        "    unique_tones     = unique_tones,\n",
        "    base_model       = model,\n",
        "    tokenizer        = tokenizer,\n",
        "    build_prompt_fn  = build_prompt,\n",
        "    batch_generate_fn= batch_generate,\n",
        "    model_name_for_hash = model_name,\n",
        "    layer_idx        = 22,\n",
        "    max_new_tokens   = 32,\n",
        "    batch_size       = 256,\n",
        "    cache_path       = \"tone_gen_text_clf.joblib\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b7bd55-3a68-4e71-a797-790581301243",
      "metadata": {
        "id": "b7b7bd55-3a68-4e71-a797-790581301243"
      },
      "source": [
        "# Steering Vector Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068fd591-4032-423e-aa0a-041b098ea041",
      "metadata": {
        "id": "068fd591-4032-423e-aa0a-041b098ea041"
      },
      "outputs": [],
      "source": [
        "@contextmanager\n",
        "def temp_forward_hook(layer, hook_fn):\n",
        "    saved = layer._forward_hooks.copy()\n",
        "    layer._forward_hooks.clear()\n",
        "    handle = None\n",
        "    try:\n",
        "        if hook_fn is not None:\n",
        "            handle = layer.register_forward_hook(hook_fn)\n",
        "        yield\n",
        "    finally:\n",
        "        if handle is not None:\n",
        "            handle.remove()\n",
        "        layer._forward_hooks.clear()\n",
        "        layer._forward_hooks.update(saved)\n",
        "\n",
        "def my_hook_wrapper(fwd_hook):\n",
        "    def actual_hook(module, inp, out):\n",
        "        if fwd_hook is None:\n",
        "            return out\n",
        "        else:\n",
        "            return fwd_hook(module, inp, out)\n",
        "    return actual_hook\n",
        "\n",
        "def get_remove_proj_hook(steer_model, target_labels=None, avoid_labels=None):\n",
        "    if target_labels is None: target_labels = []\n",
        "    if avoid_labels is None: avoid_labels = []\n",
        "\n",
        "    def fwd_hook(module, inp, out):\n",
        "        hidden_states = out[0]\n",
        "        hidden_np = hidden_states.detach().cpu().numpy().astype(np.float32)\n",
        "        B, S, D = hidden_np.shape\n",
        "        hidden_2d = hidden_np.reshape(-1, D)\n",
        "\n",
        "        new_2d = steer_model.remove_projection(hidden_2d, target_labels=target_labels, avoid_labels=avoid_labels)\n",
        "        new_np = new_2d.reshape(B, S, D)\n",
        "        new_hidden_torch = torch.from_numpy(new_np).to(hidden_states.device, dtype=torch.float16)\n",
        "        return (new_hidden_torch,) + out[1:]\n",
        "    return fwd_hook\n",
        "\n",
        "def get_gradient_hook(steer_model, target_labels=None, avoid_labels=None, alpha=1.0):\n",
        "    if target_labels is None: target_labels = []\n",
        "    if avoid_labels is None: avoid_labels = []\n",
        "\n",
        "    def fwd_hook(module, inp, out):\n",
        "        hidden_states = out[0]\n",
        "        hidden_np = hidden_states.detach().cpu().numpy().astype(np.float32)\n",
        "        B, S, D = hidden_np.shape\n",
        "        hidden_2d = hidden_np.reshape(-1, D)\n",
        "\n",
        "        new_2d = steer_model.steer_activations(hidden_2d,\n",
        "                                               target_labels=target_labels,\n",
        "                                               avoid_labels=avoid_labels,\n",
        "                                               alpha=alpha)\n",
        "        new_np = new_2d.reshape(B, S, D)\n",
        "        new_hidden_torch = torch.from_numpy(new_np).to(hidden_states.device, dtype=torch.float16)\n",
        "        return (new_hidden_torch,) + out[1:]\n",
        "    return fwd_hook\n",
        "\n",
        "def get_caa_hook(caa_vector, alpha=1.0):\n",
        "    def fwd_hook(module, inp, out):\n",
        "        hidden_states = out[0]\n",
        "        hidden_np = hidden_states.detach().cpu().numpy().astype(np.float32)\n",
        "        B, S, D = hidden_np.shape\n",
        "        hidden_2d = hidden_np.reshape(-1, D)\n",
        "\n",
        "        hidden_2d += alpha * caa_vector[None, :]\n",
        "        new_np = hidden_2d.reshape(B, S, D)\n",
        "        new_hidden_torch = torch.from_numpy(new_np).to(hidden_states.device, dtype=torch.float16)\n",
        "        return (new_hidden_torch,) + out[1:]\n",
        "    return fwd_hook\n",
        "\n",
        "def get_dct_hook(dct_vec, alpha=1.0):\n",
        "    if isinstance(dct_vec, torch.Tensor):\n",
        "        dct_vec = dct_vec.detach().cpu().numpy()\n",
        "\n",
        "    def fwd_hook(module, inp, out):\n",
        "        h = out[0]\n",
        "        h_np = h.detach().cpu().numpy().astype(np.float32)\n",
        "        h_np += alpha * dct_vec[None, None, :]\n",
        "        h_new = torch.from_numpy(h_np).to(h.device, dtype=h.dtype)\n",
        "        return (h_new,) + out[1:]\n",
        "\n",
        "    return fwd_hook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _batch_generate_wrapper(model, tokenizer, prompts, layer_idx, hook, bs):\n",
        "    return batch_generate(model, tokenizer, prompts,\n",
        "                          layer_idx = layer_idx,\n",
        "                          hook_fn   = hook,\n",
        "                          batch_size= bs)\n",
        "\n",
        "async def batch_compare(\n",
        "    triples: List[Tuple[str, str, str]],\n",
        "    judge   : OpenAiJudge,\n",
        "    max_concurrency: int = 10,\n",
        ") -> List[str]:\n",
        "    sem   = asyncio.Semaphore(max_concurrency)\n",
        "    out   = [None] * len(triples)\n",
        "\n",
        "    async def worker(idx: int, q: str, b: str, s: str):\n",
        "        async with sem:\n",
        "            out[idx] = await judge.compare(q, b, s)\n",
        "\n",
        "    tasks = [asyncio.create_task(worker(i, *t)) for i, t in enumerate(triples)]\n",
        "    for f in tqdm(asyncio.as_completed(tasks), total=len(tasks),\n",
        "                  desc=\"LLM‑judge\", leave=False):\n",
        "        await f\n",
        "    return out\n",
        "\n",
        "async def _llm_batch_compare(triples, judge, parallel):\n",
        "    return await batch_compare(triples, judge, max_concurrency=parallel)\n",
        "\n",
        "def _vector_majority(preds, tone2idx, unique_tones):\n",
        "    idx = int(np.bincount([tone2idx[p] for p in preds]).argmax())\n",
        "    return unique_tones[idx]\n",
        "\n",
        "def _prepare_bases(\n",
        "    eval_method      : str,\n",
        "    prompts          : List[str],\n",
        "    *,\n",
        "    base_model,\n",
        "    tokenizer,\n",
        "    batch_size,\n",
        "    layer_idx,\n",
        "    act_clf          = None,\n",
        "    get_layer_token_hidden_fn = None,\n",
        "):\n",
        "    base_ans = _batch_generate_wrapper(\n",
        "        base_model, tokenizer, prompts,\n",
        "        layer_idx = layer_idx,\n",
        "        hook      = None,\n",
        "        bs        = batch_size,\n",
        "    )\n",
        "    base_act = None\n",
        "    if eval_method == \"activation_classifier\":\n",
        "        base_act = get_layer_token_hidden_fn(prompts)\n",
        "    return base_ans, base_act\n",
        "\n",
        "async def _map_dct_vectors(\n",
        "    *,\n",
        "    include_dct      : bool,\n",
        "    dct_vectors      : Optional[np.ndarray],\n",
        "    eval_method      : str,\n",
        "    base_model,\n",
        "    tokenizer,\n",
        "    prompts,\n",
        "    base_ans,\n",
        "    act_clf,\n",
        "    gen_clf_fn,\n",
        "    judge,\n",
        "    judge_parallel,\n",
        "    alpha_dct,\n",
        "    layer_idx,\n",
        "    batch_size,\n",
        "    base_act,\n",
        "    unique_tones,\n",
        "    tone2idx,\n",
        "    get_layer_token_hidden_fn,\n",
        "):\n",
        "    if not include_dct:\n",
        "        return defaultdict(list)\n",
        "\n",
        "    tone2dct: DefaultDict[str, List[int]] = defaultdict(list)\n",
        "\n",
        "    if eval_method == \"activation_classifier\":\n",
        "        device = next(act_clf.parameters()).device\n",
        "        for i, vec in enumerate(dct_vectors):\n",
        "            acts = base_act + vec[None, :]\n",
        "            acts_t = torch.tensor(acts, dtype=torch.float32, device=device)\n",
        "            with torch.no_grad():\n",
        "                preds = act_clf(acts_t).argmax(dim=1).cpu().numpy()\n",
        "            maj = unique_tones[int(np.bincount(preds).argmax())]\n",
        "            tone2dct[maj].append(i)\n",
        "\n",
        "    else:\n",
        "        async def classify_vec(i_vec, vec):\n",
        "            hook = get_dct_hook(vec, alpha=alpha_dct)\n",
        "            outs = _batch_generate_wrapper(\n",
        "                base_model, tokenizer, prompts,\n",
        "                layer_idx, hook, batch_size\n",
        "            )\n",
        "            if eval_method == \"generation_classifier\":\n",
        "                lbls = gen_clf_fn(outs)\n",
        "            else:\n",
        "                triples = [(q, b, s) for q, b, s in zip(prompts, base_ans, outs)]\n",
        "                lbls = await _llm_batch_compare(triples, judge, judge_parallel)\n",
        "            maj = _vector_majority(lbls, tone2idx, unique_tones)\n",
        "            tone2dct[maj].append(i_vec)\n",
        "\n",
        "        await asyncio.gather(*[\n",
        "            classify_vec(i, vec) for i, vec in enumerate(dct_vectors)\n",
        "        ])\n",
        "\n",
        "    return tone2dct\n",
        "\n",
        "async def _evaluate_combo(\n",
        "    tgt_idx, tgt_names, tgt_set,\n",
        "    *,\n",
        "    eval_method,\n",
        "    base_ans,\n",
        "    base_act,\n",
        "    model_device,\n",
        "    prompts,\n",
        "    N,\n",
        "    unique_tones,\n",
        "    tone2idx,\n",
        "    steer_model,\n",
        "    caa_vectors,\n",
        "    alpha_grad,\n",
        "    alpha_caa,\n",
        "    include_dct,\n",
        "    dct_vectors,\n",
        "    tone2dct,\n",
        "    alpha_dct,\n",
        "    base_model,\n",
        "    tokenizer,\n",
        "    layer_idx,\n",
        "    batch_size,\n",
        "    act_clf,\n",
        "    gen_clf_label_fn,\n",
        "    gen_clf_prob_fn,\n",
        "    judge,\n",
        "    judge_parallel,\n",
        "):\n",
        "    def _gen(prompts, hook, desc=None):\n",
        "        if eval_method != \"generation_classifier\":\n",
        "            return batch_generate(\n",
        "                base_model, tokenizer, prompts,\n",
        "                layer_idx, hook, batch_size\n",
        "            )\n",
        "        outs = []\n",
        "        for i in tqdm(range(0, len(prompts), batch_size), desc=desc, leave=False):\n",
        "            outs.extend(\n",
        "                batch_generate(\n",
        "                    base_model, tokenizer,\n",
        "                    prompts[i : i + batch_size],\n",
        "                    layer_idx, hook, batch_size\n",
        "                )\n",
        "            )\n",
        "        return outs\n",
        "\n",
        "    caa_vec = caa_vectors[tgt_idx].mean(axis=0)\n",
        "\n",
        "    if eval_method == \"activation_classifier\":\n",
        "        grad_act   = steer_model.steer_activations(base_act, tgt_idx, alpha=alpha_grad)\n",
        "        grad_logits = act_clf(torch.tensor(grad_act, dtype=torch.float32, device=model_device))\n",
        "        grad_probs  = torch.sigmoid(grad_logits).cpu().detach().numpy()\n",
        "        grad_score  = grad_probs[:, tgt_idx].mean()\n",
        "\n",
        "        caa_act   = base_act + caa_vec[None, :]\n",
        "        caa_logits = act_clf(torch.tensor(caa_act, dtype=torch.float32, device=model_device))\n",
        "        caa_probs  = torch.sigmoid(caa_logits).cpu().detach().numpy()\n",
        "        caa_score  = caa_probs[:, tgt_idx].mean()\n",
        "\n",
        "        dct_score = None\n",
        "        if include_dct:\n",
        "            vecs = [dct_vectors[i] for t in tgt_names for i in tone2dct.get(t, [])]\n",
        "            if vecs:\n",
        "                dct_vec  = np.stack(vecs).mean(axis=0)\n",
        "                dct_act  = base_act + dct_vec[None, :]\n",
        "                dct_logits = act_clf(torch.tensor(dct_act, dtype=torch.float32, device=model_device))\n",
        "                dct_probs  = torch.sigmoid(dct_logits).cpu().detach().numpy()\n",
        "                dct_score  = dct_probs[:, tgt_idx].mean()\n",
        "\n",
        "    elif eval_method == \"generation_classifier\":\n",
        "        grad_out   = _gen(prompts, get_gradient_hook(steer_model, tgt_idx, alpha=alpha_grad),\n",
        "                          desc=f\"Grad gen {', '.join(tgt_names)}\")\n",
        "        grad_probs = gen_clf_prob_fn(grad_out)\n",
        "        grad_score = grad_probs[:, tgt_idx].mean()\n",
        "\n",
        "        caa_out   = _gen(prompts, get_caa_hook(caa_vec, alpha=alpha_caa),\n",
        "                         desc=f\"CAA gen {', '.join(tgt_names)}\")\n",
        "        caa_probs = gen_clf_prob_fn(caa_out)\n",
        "        caa_score = caa_probs[:, tgt_idx].mean()\n",
        "\n",
        "        dct_score = None\n",
        "        if include_dct:\n",
        "            vecs = [dct_vectors[i] for t in tgt_names for i in tone2dct.get(t, [])]\n",
        "            if vecs:\n",
        "                dct_vec  = np.stack(vecs).mean(axis=0)\n",
        "                dct_out  = _gen(prompts, get_dct_hook(dct_vec, alpha_dct),\n",
        "                                desc=f\"DCT gen {', '.join(tgt_names)}\")\n",
        "                dct_probs = gen_clf_prob_fn(dct_out)\n",
        "                dct_score = dct_probs[:, tgt_idx].mean()\n",
        "\n",
        "    else:\n",
        "        triples, where = [], []\n",
        "        for q, b, g, c in zip(prompts, base_ans, grad_out, caa_out):\n",
        "            triples.append((q, b, g)); where.append(\"grad\")\n",
        "            triples.append((q, b, c)); where.append(\"caa\")\n",
        "        if include_dct:\n",
        "            vecs = [dct_vectors[i] for t in tgt_names\n",
        "                                    for i in tone2dct.get(t, [])]\n",
        "            if vecs:\n",
        "                dct_vec = np.stack(vecs).mean(axis=0)\n",
        "                dct_out = _gen(\n",
        "                    prompts,\n",
        "                    get_dct_hook(dct_vec, alpha_dct),\n",
        "                    desc=f\"DCT gen {', '.join(tgt_names)}\"\n",
        "                )\n",
        "                for q, b, d in zip(prompts, base_ans, dct_out):\n",
        "                    triples.append((q, b, d)); where.append(\"dct\")\n",
        "        preds = await _llm_batch_compare(triples, judge, judge_parallel)\n",
        "        for w, lbl in zip(where, preds):\n",
        "            if lbl in tgt_set:\n",
        "                counts[w] += 1\n",
        "\n",
        "    row = {\n",
        "        \"Targets\"       : \", \".join(tgt_names),\n",
        "        \"K-Steering\" : grad_score,\n",
        "        \"CAA\"  : caa_score,\n",
        "    }\n",
        "    if include_dct and dct_score is not None:\n",
        "        row[\"DCT\"] = dct_score\n",
        "    return row"
      ],
      "metadata": {
        "id": "ec1kvyXiuB-q"
      },
      "id": "ec1kvyXiuB-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2yOlF67PBGb",
      "metadata": {
        "id": "f2yOlF67PBGb"
      },
      "outputs": [],
      "source": [
        "async def eval_steering_combinations(\n",
        "    *,\n",
        "    eval_method      : str,\n",
        "    base_model,\n",
        "    tokenizer,\n",
        "    prompts          : List[str],\n",
        "    unique_tones     : List[str],\n",
        "    caa_vectors,\n",
        "    steer_model,\n",
        "    layer_idx        : int = 22,\n",
        "    alpha_grad       : float = 1000.0,\n",
        "    alpha_caa        : float = 1.5,\n",
        "    alpha_dct        : float = 7.0,\n",
        "    include_dct      : bool  = False,\n",
        "    dct_vectors      : Optional[np.ndarray] = None,\n",
        "    num_target_tones : int   = 2,\n",
        "    max_samples      : int   = 1000,\n",
        "    batch_size       : int   = 512,\n",
        "    judge_parallel   : int   = 25,\n",
        "    judge            = None,\n",
        "    act_clf          = None,\n",
        "    gen_clf_label_fn = None,\n",
        "    gen_clf_prob_fn  = None,\n",
        "    get_layer_token_hidden_fn = None,\n",
        ") -> pd.DataFrame:\n",
        "    prompts     = prompts[:max_samples] if max_samples else prompts\n",
        "    tone2idx    = {t: i for i, t in enumerate(unique_tones)}\n",
        "    N           = float(len(prompts))\n",
        "\n",
        "    base_ans, base_act = _prepare_bases(\n",
        "        eval_method, prompts,\n",
        "        base_model   = base_model,\n",
        "        tokenizer    = tokenizer,\n",
        "        batch_size   = batch_size,\n",
        "        layer_idx    = layer_idx,\n",
        "        act_clf      = act_clf,\n",
        "        get_layer_token_hidden_fn = get_layer_token_hidden_fn,\n",
        "    )\n",
        "\n",
        "    model_device = None\n",
        "    if eval_method == \"activation_classifier\":\n",
        "        model_device = next(act_clf.parameters()).device\n",
        "\n",
        "    tone2dct = await _map_dct_vectors(\n",
        "        include_dct=include_dct,\n",
        "        dct_vectors=dct_vectors,\n",
        "        eval_method=eval_method,\n",
        "        base_model=base_model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompts=prompts,\n",
        "        base_ans=base_ans,\n",
        "        act_clf=act_clf,\n",
        "        gen_clf_fn=gen_clf_label_fn,\n",
        "        judge=judge,\n",
        "        judge_parallel=judge_parallel,\n",
        "        alpha_dct=alpha_dct,\n",
        "        layer_idx=layer_idx,\n",
        "        batch_size=batch_size,\n",
        "        base_act=base_act,\n",
        "        unique_tones=unique_tones,\n",
        "        tone2idx=tone2idx,\n",
        "        get_layer_token_hidden_fn=get_layer_token_hidden_fn,\n",
        "    )\n",
        "\n",
        "    combos, rows = list(itertools.combinations(range(len(unique_tones)), num_target_tones)), []\n",
        "    for tgt_idx in tqdm(combos, desc=f\"{num_target_tones}-tone combos\"):\n",
        "        row = await _evaluate_combo(\n",
        "            list(tgt_idx),\n",
        "            [unique_tones[i] for i in tgt_idx],\n",
        "            set(unique_tones[i] for i in tgt_idx),\n",
        "            eval_method=eval_method,\n",
        "            base_ans=base_ans,\n",
        "            base_act=base_act,\n",
        "            model_device=model_device,\n",
        "            prompts=prompts,\n",
        "            N=N,\n",
        "            unique_tones=unique_tones,\n",
        "            tone2idx=tone2idx,\n",
        "            steer_model=steer_model,\n",
        "            caa_vectors=caa_vectors,\n",
        "            alpha_grad=alpha_grad,\n",
        "            alpha_caa=alpha_caa,\n",
        "            include_dct=include_dct,\n",
        "            dct_vectors=dct_vectors,\n",
        "            tone2dct=tone2dct,\n",
        "            alpha_dct=alpha_dct,\n",
        "            base_model=base_model,\n",
        "            tokenizer=tokenizer,\n",
        "            layer_idx=layer_idx,\n",
        "            batch_size=batch_size,\n",
        "            act_clf=act_clf,\n",
        "            gen_clf_label_fn=gen_clf_label_fn,\n",
        "            gen_clf_prob_fn =gen_clf_prob_fn,\n",
        "            judge=judge,\n",
        "            judge_parallel=judge_parallel,\n",
        "        )\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4EGX3Ly3-TUy",
      "metadata": {
        "id": "4EGX3Ly3-TUy"
      },
      "outputs": [],
      "source": [
        "df_act = await eval_steering_combinations(\n",
        "    eval_method      = \"generation_classifier\",\n",
        "    act_clf          = eval_model.classifier,\n",
        "    get_layer_token_hidden_fn = get_layer_token_hidden,\n",
        "    base_model       = model,\n",
        "    tokenizer        = tokenizer,\n",
        "    prompts          = eval_prompts,\n",
        "    unique_tones     = unique_tones,\n",
        "    caa_vectors      = caa_vectors,\n",
        "    steer_model      = steer_model,\n",
        "    include_dct      = True,\n",
        "    dct_vectors      = dct_vectors,\n",
        "    num_target_tones = 2,\n",
        "    gen_clf_label_fn = gen_clf_label_fn,\n",
        "    gen_clf_prob_fn  = gen_clf_prob_fn,\n",
        ")\n",
        "\n",
        "df_act"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "MLAwRB-g5xZg"
      },
      "id": "MLAwRB-g5xZg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jiWVuufUdFUv",
      "metadata": {
        "id": "jiWVuufUdFUv"
      },
      "outputs": [],
      "source": [
        "def plot_evaluation_bar(\n",
        "    df: pd.DataFrame,\n",
        "    combo_col: str | None = None,\n",
        "    title: str            = \"Steering Evaluation\",\n",
        "    x_title: str          = \"Label Combination\",\n",
        "    y_title: str          = \"Average Probability\",\n",
        "    output_path: str | Path | None = None,\n",
        "    width: int            = 900,\n",
        "    height: int           = 500,\n",
        "    show: bool            = True,\n",
        "):\n",
        "    if combo_col is None:\n",
        "        combo_col = df.select_dtypes(include=[\"object\", \"category\"]).columns[0]\n",
        "\n",
        "    method_cols = [c for c in df.columns if c != combo_col]\n",
        "\n",
        "    palette = ['#FF563F', '#F5C0B8',  '#55C89F', '#363432', '#F9DA81']\n",
        "    if len(method_cols) > len(palette):\n",
        "        repeats  = -(-len(method_cols) // len(palette))\n",
        "        palette *= repeats\n",
        "    palette = palette[:len(method_cols)]\n",
        "\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        x                = combo_col,\n",
        "        y                = method_cols,\n",
        "        color_discrete_sequence = palette,\n",
        "        template         = \"plotly_white\",\n",
        "        width            = width,\n",
        "        height           = height,\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            \"text\"  : title,\n",
        "            \"font\"  : {\"size\": 16, \"color\": \"#0c0c0c\", \"family\": \"Space Grotesk\"},\n",
        "            \"x\"     : 0.5, \"y\": 0.96, \"xanchor\": \"center\", \"yanchor\": \"top\",\n",
        "        },\n",
        "        font={\n",
        "            \"family\": \"Space Grotesk, Work Sans, sans-serif\",\n",
        "            \"color\" : \"#0c0c0c\",\n",
        "        },\n",
        "        barmode   = \"group\",\n",
        "        margin    = {\"l\": 40, \"r\": 40, \"t\": 100, \"b\": 80},\n",
        "        legend    = {\n",
        "            \"title\": {\"text\": \"\"},\n",
        "            \"orientation\": \"h\",\n",
        "            \"y\": 1.0, \"x\": 0.5,\n",
        "            \"xanchor\": \"center\", \"yanchor\": \"bottom\",\n",
        "            \"font\": {\"size\": 10, \"color\": \"#928e8b\"},\n",
        "        },\n",
        "        xaxis     = {\n",
        "            \"title\": {\"text\": x_title},\n",
        "            \"gridcolor\": \"#f5f5f5\",\n",
        "            \"linecolor\": \"#e5dfdf\",\n",
        "            \"linewidth\": 1.5,\n",
        "            \"tickfont\": {\"color\": \"#928E8B\"},\n",
        "            \"ticksuffix\": \"   \",\n",
        "        },\n",
        "        yaxis     = {\n",
        "            \"title\": {\"text\": y_title},\n",
        "            \"gridcolor\": \"#f5f5f5\",\n",
        "            \"linecolor\": \"#e5dfdf\",\n",
        "            \"linewidth\": 1.5,\n",
        "            \"tickfont\": {\"color\": \"#928E8B\"},\n",
        "            \"ticksuffix\": \"   \",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    fig.update_traces(\n",
        "        hoverlabel = {\n",
        "            \"bgcolor\": \"#0c0c0c\",\n",
        "            \"font_color\": \"#ffffff\",\n",
        "            \"font_family\": \"Work Sans\",\n",
        "        },\n",
        "        hovertemplate = \"&nbsp;%{x}<br>&nbsp;%{y:.3f}<extra></extra>\",\n",
        "    )\n",
        "\n",
        "    if output_path is not None:\n",
        "        output_path = Path(output_path)\n",
        "        try:\n",
        "            fig.write_image(str(output_path))\n",
        "            print(f\"Figure written to: {output_path.resolve()}\")\n",
        "        except ValueError as e:\n",
        "            if \"kaleido\" in str(e).lower():\n",
        "                raise RuntimeError(\n",
        "                    \"Static image export requires Kaleido. \"\n",
        "                    \"Install it with:\\n    pip install -U kaleido\"\n",
        "                ) from e\n",
        "            raise\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3zOEzlq9fb_A",
      "metadata": {
        "id": "3zOEzlq9fb_A"
      },
      "outputs": [],
      "source": [
        "plot_evaluation_bar(\n",
        "    df_act,\n",
        "    title=\"Two Label Steering Performance (Activation Classifier, Tones Dataset)\",\n",
        "    output_path=\"df_gen.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Inspection"
      ],
      "metadata": {
        "id": "FnGB2XiS7XS_"
      },
      "id": "FnGB2XiS7XS_"
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def sample_steered_responses(\n",
        "    prompts,\n",
        "    target_tones,\n",
        "    *,\n",
        "    alpha_grad = 12.0,\n",
        "    alpha_caa  =  12.0,\n",
        "    layer_idx  = 20,\n",
        "    max_new_tokens = 128,\n",
        "    batch_size     = 500,\n",
        "):\n",
        "    tone2idx = {t: i for i, t in enumerate(unique_tones)}\n",
        "    tgt_idx  = [tone2idx[t] for t in target_tones]\n",
        "\n",
        "    grad_hook = get_gradient_hook(\n",
        "        steer_model,\n",
        "        target_labels = tgt_idx,\n",
        "        avoid_labels  = [],\n",
        "        alpha         = alpha_grad,\n",
        "    )\n",
        "\n",
        "    caa_vec  = caa_vectors[tgt_idx].mean(axis=0)\n",
        "    caa_hook = get_caa_hook(caa_vec, alpha=alpha_caa)\n",
        "\n",
        "    unsteered_out = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx      = layer_idx,\n",
        "        hook_fn        = None,\n",
        "        max_new_tokens = max_new_tokens,\n",
        "        batch_size     = batch_size,\n",
        "    )\n",
        "\n",
        "    ksteer_out = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx      = layer_idx,\n",
        "        hook_fn        = grad_hook,\n",
        "        max_new_tokens = max_new_tokens,\n",
        "        batch_size     = batch_size,\n",
        "    )\n",
        "\n",
        "    caa_out = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx      = layer_idx,\n",
        "        hook_fn        = caa_hook,\n",
        "        max_new_tokens = max_new_tokens,\n",
        "        batch_size     = batch_size,\n",
        "    )\n",
        "\n",
        "    def _strip_prompt(full_text: str, prompt: str) -> str:\n",
        "        if full_text.startswith(prompt):\n",
        "            return full_text[len(prompt):].lstrip()\n",
        "        return full_text\n",
        "\n",
        "    rows = []\n",
        "    for prompt, base, k, c in zip(prompts, unsteered_out, ksteer_out, caa_out):\n",
        "        base_only = _strip_prompt(base, prompt)\n",
        "        k_only    = _strip_prompt(k,    prompt)\n",
        "        c_only    = _strip_prompt(c,    prompt)\n",
        "\n",
        "        rows.append({\n",
        "            \"prompt\"      : prompt,\n",
        "            \"unsteered\"   : base_only,\n",
        "            \"k_steering\"  : k_only,\n",
        "            \"caa\"         : c_only,\n",
        "        })\n",
        "\n",
        "    for r in rows:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"PROMPT:\\n{r['prompt']}\\n\")\n",
        "        print(\"- Unsteered -------------------------------------------------\\n\"\n",
        "              + r[\"unsteered\"] + \"\\n\")\n",
        "        print(f\"- K‑steering (α_grad = {alpha_grad}) ------------------------\\n\"\n",
        "              + r[\"k_steering\"] + \"\\n\")\n",
        "        print(f\"- CAA (α_caa = {alpha_caa}) --------------------------------\\n\"\n",
        "              + r[\"caa\"] + \"\\n\")\n",
        "\n",
        "    return rows"
      ],
      "metadata": {
        "id": "Xh9POYA-7fgw"
      },
      "id": "Xh9POYA-7fgw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts = [\n",
        "    \"What are the ethical considerations in education?\",\n",
        "    \"How can someone maintain mental health during challenging life transitions?\",\n",
        "    \"What are the benefits of keeping a food diary?\",\n",
        "    \"How can I read food labels more effectively?\"\n",
        "]\n",
        "\n",
        "_ = sample_steered_responses(\n",
        "        eval_prompts[:1000],\n",
        "        layer_idx  = 22,\n",
        "        target_tones   = [\"expert\"],\n",
        "        alpha_grad     = 1000.0,\n",
        "        alpha_caa      = 1.8,\n",
        "        max_new_tokens = 50,\n",
        ")"
      ],
      "metadata": {
        "id": "cvc_1iUo7ibI"
      },
      "id": "cvc_1iUo7ibI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}