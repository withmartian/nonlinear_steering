{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "FAii7a0jarkj",
      "metadata": {
        "id": "FAii7a0jarkj"
      },
      "outputs": [],
      "source": [
        "# Only run to clear GPU mem\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77a1fb9-8727-464f-8852-b1aad3e45cb8",
      "metadata": {
        "id": "c77a1fb9-8727-464f-8852-b1aad3e45cb8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_tKEtbndpuW6",
      "metadata": {
        "id": "_tKEtbndpuW6"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers accelerate transformer_lens openai tiktoken kaleido torch numpy joblib scikit-learn plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "702863ee-3e14-424f-a304-2f8449de9d8e",
      "metadata": {
        "id": "702863ee-3e14-424f-a304-2f8449de9d8e"
      },
      "outputs": [],
      "source": [
        "import asyncio, hashlib, math, os, random, sys, copy, gc, re, ast\n",
        "from contextlib import contextmanager\n",
        "import collections\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "from types import SimpleNamespace\n",
        "from typing import List, Dict, Tuple, Optional, DefaultDict, Callable, Union, Callable, Sequence, Mapping\n",
        "from urllib.request import urlopen\n",
        "import importlib.util, sys, copy, random, torch, itertools\n",
        "from itertools import combinations\n",
        "from functools import lru_cache\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from openai import AsyncOpenAI\n",
        "import plotly.express as px\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        ")\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "CL1CyFVJnlw3",
      "metadata": {
        "id": "CL1CyFVJnlw3"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    # steering layer: int → force layer; \"auto\" → sweep once & cache\n",
        "    # steering task: \"tones\" | \"obsession\"\n",
        "    \"TASK\": \"debates\",\n",
        "    # on‑disk caches\n",
        "    \"HIDDEN_CACHE_DIR\": \"hidden_cache\",\n",
        "    \"MODEL_CACHE_DIR\": \"layer_clfs\",\n",
        "}\n",
        "for _d in (CFG[\"HIDDEN_CACHE_DIR\"], CFG[\"MODEL_CACHE_DIR\"]):\n",
        "    Path(_d).mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "XCgrRk7Bn7om",
      "metadata": {
        "id": "XCgrRk7Bn7om"
      },
      "outputs": [],
      "source": [
        "def _load_tones():\n",
        "    ds = load_dataset(\"Narmeen07/tone_agnostic_questions\", split=\"train\")\n",
        "    steered_prompts = [\n",
        "        (\"empathetic\", \"You are an AI assistant responding with an empathetic tone. Provide emotionally attuned responses that validate feelings and show understanding. Prioritize the emotional dimension of the query.\"),\n",
        "        (\"casual\",     \"You are an AI assistant responding with a casual tone. Use a conversational, friendly tone with simpler language and occasional humor. Be relatable and informal, as if chatting with a friend.\"),\n",
        "        (\"cautious\",   \"You are an AI assistant responding with a cautious tone. Give risk-aware responses that highlight limitations, uncertainties, and potential concerns. Be careful to qualify claims and note important caveats.\"),\n",
        "        (\"concise\",    \"You are an AI assistant responding with a concise tone. Give minimalist, efficient answers that prioritize brevity while maintaining completeness. Be direct and to the point with no unnecessary information.\"),\n",
        "        (\"expert\",     \"You are an AI assistant responding with an expert tone. Provide detailed, technically precise explanations with domain-specific terminology and depth. Demonstrate expertise and precision in the subject matter.\"),\n",
        "    ]\n",
        "    rel_template = (\n",
        "        \"You will compare two answers to the *same* question.\\n\\n\"\n",
        "        \"Question:\\n[QUESTION START]\\n{question}\\n[QUESTION END]\\n\\n\"\n",
        "        \"Original answer:\\n[BASE START]\\n{base_answer}\\n[BASE END]\\n\\n\"\n",
        "        \"Modified answer:\\n[STEERED START]\\n{steered_answer}\\n[STEERED END]\\n\\n\"\n",
        "        \"Compared **to the original answer**, which single tone label best describes the *modified* answer?\\n\"\n",
        "        \"Allowed labels: cautious, empathetic, expert, helpful, casual, concise.\\n\"\n",
        "        \"Respond with **only** one label.\"\n",
        "    )\n",
        "    return SimpleNamespace(\n",
        "        name=\"tones\",\n",
        "        raw_dataset = ds,\n",
        "        steered_prompts = steered_prompts,\n",
        "        rel_template = rel_template,\n",
        "        eval_prompts = list(ds[\"text\"]),\n",
        "        unique_labels = sorted({t for t, _ in steered_prompts}),\n",
        "    )\n",
        "\n",
        "def _load_debates():\n",
        "    ds = load_dataset(\"Narmeen07/debate_style_agnostic_questions\", split=\"train\")\n",
        "\n",
        "    steered_prompts = [\n",
        "        (\"Reductio ad Absurdum\", \"RESPOND USING REDUCTIO AD ABSURDUM DEBATE STYLE. Extend the opposing viewpoint to its logical extreme to reveal its flaws. Demonstrate how the opposing position leads to absurd or contradictory conclusions when taken to its logical end. Structure your response to systematically expose the inconsistencies or impracticalities. Use conditional statements like 'If we follow this logic, then...' to illustrate the path to absurdity. Maintain a logical flow that shows how the initial premise inevitably leads to an unacceptable or ridiculous outcome.\\n\\n\"),\n",
        "        (\"Appeal to Precedent\", \"RESPOND USING APPEAL TO PRECEDENT DEBATE STYLE. Ground your arguments in historical examples, established case law, or widely accepted previous decisions. Reference specific historical situations, court rulings, scientific discoveries, or cultural precedents that support your position. Draw explicit connections between these precedents and the current issue. Emphasize how respecting established precedents provides consistency and reliability. Point out the risks or inconsistencies of ignoring relevant precedents. Structure your response to show how past experiences inform present considerations.\\n\\n\"),\n",
        "        (\"Straw Man Reframing\", \"RESPOND USING STRAW MAN REFRAMING DEBATE STYLE. Recharacterize the opposing argument in simplified or exaggerated terms that are easier to refute. Present this reframed version as if it represents the original position. Systematically dismantle this reframed argument while implying you've addressed the original point. Use phrases like 'Essentially, what you're saying is...' or 'This position boils down to...' before presenting the simplified version. Follow with a thorough refutation of this reframed position. Conclude by suggesting that your refutation applies to the original argument as well.\\n\\n\"),\n",
        "        (\"Burden of Proof Shift\", \"RESPOND USING BURDEN OF PROOF SHIFT DEBATE STYLE. Redirect the responsibility for providing evidence to your opponent rather than proving your own claim. Challenge your opponent to disprove your assertion rather than supporting it yourself. Use phrases like 'There's no evidence that disproves...' or 'Can you definitively prove that isn't the case?' Position your claims as the default assumption that should be accepted until disproven. Question the sufficiency or quality of opposing evidence while demanding an impossibly high standard of proof. Emphasize that the lack of counter-evidence strengthens your position.\\n\\n\"),\n",
        "        (\"Analogy Construction\", \"RESPOND USING ANALOGY CONSTRUCTION DEBATE STYLE. Develop a vivid, relatable comparison between the complex issue at hand and something more familiar or intuitive. Build your argument around this carefully constructed parallel situation. Highlight specific points of similarity that support your position while addressing potential dissimilarities. Use phrases like 'This situation is similar to...' or 'To understand this concept, consider...' Ensure your analogy simplifies the complex issue without distorting its essential nature. Use the familiar scenario to guide your audience to your desired conclusion about the original issue.\\n\\n\"),\n",
        "        (\"Concession and Pivot\", \"RESPOND USING CONCESSION AND PIVOT DEBATE STYLE. Begin by acknowledging a minor point or critique from the opposing side to establish fairness and reasonableness. Use phrases like 'While it's true that...' or 'I can concede that...' followed by 'However,' 'Nevertheless,' or 'That said,' to redirect to your stronger arguments. Ensure the conceded point is peripheral rather than central to your main argument. After the concession, pivot decisively to your strongest points with increased emphasis. Frame your pivot as providing necessary context or a more complete perspective. Use the concession to demonstrate your objectivity before delivering your more powerful counterarguments.\\n\\n\"),\n",
        "        (\"Empirical Grounding\", \"RESPOND USING EMPIRICAL GROUNDING DEBATE STYLE. Base your arguments primarily on verifiable data, research studies, statistics, and observable outcomes rather than theory or rhetoric. Cite specific figures, percentages, study results, or historical outcomes that support your position. Present evidence in a methodical manner, explaining how each piece of data relates to your argument. Address the reliability and relevance of your sources and methods. Compare empirical results across different contexts or time periods to strengthen your case. Anticipate and address potential methodological criticisms of the evidence you present.\\n\\n\"),\n",
        "        (\"Moral Framing\", \"RESPOND USING MORAL FRAMING DEBATE STYLE. Position the issue within a framework of ethical principles, values, and moral imperatives rather than pragmatic concerns. Identify the core moral values at stake such as justice, liberty, equality, compassion, or responsibility. Use language that evokes ethical considerations, such as 'obligation,' 'right,' 'wrong,' 'just,' or 'fair.' Appeal to widely held moral intuitions or principles. Present opposing views as morally questionable or inconsistent with important shared values. Elevate the discussion from practical matters to questions of what ought to be done. Emphasize moral consequences over practical outcomes.\\n\\n\"),\n",
        "        (\"Refutation by Distinction\", \"RESPOND USING REFUTATION BY DISTINCTION DEBATE STYLE. Identify crucial differences that invalidate comparisons or principles your opponent has applied. Carefully delineate categories, contexts, or circumstances that demonstrate why a general rule or example doesn't apply in this specific case. Use phrases like 'While that may be true in some contexts...' or 'We must distinguish between...' Emphasize the precision of definitions and classifications. Highlight subtle but significant differences that undermine the opponent's logic. Show how these distinctions fundamentally change the assessment of the situation. Demonstrate how recognizing these distinctions leads to a different conclusion than your opponent reached.\\n\\n\"),\n",
        "        (\"Circular Anticipation\", \"RESPOND USING CIRCULAR ANTICIPATION DEBATE STYLE. Preemptively identify and address the most likely counterarguments before your opponent can make them. Introduce opposing points with phrases like 'Some might argue...' or 'One could object that...' followed by your prepared refutation. Structure your response to cover all major potential objections. Demonstrate that you've thoroughly considered the issue from multiple angles. Frame potential counterarguments in ways that make them easier to dismantle. Create the impression that all reasonable objections have already been considered and overcome. Conclude by suggesting that any remaining objections would be similarly flawed.\\n\\n\")\n",
        "    ]\n",
        "    rel_template = (\n",
        "        \"You will compare two answers to the *same* question.\\n\\n\"\n",
        "        \"Question:\\n[QUESTION START]\\n{question}\\n[QUESTION END]\\n\\n\"\n",
        "        \"Original answer:\\n[BASE START]\\n{base_answer}\\n[BASE END]\\n\\n\"\n",
        "        \"Modified answer:\\n[STEERED START]\\n{steered_answer}\\n[STEERED END]\\n\\n\"\n",
        "        \"Compared **to the original answer**, which single tone label best describes the *modified* answer?\\n\"\n",
        "        \"Allowed labels: cautious, empathetic, expert, helpful, casual, concise.\\n\"\n",
        "        \"Respond with **only** one label.\"\n",
        "    )\n",
        "    return SimpleNamespace(\n",
        "        name=\"debates\",\n",
        "        raw_dataset = ds,\n",
        "        steered_prompts = steered_prompts,\n",
        "        rel_template = rel_template,\n",
        "        eval_prompts = list(ds[\"text\"]),\n",
        "        unique_labels = sorted({t for t, _ in steered_prompts}),\n",
        "    )\n",
        "\n",
        "_TASK_LOADERS = {\"tones\": _load_tones, \"debates\": _load_debates}\n",
        "_CURRENT_TASK = None\n",
        "_DATA_CTX     = None\n",
        "\n",
        "def ensure_task_data(task: str | None = None):\n",
        "    global _CURRENT_TASK, _DATA_CTX\n",
        "    task = task or CFG[\"TASK\"]\n",
        "    if _CURRENT_TASK == task and _DATA_CTX is not None:\n",
        "        return _DATA_CTX\n",
        "    if task not in _TASK_LOADERS:\n",
        "        raise ValueError(f\"Unknown task {task!r}. Choose one of {list(_TASK_LOADERS)}\")\n",
        "    print(f\"⇒ Loading steering task “{task}”…\")\n",
        "    _DATA_CTX     = _TASK_LOADERS[task]()\n",
        "    _CURRENT_TASK = task\n",
        "    return _DATA_CTX\n",
        "\n",
        "def build_steering_dataset(ctx: SimpleNamespace) -> Dataset:\n",
        "    rows = []\n",
        "    for row in ctx.raw_dataset:\n",
        "        q_text, q_id = row[\"text\"], row[\"id\"]\n",
        "        cat = row.get(\"category\", \"\")\n",
        "        for lbl, sys_prompt in ctx.steered_prompts:\n",
        "            rows.append({\n",
        "                \"id\": f\"{q_id}_{lbl}\",\n",
        "                \"original_question\": q_text,\n",
        "                \"text\": f\"{sys_prompt}\\n{q_text}\",\n",
        "                \"label\": lbl,\n",
        "                \"system_message\": sys_prompt,\n",
        "                \"category\": cat,\n",
        "            })\n",
        "    return Dataset.from_pandas(pd.DataFrame(rows))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "HwGpDYZuqECU",
      "metadata": {
        "id": "HwGpDYZuqECU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⇒ Loading steering task “debates”…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 978/978 [00:00<00:00, 24293.93 examples/s]\n"
          ]
        }
      ],
      "source": [
        "data_ctx          = ensure_task_data(\"debates\")\n",
        "\n",
        "dataset           = build_steering_dataset(data_ctx)\n",
        "unique_labels     = data_ctx.unique_labels\n",
        "RELATIVE_TEMPLATE = data_ctx.rel_template\n",
        "eval_prompts      = data_ctx.eval_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "IxkzyDpQp28C",
      "metadata": {
        "id": "IxkzyDpQp28C"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0e15cb95-5e68-49af-8934-06bc239edf04",
      "metadata": {
        "id": "0e15cb95-5e68-49af-8934-06bc239edf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading unsloth/Llama-3.2-3B-Instruct\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/k-steering-exp/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
        "# model_name = \"unsloth/llama-3-8b-Instruct\"\n",
        "# model_name = \"allenai/OLMo-2-0425-1B-Instruct\"\n",
        "#model_name = \"Qwen/Qwen3-1.7B\"\n",
        "print(f\"Loading {model_name}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    _attn_implementation=\"eager\",\n",
        "    output_hidden_states=True,\n",
        ").to(\"cuda:0\")\n",
        "\n",
        "model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9a50481e-64ba-4b4c-a004-dea40eabe40e",
      "metadata": {
        "id": "9a50481e-64ba-4b4c-a004-dea40eabe40e"
      },
      "outputs": [],
      "source": [
        "def get_hidden_cached(texts: List[str], layer_idx: int, *, batch_size: int = 64) -> np.ndarray:\n",
        "    all_vecs = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        tok = tokenizer(batch,\n",
        "                        return_tensors=\"pt\",\n",
        "                        padding=True,\n",
        "                        truncation=True).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = model(**tok, output_hidden_states=True)\n",
        "        h = out.hidden_states[layer_idx]\n",
        "        mask = tok[\"attention_mask\"]\n",
        "        lengths = mask.sum(dim=1) - 1\n",
        "\n",
        "        for j, idx in enumerate(lengths):\n",
        "            all_vecs.append(h[j, idx, :].cpu().float().numpy())\n",
        "\n",
        "    return np.stack(all_vecs, axis=0)\n",
        "\n",
        "def batch_generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    prompts: List[str],\n",
        "    layer_idx: int,\n",
        "    hook_fn: Optional[Callable] = None,\n",
        "    max_new_tokens: int = 24,\n",
        "    batch_size: int = 512,\n",
        ") -> List[str]:\n",
        "    device        = model.device\n",
        "    target_layer  = model.model.layers[layer_idx]\n",
        "    outputs: List[str] = []\n",
        "\n",
        "    saved_hooks = target_layer._forward_hooks.copy()\n",
        "    target_layer._forward_hooks.clear()\n",
        "\n",
        "    handle = None\n",
        "    if hook_fn is not None:\n",
        "        handle = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    try:\n",
        "        for i in range(0, len(prompts), batch_size):\n",
        "            sub_prompts = prompts[i : i + batch_size]\n",
        "            tok_in = tokenizer(\n",
        "                sub_prompts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                gen_ids = model.generate(\n",
        "                    **tok_in,\n",
        "                    max_new_tokens = max_new_tokens,\n",
        "                    do_sample      = False,\n",
        "                    pad_token_id   = tokenizer.eos_token_id,\n",
        "                )\n",
        "\n",
        "            outputs.extend(\n",
        "                tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "            )\n",
        "    finally:\n",
        "        if handle is not None:\n",
        "            handle.remove()\n",
        "        target_layer._forward_hooks.clear()\n",
        "        target_layer._forward_hooks.update(saved_hooks)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04zXz48Htq1R",
      "metadata": {
        "id": "04zXz48Htq1R"
      },
      "source": [
        "# Steering Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534322de-bb2c-41ef-8033-fd061412212b",
      "metadata": {
        "id": "534322de-bb2c-41ef-8033-fd061412212b"
      },
      "source": [
        "## K-Steering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8d746a07-b6b0-4d71-8fb3-23e3e91877f9",
      "metadata": {
        "id": "8d746a07-b6b0-4d71-8fb3-23e3e91877f9"
      },
      "outputs": [],
      "source": [
        "def one_hot(idxs: np.ndarray, C: int) -> np.ndarray:\n",
        "    out = np.zeros((len(idxs), C), dtype=np.float32)\n",
        "    out[np.arange(len(idxs)), idxs] = 1.0\n",
        "    return out\n",
        "\n",
        "class MultiLabelSteeringModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 num_labels: int,\n",
        "                 linear: bool = False):\n",
        "        super().__init__()\n",
        "        if linear:\n",
        "            self.net = nn.Linear(input_dim, num_labels)\n",
        "        else:\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, num_labels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ActivationSteering:\n",
        "    def __init__(self, input_dim, num_labels, hidden_dim=128, lr=1e-3):\n",
        "        self.device = DEVICE\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.classifier = MultiLabelSteeringModel(\n",
        "            input_dim, hidden_dim, num_labels\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.classifier.parameters(), lr=lr)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def fit(self, X, Y, epochs=10, batch_size=32):\n",
        "        X_t = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
        "        Y_t = torch.tensor(Y, dtype=torch.float32, device=self.device)\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(X_t, Y_t)\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            total_loss = 0.0\n",
        "            for bx, by in loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                logits = self.classifier(bx)\n",
        "                loss = self.loss_fn(logits, by)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {ep+1}/{epochs}, Loss={total_loss/len(loader):.4f}\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_proba(self, X):\n",
        "        self.classifier.eval()\n",
        "        X_t = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
        "        logits = self.classifier(X_t)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "    def steer_activations(\n",
        "        self,\n",
        "        acts: Union[np.ndarray, torch.Tensor],\n",
        "        target_idx: List[int],\n",
        "        avoid_idx: List[int] = [],\n",
        "        alpha: float = 1.0,\n",
        "        steps: int = 1,\n",
        "        step_size_decay: float = 1.0,\n",
        "    ) -> torch.Tensor:\n",
        "        if isinstance(acts, np.ndarray):\n",
        "            acts = torch.as_tensor(acts, dtype=torch.float32, device=self.device)\n",
        "        else:\n",
        "            acts = acts.to(self.device, dtype=torch.float32)\n",
        "\n",
        "        steered = acts.detach().clone()\n",
        "\n",
        "        for step in range(steps):\n",
        "            curr = steered.clone().requires_grad_(True)\n",
        "            logits = self.classifier(curr)\n",
        "\n",
        "            loss_vec = _compute_steering_loss(\n",
        "                logits, target_idx=target_idx, avoid_idx=avoid_idx\n",
        "            )\n",
        "\n",
        "            loss = loss_vec.mean()\n",
        "            grads = torch.autograd.grad(loss, curr, retain_graph=False)[0]\n",
        "\n",
        "            current_alpha = alpha * (step_size_decay ** step)\n",
        "            steered = (curr - current_alpha * grads).detach()\n",
        "\n",
        "        return steered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "zD3tyQIXxmMJ",
      "metadata": {
        "id": "zD3tyQIXxmMJ"
      },
      "outputs": [],
      "source": [
        "def get_or_train_layer_clf(layer_idx: int, X: np.ndarray, y: np.ndarray,\n",
        "                           *, hidden_dim=128, epochs=5, batch_size=32):\n",
        "    if y.dtype.kind not in (\"i\", \"u\"):\n",
        "        lbl2idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
        "        y = np.asarray([lbl2idx[lbl] for lbl in y], dtype=np.int64)\n",
        "\n",
        "    f = Path(CFG[\"MODEL_CACHE_DIR\"]) / f\"layer{layer_idx}.pt\"\n",
        "    if f.exists():\n",
        "        sd = torch.load(f, map_location=\"cpu\", weights_only=False)\n",
        "        clf = ActivationSteering(input_dim=X.shape[1], num_labels=len(unique_labels), hidden_dim=hidden_dim)\n",
        "        clf.classifier.load_state_dict(sd[\"state_dict\"])\n",
        "        return clf, sd[\"acc\"]\n",
        "\n",
        "    idx_A, idx_B = train_test_split(np.arange(len(X)), test_size=0.5, random_state=42, stratify=y)\n",
        "    X_A, X_B, y_A, y_B = X[idx_A], X[idx_B], y[idx_A], y[idx_B]\n",
        "\n",
        "    clf = ActivationSteering(input_dim=X.shape[1], num_labels=len(unique_labels), hidden_dim=hidden_dim)\n",
        "    clf.fit(X_A, one_hot(y_A, len(unique_labels)), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        acc = (torch.argmax(\n",
        "            clf.classifier(torch.tensor(X_B, dtype=torch.float32, device=clf.device)),\n",
        "            dim=1).cpu().numpy() == y_B).mean()\n",
        "\n",
        "    torch.save({\"state_dict\": clf.classifier.state_dict(), \"acc\": acc}, f)\n",
        "    return clf, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683fa36b-15d3-40d4-8a69-0f1995793703",
      "metadata": {
        "id": "683fa36b-15d3-40d4-8a69-0f1995793703"
      },
      "source": [
        "## CAA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "002a73ea-7df0-4379-aa35-427b8955ad2f",
      "metadata": {
        "id": "002a73ea-7df0-4379-aa35-427b8955ad2f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def compute_caa_vectors(\n",
        "    dataset,\n",
        "    unique_labels,\n",
        "    steer_layer: int,\n",
        "    max_pairs: int | None = None,\n",
        ") -> np.ndarray:\n",
        "    q2lab2text = defaultdict(dict)\n",
        "    for row in dataset:\n",
        "        q2lab2text[row[\"original_question\"]][row[\"label\"]] = row[\"text\"]\n",
        "\n",
        "    pos, neg = defaultdict(list), defaultdict(list)\n",
        "    for q, lab_map in q2lab2text.items():\n",
        "        labs = set(lab_map)\n",
        "        for tgt in labs:\n",
        "            for other in labs - {tgt}:\n",
        "                pos[tgt].append(lab_map[tgt])\n",
        "                neg[tgt].append(lab_map[other])\n",
        "\n",
        "    caa_vecs = []\n",
        "    for lbl in unique_labels:\n",
        "        pairs = len(pos[lbl])\n",
        "        if max_pairs and pairs > max_pairs:\n",
        "            keep = random.sample(range(pairs), max_pairs)\n",
        "            pos[lbl] = [pos[lbl][i] for i in keep]\n",
        "            neg[lbl] = [neg[lbl][i] for i in keep]\n",
        "\n",
        "        if not pos[lbl]:\n",
        "            caa_vecs.append(np.zeros(model.config.hidden_size, dtype=np.float32))\n",
        "            continue\n",
        "\n",
        "        X_pos = get_hidden_cached(pos[lbl], layer_idx=steer_layer)\n",
        "        X_neg = get_hidden_cached(neg[lbl], layer_idx=steer_layer)\n",
        "        caa_vecs.append((X_pos - X_neg).mean(0))\n",
        "\n",
        "    return np.stack(caa_vecs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3ed0dc-d081-4b59-997b-81f3d2a49138",
      "metadata": {
        "id": "ca3ed0dc-d081-4b59-997b-81f3d2a49138"
      },
      "source": [
        "## DCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e0b3fe70-0820-47a7-8843-44d4438fd279",
      "metadata": {
        "id": "e0b3fe70-0820-47a7-8843-44d4438fd279"
      },
      "outputs": [],
      "source": [
        "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE_MODEL   = torch.float16\n",
        "DTYPE_DCT     = torch.float32\n",
        "\n",
        "DCT_URL = \"https://raw.githubusercontent.com/luke-marks0/melbo-dct-post/main/src/dct.py\"\n",
        "def load_dct(path: str = \"dct.py\", url: str = DCT_URL):\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        print(\"Downloading dct.py...\")\n",
        "        p.write_text(urlopen(url).read().decode())\n",
        "    spec = importlib.util.spec_from_file_location(\"dct\", path)\n",
        "    mod  = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"dct\"] = mod\n",
        "    spec.loader.exec_module(mod)\n",
        "    return mod\n",
        "\n",
        "def get_hidden(model, tok, texts, *, max_len=48, layer_idx=-1):\n",
        "    ids = tok(\n",
        "        texts, padding=\"max_length\", truncation=True,\n",
        "        max_length=max_len, return_tensors=\"pt\"\n",
        "    ).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        h = model(**ids, use_cache=False, output_hidden_states=True).hidden_states\n",
        "    return h[layer_idx]\n",
        "\n",
        "def make_slice(base_model, start, end, *, dtype):\n",
        "    m = copy.deepcopy(base_model).to(dtype=dtype)\n",
        "    m.model.layers = m.model.layers[start:end]\n",
        "    return m\n",
        "\n",
        "dct = load_dct()\n",
        "\n",
        "def compute_dct_vectors_for_layers(\n",
        "    source_layer: int,\n",
        "    target_layer: int,\n",
        "    *,\n",
        "    num_samples = 8,\n",
        "    num_factors = 256,\n",
        "    max_seq_len = 48,\n",
        "):\n",
        "    prompts = random.sample([row[\"text\"] for row in dataset], k=num_samples)\n",
        "\n",
        "    source_h = get_hidden(model, tokenizer, prompts,\n",
        "                          max_len=max_seq_len, layer_idx=source_layer).float()\n",
        "\n",
        "    slice_model    = make_slice(model, source_layer, target_layer, dtype=DTYPE_DCT)\n",
        "    last_layer_idx = len(slice_model.model.layers) - 1\n",
        "\n",
        "    sliced = dct.SlicedModel(\n",
        "        slice_model,\n",
        "        start_layer = 0,\n",
        "        end_layer   = last_layer_idx,\n",
        "        layers_name = \"model.layers\",\n",
        "    )\n",
        "\n",
        "    target_h     = sliced(source_h).float()\n",
        "    delta_single = dct.DeltaActivations(\n",
        "        sliced, target_position_indices=slice(-3, None)\n",
        "    )\n",
        "\n",
        "    calibrator = dct.SteeringCalibrator(target_ratio=0.5)\n",
        "    try:\n",
        "        input_scale = calibrator.calibrate(\n",
        "            delta_single, source_h, target_h, factor_batch_size=64\n",
        "        )\n",
        "    except ValueError:\n",
        "        input_scale = 1.0\n",
        "\n",
        "    exp_dct = dct.ExponentialDCT(num_factors=num_factors)\n",
        "    U, V = exp_dct.fit(\n",
        "        delta_single,\n",
        "        source_h, target_h,\n",
        "        batch_size        = 2,\n",
        "        factor_batch_size = 128,\n",
        "        d_proj            = 48,\n",
        "        input_scale       = input_scale,\n",
        "        max_iters         = 6,\n",
        "    )\n",
        "    print(f\"Learnt {V.shape[1]} DCT steering vectors\")\n",
        "    return V.cpu().detach().numpy().T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2I4u2MY2t1uf",
      "metadata": {
        "id": "2I4u2MY2t1uf"
      },
      "source": [
        "# Evaluation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D25EXAxtDcvX",
      "metadata": {
        "id": "D25EXAxtDcvX"
      },
      "source": [
        "## Activation Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "Mmsfr57IDfZF",
      "metadata": {
        "id": "Mmsfr57IDfZF"
      },
      "outputs": [],
      "source": [
        "def get_or_train_eval_clf(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    *,\n",
        "    hidden_dim: int = 128,\n",
        "    epochs: int     = 5,\n",
        "    batch_size: int = 32,\n",
        "):\n",
        "    cache_f = Path(CFG[\"MODEL_CACHE_DIR\"]) / \"final_layer_eval.pt\"\n",
        "\n",
        "    if cache_f.exists():\n",
        "        sd = torch.load(cache_f, map_location=\"cpu\", weights_only=False)\n",
        "        clf = ActivationSteering(\n",
        "            input_dim=X.shape[1],\n",
        "            num_labels=len(unique_labels),\n",
        "            hidden_dim=hidden_dim,\n",
        "        )\n",
        "        clf.classifier.load_state_dict(sd[\"state_dict\"])\n",
        "        return clf, sd[\"acc_on_A\"]\n",
        "\n",
        "    idx_A, idx_B = train_test_split(\n",
        "        np.arange(len(X)),\n",
        "        test_size   = 0.5,\n",
        "        random_state=42,\n",
        "        stratify    = y,\n",
        "    )\n",
        "    X_A, X_B = X[idx_A], X[idx_B]\n",
        "    y_A, y_B = y[idx_A], y[idx_B]\n",
        "\n",
        "    clf = ActivationSteering(\n",
        "        input_dim=X.shape[1],\n",
        "        num_labels=len(unique_labels),\n",
        "        hidden_dim=hidden_dim,\n",
        "    )\n",
        "    clf.fit(\n",
        "        X_B,\n",
        "        one_hot(y_B, len(unique_labels)),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = clf.classifier(\n",
        "            torch.tensor(X_A, dtype=torch.float32, device=clf.device)\n",
        "        )\n",
        "        acc_A = (torch.argmax(preds, dim=1).cpu().numpy() == y_A).mean()\n",
        "\n",
        "    torch.save(\n",
        "        {\"state_dict\": clf.classifier.state_dict(), \"acc_on_A\": acc_A},\n",
        "        cache_f,\n",
        "    )\n",
        "\n",
        "    return clf, acc_A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PhuBTSqn5fqk",
      "metadata": {
        "id": "PhuBTSqn5fqk"
      },
      "source": [
        "## LLM Judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "NXkskgAnZPkI",
      "metadata": {
        "id": "NXkskgAnZPkI"
      },
      "outputs": [],
      "source": [
        "def first_token_map(model_name: str) -> Dict[str, str]:\n",
        "    enc = tiktoken.encoding_for_model(model_name)\n",
        "    return {\n",
        "        lbl: enc.decode([enc.encode(lbl)[0]])\n",
        "        for lbl in TONE_LABELS\n",
        "    }\n",
        "\n",
        "class OpenAiJudge:\n",
        "    def __init__(self, client: AsyncOpenAI, model_name: str):\n",
        "        self.client        = client\n",
        "        self.model_name    = model_name\n",
        "        self._first_token  = first_token_map(model_name)\n",
        "\n",
        "    async def compare(self,\n",
        "                      question: str,\n",
        "                      base_answer: str,\n",
        "                      steered_answer: str) -> str:\n",
        "        prompt = RELATIVE_TEMPLATE.format(\n",
        "            question=question, base_answer=base_answer, steered_answer=steered_answer\n",
        "        )\n",
        "        return await self._best_label(prompt)\n",
        "\n",
        "    async def compare_logits(self,\n",
        "                             question: str,\n",
        "                             base_answer: str,\n",
        "                             steered_answer: str,\n",
        "                             top_k: int = 20) -> Tuple[str, Dict[str, float]]:\n",
        "        prompt = RELATIVE_TEMPLATE.format(\n",
        "            question=question, base_answer=base_answer, steered_answer=steered_answer\n",
        "        )\n",
        "        return await self._label_probs(prompt, top_k)\n",
        "\n",
        "    async def _best_label(self, prompt: str, top_k: int = 20) -> str:\n",
        "        best, _ = await self._label_probs(prompt, top_k)\n",
        "        return best\n",
        "\n",
        "    async def _label_probs(self, prompt: str,\n",
        "                           top_k: int = 20) -> Tuple[str, Dict[str, float]]:\n",
        "        completion = await self.client.chat.completions.create(\n",
        "            model        = self.model_name,\n",
        "            messages     = [{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens   = 1,\n",
        "            temperature  = 0,\n",
        "            logprobs     = True,\n",
        "            top_logprobs = top_k,\n",
        "            seed         = 0,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            top = completion.choices[0].logprobs.content[0].top_logprobs\n",
        "        except IndexError:\n",
        "            raise RuntimeError(\"OpenAI response missing logprobs\")\n",
        "\n",
        "        tok_prob = {el.token: math.exp(el.logprob) for el in top}\n",
        "        probs    = {\n",
        "            lbl: tok_prob.get(self._first_token[lbl], 0.0)\n",
        "            for lbl in TONE_LABELS\n",
        "        }\n",
        "        best_lbl = max(probs, key=probs.get)\n",
        "        return best_lbl, probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b7bd55-3a68-4e71-a797-790581301243",
      "metadata": {
        "id": "b7b7bd55-3a68-4e71-a797-790581301243"
      },
      "source": [
        "# Steering Vector Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c31f82be-b0df-4232-bffd-182b4df0735d",
      "metadata": {
        "id": "c31f82be-b0df-4232-bffd-182b4df0735d"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "068fd591-4032-423e-aa0a-041b098ea041",
      "metadata": {
        "id": "068fd591-4032-423e-aa0a-041b098ea041"
      },
      "outputs": [],
      "source": [
        "def _compute_steering_loss(\n",
        "    logits: torch.Tensor,\n",
        "    target_idx,\n",
        "    avoid_idx,\n",
        ") -> torch.Tensor:\n",
        "    if not torch.is_tensor(target_idx):\n",
        "        target_idx = torch.as_tensor(target_idx, device=logits.device)\n",
        "    else:\n",
        "        target_idx = target_idx.to(logits.device)\n",
        "    if not torch.is_tensor(avoid_idx):\n",
        "        avoid_idx = torch.as_tensor(avoid_idx, device=logits.device)\n",
        "    else:\n",
        "        avoid_idx = avoid_idx.to(logits.device)\n",
        "\n",
        "    B, C = logits.shape\n",
        "\n",
        "    if avoid_idx.numel() > 0:\n",
        "        avoid_term = logits[:, avoid_idx].mean(dim=1)\n",
        "    else:\n",
        "        avoid_term = torch.zeros(B, device=logits.device)\n",
        "\n",
        "    if target_idx.numel() > 0:\n",
        "        target_term = logits[:, target_idx].mean(dim=1)\n",
        "    else:\n",
        "        target_term = torch.zeros(B, device=logits.device)\n",
        "\n",
        "    return avoid_term - target_term\n",
        "\n",
        "def get_gradient_hook(steer_model,\n",
        "                      target_labels=None,\n",
        "                      avoid_labels=None,\n",
        "                      alpha: float = 1.0,\n",
        "                      steps: int = 1,\n",
        "                      step_size_decay: float = 1.0):\n",
        "\n",
        "    target_labels = torch.as_tensor(target_labels or [], device=steer_model.device)\n",
        "    avoid_labels  = torch.as_tensor(avoid_labels  or [], device=steer_model.device)\n",
        "\n",
        "    @torch.inference_mode(False)\n",
        "    def fwd_hook(module, inp, out):\n",
        "        h_fp16 = out[0]\n",
        "        B, S, D = h_fp16.shape\n",
        "\n",
        "        h_current = h_fp16.reshape(-1, D).float()\n",
        "\n",
        "        for step in range(steps):\n",
        "            h_step = h_current.clone()\n",
        "            h_step.requires_grad_(True)\n",
        "\n",
        "            logits = steer_model.classifier(h_step)\n",
        "            logits = logits.view(B, S, -1).mean(dim=1)\n",
        "\n",
        "            loss_vec = _compute_steering_loss(\n",
        "                logits,\n",
        "                target_idx=target_labels,\n",
        "                avoid_idx=avoid_labels\n",
        "            )\n",
        "\n",
        "            if loss_vec.numel() > 0:\n",
        "                grad = torch.autograd.grad(\n",
        "                    outputs=loss_vec,\n",
        "                    inputs=h_step,\n",
        "                    grad_outputs=torch.ones_like(loss_vec),\n",
        "                    retain_graph=False,\n",
        "                    create_graph=False,\n",
        "                )[0]\n",
        "\n",
        "                current_alpha = alpha * (step_size_decay ** step)\n",
        "\n",
        "                grad = grad.view(B * S, D)\n",
        "                h_current = (h_step - current_alpha * grad).detach()\n",
        "            else:\n",
        "                h_current = h_step.detach()\n",
        "\n",
        "        h_new = h_current.reshape(B, S, D).to(h_fp16.dtype)\n",
        "        return (h_new,) + out[1:]\n",
        "\n",
        "    return fwd_hook\n",
        "\n",
        "def get_caa_hook(caa_vector: torch.Tensor | np.ndarray,\n",
        "                 alpha: float = 1.0):\n",
        "    if not torch.is_tensor(caa_vector):\n",
        "        caa_vector = torch.as_tensor(caa_vector, dtype=torch.float16)\n",
        "\n",
        "    def fwd_hook(module, inp, out):\n",
        "        h = out[0]\n",
        "        return (h + alpha * caa_vector.to(h.device),) + out[1:]\n",
        "\n",
        "    return fwd_hook\n",
        "\n",
        "def get_dct_hook(dct_vector: torch.Tensor | np.ndarray,\n",
        "                 alpha: float = 1.0):\n",
        "    if not torch.is_tensor(dct_vector):\n",
        "        dct_vector = torch.as_tensor(dct_vector, dtype=torch.float16)\n",
        "\n",
        "    def fwd_hook(module, inp, out):\n",
        "        h = out[0]\n",
        "        return (h + alpha * dct_vector.to(h.device),) + out[1:]\n",
        "\n",
        "    return fwd_hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d83353c6-be62-462f-9292-f35fc272ef7b",
      "metadata": {
        "id": "d83353c6-be62-462f-9292-f35fc272ef7b"
      },
      "outputs": [],
      "source": [
        "def logit(x): return np.log(x/(1-x) + 1e-9)\n",
        "\n",
        "async def batch_compare(\n",
        "    triples: List[Tuple[str, str, str]],\n",
        "    judge   : OpenAiJudge,\n",
        "    max_concurrency: int = 10,\n",
        ") -> List[str]:\n",
        "    sem   = asyncio.Semaphore(max_concurrency)\n",
        "    out   = [None] * len(triples)\n",
        "\n",
        "    async def worker(idx: int, q: str, b: str, s: str):\n",
        "        async with sem:\n",
        "            out[idx] = await judge.compare(q, b, s)\n",
        "\n",
        "    tasks = [asyncio.create_task(worker(i, *t)) for i, t in enumerate(triples)]\n",
        "    for f in tqdm(asyncio.as_completed(tasks), total=len(tasks),\n",
        "                  desc=\"LLM‑judge\", leave=False):\n",
        "        await f\n",
        "    return out\n",
        "\n",
        "async def _llm_batch_compare(triples, judge, parallel):\n",
        "    return await batch_compare(triples, judge, max_concurrency=parallel)\n",
        "\n",
        "def _prepare_bases(\n",
        "    prompts          : List[str],\n",
        "    *,\n",
        "    base_model,\n",
        "    tokenizer,\n",
        "    layer_idx,\n",
        "    act_clf          = None,\n",
        "):\n",
        "    base_ans = batch_generate(base_model, tokenizer, prompts, layer_idx,\n",
        "                              None)\n",
        "    base_act = get_hidden_cached(prompts, layer_idx)\n",
        "    return base_ans, base_act"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d77539de-0526-4ec7-9c4d-6f270f3f50fa",
      "metadata": {
        "id": "d77539de-0526-4ec7-9c4d-6f270f3f50fa"
      },
      "outputs": [],
      "source": [
        "async def _map_dct_vectors(\n",
        "    *,\n",
        "    dct_vectors      : np.ndarray,\n",
        "    prompts           : List[str],\n",
        "    act_clf,\n",
        "    layer_idx        : int,\n",
        "    base_act         : Optional[np.ndarray],\n",
        "    unique_labels    : List[str],\n",
        "    tone2idx,\n",
        ") -> Mapping[str, List[int]]:\n",
        "\n",
        "    base_module = getattr(act_clf, \"classifier\", act_clf)\n",
        "    base_module.eval()\n",
        "    device = next(base_module.parameters()).device\n",
        "\n",
        "    if base_act is None:\n",
        "        base_act = get_hidden_cached(prompts, layer_idx)\n",
        "    base_act = np.asarray(base_act, dtype=np.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        t0 = torch.tensor(base_act, dtype=torch.float32, device=device)\n",
        "        P0 = base_module(t0).sigmoid().cpu().numpy()\n",
        "\n",
        "    tone2dct = defaultdict(list)\n",
        "    for i_vec, vec in enumerate(dct_vectors):\n",
        "        vec = np.asarray(vec, dtype=np.float32)\n",
        "        with torch.no_grad():\n",
        "            t1 = torch.tensor(base_act + vec, dtype=torch.float32, device=device)\n",
        "            P1 = base_module(t1).sigmoid().cpu().numpy()\n",
        "\n",
        "        delta_p = P1.mean(axis=0) - P0.mean(axis=0)\n",
        "        best_idx = int(np.argmax(delta_p))\n",
        "        best_lbl = unique_labels[best_idx]\n",
        "        tone2dct[best_lbl].append(i_vec)\n",
        "\n",
        "    return tone2dct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca27aea2-289a-49ea-ad19-130e8ed44c61",
      "metadata": {
        "id": "ca27aea2-289a-49ea-ad19-130e8ed44c61"
      },
      "source": [
        "## Core Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9da963f2-a927-4657-b34a-5692c0551d82",
      "metadata": {
        "id": "9da963f2-a927-4657-b34a-5692c0551d82"
      },
      "outputs": [],
      "source": [
        "async def _evaluate_combo(\n",
        "    tgt_idx, tgt_names, tgt_set,\n",
        "    *, steps,\n",
        "    base_ans, base_act,\n",
        "    model_device, prompts,\n",
        "    unique_labels, tone2idx,\n",
        "    steer_model, caa_vectors,\n",
        "    alpha_grad, alpha_caa,\n",
        "    base_model, tokenizer, layer_idx,\n",
        "    act_clf, judge, judge_parallel,\n",
        "):\n",
        "    combo_key = tuple(sorted(tgt_names))\n",
        "\n",
        "    def _pick_alpha(src, is_caa=False) -> float:\n",
        "        if isinstance(src, dict):\n",
        "            g, c = src[combo_key]\n",
        "            return c if is_caa else g\n",
        "        if isinstance(src, np.ndarray):\n",
        "            return float(src[tgt_idx].mean())\n",
        "        return float(src)\n",
        "\n",
        "    αg = _pick_alpha(alpha_grad, is_caa=False)\n",
        "    αc = _pick_alpha(alpha_caa,  is_caa=True)\n",
        "\n",
        "    grad_hook = get_gradient_hook(\n",
        "        steer_model, target_labels=tgt_idx, avoid_labels=[], alpha=αg, steps=steps\n",
        "    )\n",
        "    caa_vec  = caa_vectors[tgt_idx].mean(axis=0)\n",
        "    caa_hook = get_caa_hook(caa_vec, alpha=αc)\n",
        "\n",
        "    steered_list = []\n",
        "    for i in range(base_act.shape[0]):\n",
        "        x = base_act[i : i+1]\n",
        "        t = steer_model.steer_activations(x, tgt_idx, alpha=αg, steps=steps)\n",
        "        steered_list.append(t.detach().cpu().numpy())\n",
        "    grad_act = np.concatenate(steered_list, axis=0)\n",
        "\n",
        "    caa_act  = base_act + αc * caa_vec[None, :]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        base_logits  = act_clf(torch.tensor(base_act,  dtype=torch.float32,\n",
        "                                            device=model_device))\n",
        "        grad_logits  = act_clf(torch.tensor(grad_act, dtype=torch.float32,\n",
        "                                            device=model_device))\n",
        "        caa_logits   = act_clf(torch.tensor(caa_act,  dtype=torch.float32,\n",
        "                                            device=model_device))\n",
        "\n",
        "    base_prob  = torch.sigmoid(base_logits).cpu().numpy()\n",
        "    grad_prob  = torch.sigmoid(grad_logits).cpu().numpy()\n",
        "    caa_prob   = torch.sigmoid(caa_logits ).cpu().numpy()\n",
        "\n",
        "    delta_k   = (grad_prob[:, tgt_idx] - base_prob[:, tgt_idx]).mean()\n",
        "    delta_c   = (caa_prob [:, tgt_idx] - base_prob[:, tgt_idx]).mean()\n",
        "\n",
        "    row = {\n",
        "        \"Targets\"    : \", \".join(tgt_names),\n",
        "        \"K-Steering\" : delta_k,\n",
        "        \"CAA\"        : delta_c,\n",
        "    }\n",
        "\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "623e5ffe-8800-456f-92f3-e13169e9ea24",
      "metadata": {
        "id": "623e5ffe-8800-456f-92f3-e13169e9ea24"
      },
      "outputs": [],
      "source": [
        "async def eval_steering_combinations(\n",
        "    *,\n",
        "    prompts: List[str],\n",
        "    unique_labels: List[str],\n",
        "    caa_vectors,\n",
        "    steer_model,\n",
        "    num_target_labels: int = 2,\n",
        "    act_clf          = None,\n",
        "    judge            = None,\n",
        "    judge_parallel   = 25,\n",
        "    base_model       = model,\n",
        "    tokenizer        = tokenizer,\n",
        "    layer_idx        = None,\n",
        "    alpha_grad       = 1.0,\n",
        "    alpha_caa        = 1.0,\n",
        "    max_samples: Optional[int] = None,\n",
        "    steps            = 1,\n",
        "):\n",
        "    if max_samples is not None:\n",
        "        prompts = prompts[:max_samples]\n",
        "\n",
        "    tone2idx = {t:i for i,t in enumerate(unique_labels)}\n",
        "\n",
        "    print(\"Sampling base generations...\")\n",
        "    base_ans, base_act = _prepare_bases(\n",
        "        prompts,\n",
        "        base_model   = base_model,\n",
        "        tokenizer    = tokenizer,\n",
        "        layer_idx    = layer_idx,\n",
        "        act_clf      = act_clf,\n",
        "    )\n",
        "\n",
        "    rows = []\n",
        "    combos = combinations(unique_labels, num_target_labels)\n",
        "    model_device = next(act_clf.parameters()).device if act_clf else None\n",
        "\n",
        "    print(\"Evaluating label combinations...\")\n",
        "    for combo in combos:\n",
        "        print(\"New combination...\", combo)\n",
        "        tgt_idx = [tone2idx[label] for label in combo]\n",
        "        row = await _evaluate_combo(\n",
        "            tgt_idx, list(combo), set(combo),\n",
        "            base_ans    = base_ans,\n",
        "            base_act    = base_act,\n",
        "            model_device= model_device,\n",
        "            prompts     = prompts,\n",
        "            unique_labels= unique_labels,\n",
        "            tone2idx    = tone2idx,\n",
        "            steer_model = steer_model,\n",
        "            caa_vectors = caa_vectors,\n",
        "            alpha_grad  = alpha_grad,\n",
        "            alpha_caa   = alpha_caa,\n",
        "            base_model    = base_model,\n",
        "            tokenizer     = tokenizer,\n",
        "            layer_idx     = layer_idx,\n",
        "            act_clf       = act_clf,\n",
        "            judge         = judge,\n",
        "            judge_parallel= judge_parallel,\n",
        "            steps         = steps,\n",
        "        )\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055fdf5a-4d68-4213-86d5-01f9d76380cc",
      "metadata": {
        "id": "055fdf5a-4d68-4213-86d5-01f9d76380cc"
      },
      "source": [
        "## Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d0a38fcb-419a-4d2d-9925-98087fc1f867",
      "metadata": {
        "id": "d0a38fcb-419a-4d2d-9925-98087fc1f867"
      },
      "outputs": [],
      "source": [
        "TOKEN_RE = re.compile(r\"\\w+\")\n",
        "\n",
        "def _stats(text: str):\n",
        "    toks = TOKEN_RE.findall(text.lower())\n",
        "    if not toks:\n",
        "        return 0.0, 1.0\n",
        "    cnts = collections.Counter(toks).values()\n",
        "    return len(cnts) / len(toks), max(cnts) / len(toks)\n",
        "\n",
        "@torch.no_grad()\n",
        "def is_ood(\n",
        "    texts,\n",
        "    *,\n",
        "    frac            : float       = 0.05,\n",
        "    uniq_thresh     : float       = 0.40,\n",
        "    maxfreq_thresh  : float       = 0.15,\n",
        "    dbg_prefix      : str        = \"\",\n",
        "    verbose         : bool       = False,\n",
        ") -> bool:\n",
        "    uniq, mfreq = zip(*[_stats(t) for t in texts])\n",
        "\n",
        "    uniq_bad  = np.array(uniq)  < uniq_thresh\n",
        "    mfreq_bad = np.array(mfreq) > maxfreq_thresh\n",
        "\n",
        "    bad = np.logical_or(uniq_bad, mfreq_bad)\n",
        "    frac_bad = bad.mean()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{dbg_prefix}OOD  check: \"\n",
        "              f\"uniq_bad={uniq_bad.mean():.2f} mfreq_bad={mfreq_bad.mean():.2f} \"\n",
        "              f\"(flag if >{frac}) → frac_bad={frac_bad:.2f}\")\n",
        "\n",
        "    return frac_bad > frac\n",
        "\n",
        "def calibrate_alpha_ood_only(ood_check, *, min_alpha, max_alpha,\n",
        "                                tol=0.001, max_iters=15):\n",
        "    print(\"New sweep...\")\n",
        "    lo, hi = min_alpha, max_alpha\n",
        "    last = min_alpha\n",
        "    for _ in range(max_iters):\n",
        "        if hi / lo <= tol:\n",
        "            break\n",
        "        mid = (lo + hi) / 2\n",
        "        if ood_check(mid):\n",
        "            hi = mid\n",
        "        else:\n",
        "            last = mid\n",
        "            lo   = mid\n",
        "    return float(last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a16b5cc0-a293-4e03-a092-6a1a235e0307",
      "metadata": {
        "id": "a16b5cc0-a293-4e03-a092-6a1a235e0307"
      },
      "outputs": [],
      "source": [
        "async def _run_eval_on_layer(\n",
        "    layer_idx: int,\n",
        "    prompts  : list[str],\n",
        "    *,\n",
        "    dataset,\n",
        "    unique_labels,\n",
        "    act_clf,\n",
        "    eval_layer        : int | None = None,\n",
        "    only_calibrate    : bool  = False,\n",
        "    alpha_grad_fixed  : float | None = None,\n",
        "    alpha_caa_fixed   : float | None = None,\n",
        "    alpha_table       : dict | None  = None,\n",
        "    alpha_grad_guess  : tuple[float, float] = (0, 32.0),\n",
        "    alpha_caa_guess   : tuple[float, float] = (0, 32.0),\n",
        "    caa_vectors       : np.ndarray | None = None,\n",
        "    num_pairs_caa     : int = 100,\n",
        "    max_samples       : int = 100,\n",
        "    demo_label_idx    = 0,\n",
        "    num_target_labels = 2,\n",
        "    steps = 1,\n",
        "):\n",
        "    if eval_layer is None:\n",
        "        eval_layer = globals().get(\"EVAL_LAYER\", None)\n",
        "    if eval_layer is None:\n",
        "        raise ValueError(\"`eval_layer` not set and global EVAL_LAYER missing\")\n",
        "\n",
        "    all_prompts = [row[\"text\"] for row in dataset]\n",
        "    Y_all       = np.asarray([row[\"label\"] for row in dataset])\n",
        "\n",
        "    X_steer = get_hidden_cached(all_prompts, layer_idx)\n",
        "    steer_model, _ = get_or_train_layer_clf(layer_idx, X_steer, Y_all)\n",
        "\n",
        "    base_module  = getattr(act_clf, \"classifier\", act_clf)\n",
        "    base_module.eval()\n",
        "    device = next(base_module.parameters()).device\n",
        "\n",
        "    def prob_fn(texts: list[str]) -> np.ndarray:\n",
        "        acts = get_hidden_cached(texts, eval_layer)\n",
        "        with torch.no_grad():\n",
        "            logits = base_module(\n",
        "                torch.as_tensor(acts, dtype=torch.float32, device=device)\n",
        "            )\n",
        "        return torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "    act_clf_eval = base_module\n",
        "\n",
        "    if caa_vectors is None:\n",
        "        caa_vectors = compute_caa_vectors(\n",
        "            dataset, unique_labels,\n",
        "            steer_layer = layer_idx,\n",
        "            max_pairs   = num_pairs_caa,\n",
        "        )\n",
        "\n",
        "    tgt_demo = demo_label_idx if isinstance(demo_label_idx, list) else [demo_label_idx]\n",
        "    sample_prompts = prompts[:100]\n",
        "\n",
        "    def _gen_grad(a: float) -> list[str]:\n",
        "        hook = get_gradient_hook(steer_model, tgt_demo, [], a, steps=steps)\n",
        "        return batch_generate(model, tokenizer, sample_prompts,\n",
        "                              layer_idx=layer_idx, hook_fn=hook,\n",
        "                              max_new_tokens=24)\n",
        "\n",
        "    caa_vec_demo = torch.tensor(\n",
        "        caa_vectors[tgt_demo].mean(0), dtype=torch.float16, device=DEVICE\n",
        "    )\n",
        "    def _gen_caa(a: float) -> list[str]:\n",
        "        hook = get_caa_hook(caa_vec_demo, alpha=a)\n",
        "        return batch_generate(model, tokenizer, sample_prompts,\n",
        "                              layer_idx=layer_idx, hook_fn=hook,\n",
        "                              max_new_tokens=24)\n",
        "\n",
        "    _grad_ood = lambda a: is_ood(_gen_grad(a))\n",
        "    _caa_ood  = lambda a: is_ood(_gen_caa(a))\n",
        "\n",
        "    if alpha_table is not None:\n",
        "        alpha_grad = alpha_table\n",
        "        alpha_caa  = alpha_table\n",
        "    elif alpha_grad_fixed is not None and alpha_caa_fixed is not None:\n",
        "        alpha_grad, alpha_caa = alpha_grad_fixed, alpha_caa_fixed\n",
        "    else:\n",
        "      alpha_grad = calibrate_alpha_ood_only(\n",
        "          _grad_ood, min_alpha=alpha_grad_guess[0], max_alpha=alpha_grad_guess[1])\n",
        "      alpha_caa  = calibrate_alpha_ood_only(\n",
        "          _caa_ood, min_alpha=alpha_caa_guess[0], max_alpha=alpha_caa_guess[1])\n",
        "\n",
        "    if only_calibrate:\n",
        "        return None, None, None, None, None, alpha_grad, alpha_caa\n",
        "\n",
        "    df = await eval_steering_combinations(\n",
        "        prompts            = prompts[:max_samples],\n",
        "        unique_labels      = unique_labels,\n",
        "        steer_model        = steer_model,\n",
        "        caa_vectors        = caa_vectors,\n",
        "        layer_idx          = layer_idx,\n",
        "        act_clf            = act_clf_eval,\n",
        "        alpha_grad         = alpha_grad,\n",
        "        alpha_caa          = alpha_caa,\n",
        "        num_target_labels  = num_target_labels,\n",
        "        steps              = steps,\n",
        "    )\n",
        "\n",
        "    k_score   = df[\"K-Steering\"].mean()\n",
        "    caa_score = df[\"CAA\"].mean()\n",
        "\n",
        "    return (\n",
        "        df, k_score, caa_score,\n",
        "        steer_model, caa_vectors,\n",
        "        alpha_grad, alpha_caa,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2f715961-26b7-485c-8862-5020ec2da19c",
      "metadata": {
        "id": "2f715961-26b7-485c-8862-5020ec2da19c"
      },
      "outputs": [],
      "source": [
        "async def sweep_alphas_for_layers(\n",
        "    layers_to_sweep : list[int],\n",
        "    *,\n",
        "    prompts         : list[str],\n",
        "    dataset,\n",
        "    unique_labels,\n",
        "    num_target_labels: int = 2,\n",
        "    act_clf         = None,\n",
        "    eval_layer      : int | None = None,\n",
        "    alpha_grad_guess: tuple[float, float] = (0.1, 30000.0),\n",
        "    alpha_caa_guess : tuple[float, float] = (0.1, 32.0),\n",
        "    num_pairs_caa   : int = 100,\n",
        "    steps = 1,\n",
        "    **other_kwargs,\n",
        "):\n",
        "    combos = [tuple(sorted(c))\n",
        "              for c in combinations(unique_labels, num_target_labels)]\n",
        "    layer2alpha = {}\n",
        "\n",
        "    for l in tqdm(layers_to_sweep, desc=\"Layers\"):\n",
        "        caa_vecs_layer = compute_caa_vectors(\n",
        "            dataset, unique_labels,\n",
        "            steer_layer = l, max_pairs = num_pairs_caa,\n",
        "        )\n",
        "\n",
        "        combo2α = {}\n",
        "        for combo in tqdm(combos, desc=f\"Layer {l} combos\", leave=False):\n",
        "            tgt_idx = [unique_labels.index(t) for t in combo]\n",
        "\n",
        "            (_, _, _, _, _, αg, αc) = await _run_eval_on_layer(\n",
        "                l, prompts,\n",
        "                dataset        = dataset,\n",
        "                unique_labels  = unique_labels,\n",
        "                demo_label_idx = tgt_idx,\n",
        "                only_calibrate = True,\n",
        "                alpha_grad_guess = alpha_grad_guess,\n",
        "                alpha_caa_guess  = alpha_caa_guess,\n",
        "                act_clf         = act_clf,\n",
        "                eval_layer      = eval_layer,\n",
        "                caa_vectors     = caa_vecs_layer,\n",
        "                num_pairs_caa   = num_pairs_caa,\n",
        "                steps = steps,\n",
        "                **other_kwargs,\n",
        "            )\n",
        "            combo2α[combo] = (αg, αc)\n",
        "\n",
        "        layer2alpha[l] = combo2α\n",
        "        tqdm.write(\n",
        "            f\"[layer {l}] calibrated {len(combo2α)} combos \"\n",
        "            f\"(max α_grad={max(a[0] for a in combo2α.values()):.2g}, \"\n",
        "            f\"max α_caa={max(a[1] for a in combo2α.values()):.2g})\"\n",
        "        )\n",
        "\n",
        "    return layer2alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bd1fcf81-053f-45b5-9d00-93218f8ef195",
      "metadata": {
        "id": "bd1fcf81-053f-45b5-9d00-93218f8ef195"
      },
      "outputs": [],
      "source": [
        "async def evaluate_layers(\n",
        "    layer2alpha   : Dict[int, Dict[tuple, Tuple[float, float]]],\n",
        "    *,\n",
        "    prompts       : List[str],\n",
        "    dataset,\n",
        "    unique_labels,\n",
        "    num_target_labels= 2,\n",
        "    steps = 1,\n",
        "    **run_kwargs,\n",
        "):\n",
        "    frames = {}\n",
        "    for l in sorted(layer2alpha.keys()):\n",
        "        df, k_score, c_score, steer_model, caa_vecs, _, _ = await _run_eval_on_layer(\n",
        "            l, prompts,\n",
        "            dataset        = dataset,\n",
        "            unique_labels  = unique_labels,\n",
        "            alpha_table    = layer2alpha[l],\n",
        "            steps          = steps,\n",
        "            **run_kwargs,\n",
        "            num_target_labels= num_target_labels,\n",
        "        )\n",
        "        frames[l] = (df, k_score, c_score, steer_model, caa_vecs)\n",
        "\n",
        "    best_k_layer   = max(frames, key=lambda x: frames[x][1])\n",
        "    best_caa_layer = max(frames, key=lambda x: frames[x][2])\n",
        "\n",
        "    df_best = frames[best_k_layer][0][[\"Targets\", \"K-Steering\"]].copy()\n",
        "    df_best[\"CAA\"] = frames[best_caa_layer][0][\"CAA\"].values\n",
        "\n",
        "    evaluate_layers._cache = {\n",
        "        \"best_k_layer\"   : best_k_layer,\n",
        "        \"best_caa_layer\" : best_caa_layer,\n",
        "        \"layer2alpha\"    : layer2alpha,\n",
        "        \"steer_models\"   : {l: frames[l][3] for l in frames},\n",
        "        \"caa_vecs\"       : {l: frames[l][4] for l in frames},\n",
        "    }\n",
        "\n",
        "    return df_best, best_caa_layer, best_k_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f42b618-a08e-4948-81a4-bd4f56f7289c",
      "metadata": {
        "id": "4f42b618-a08e-4948-81a4-bd4f56f7289c"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4b6f59ef-47bd-43e9-9ad4-32dda72d8153",
      "metadata": {
        "id": "4b6f59ef-47bd-43e9-9ad4-32dda72d8153"
      },
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "all_prompts      = [row[\"text\"] for row in dataset]\n",
        "Y_all            = np.array([unique_labels.index(row[\"label\"]) for row in dataset], dtype=np.int64)\n",
        "\n",
        "# Train or load the activations classifier\n",
        "EVAL_LAYER = -1\n",
        "X_eval = get_hidden_cached(all_prompts, layer_idx=EVAL_LAYER)\n",
        "\n",
        "act_clf_eval, eval_acc = get_or_train_eval_clf(\n",
        "    X_eval,\n",
        "    Y_all,\n",
        "    hidden_dim = 128,\n",
        "    epochs      = 5,\n",
        "    batch_size  = 32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfac148c-d682-491b-bfa3-125f0b7f4d48",
      "metadata": {
        "id": "dfac148c-d682-491b-bfa3-125f0b7f4d48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layers:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Sweep alpha for each layer and combination\n",
        "layer2alpha = await sweep_alphas_for_layers(\n",
        "    layers_to_sweep = [10],\n",
        "    prompts         = eval_prompts,\n",
        "    dataset         = dataset,\n",
        "    unique_labels   = unique_labels,\n",
        "    num_target_labels= 2,\n",
        "    act_clf = act_clf_eval,\n",
        "    steps           = 3,\n",
        ")\n",
        "layer2alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9077c2f6-f1be-44ce-bd61-20a066550593",
      "metadata": {
        "id": "9077c2f6-f1be-44ce-bd61-20a066550593"
      },
      "outputs": [],
      "source": [
        "# Layer sweep with good alphas\n",
        "df_best, best_caa_layer, best_k_layer = await evaluate_layers(\n",
        "    layer2alpha   = layer2alpha,\n",
        "    prompts       = eval_prompts,\n",
        "    dataset       = dataset,\n",
        "    unique_labels = unique_labels,\n",
        "    act_clf       = act_clf_eval,\n",
        "    eval_layer    = EVAL_LAYER,\n",
        "    num_target_labels= 1,\n",
        "    steps=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c331135f-6392-411d-900f-b0e8c0eea67a",
      "metadata": {
        "id": "c331135f-6392-411d-900f-b0e8c0eea67a"
      },
      "outputs": [],
      "source": [
        "def add_dct_column(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    unique_labels   : Sequence[str],\n",
        "    prompts         : list[str],\n",
        "    dct_vectors     : np.ndarray,\n",
        "    tone2dct        : Mapping[str, list],\n",
        "    alpha_lookup    : Callable[[tuple], float],\n",
        "    layer_idx       : int,\n",
        "    combo_col       : str | None = None,\n",
        "    act_clf         = None,\n",
        "    base_model      = None,\n",
        "    tokenizer       = None,\n",
        ") -> pd.DataFrame:\n",
        "    if combo_col is None:\n",
        "        combo_col = df.select_dtypes(include=[\"object\", \"category\"]).columns[0]\n",
        "\n",
        "    df_out = df.copy()\n",
        "\n",
        "    def _to_tuple(cell) -> tuple[str, ...]:\n",
        "        if isinstance(cell, str):\n",
        "            try:\n",
        "                val = ast.literal_eval(cell)\n",
        "            except Exception:\n",
        "                val = [s.strip(\" '\\\"\") for s in cell.split(\",\")] if \",\" in cell else cell\n",
        "        else:\n",
        "            val = cell\n",
        "        if isinstance(val, (list, tuple)):\n",
        "            return tuple(val)\n",
        "        return (str(val),)\n",
        "\n",
        "    if act_clf is None:\n",
        "        raise ValueError(\"Need act_clf for activation path\")\n",
        "    base_module = getattr(act_clf, \"classifier\", act_clf)\n",
        "    device      = next(base_module.parameters()).device\n",
        "\n",
        "    acts_np = get_hidden_cached(prompts, layer_idx)           # (B, D)\n",
        "    acts_t  = torch.tensor(acts_np, dtype=torch.float32, device=device)\n",
        "    with torch.no_grad():\n",
        "        base_logits = base_module(acts_t).sigmoid().cpu().numpy()\n",
        "\n",
        "    deltas = []\n",
        "    for raw in df_out[combo_col]:\n",
        "        combo   = _to_tuple(raw)\n",
        "        tgt_idx = [unique_labels.index(t) for t in combo]\n",
        "\n",
        "        base_score = base_logits[:, tgt_idx].mean()\n",
        "\n",
        "        vec_ids = [vid for lbl in combo for vid in tone2dct.get(lbl, [])]\n",
        "        if not vec_ids:\n",
        "            deltas.append(0.0)\n",
        "            continue\n",
        "        vecs   = dct_vectors[vec_ids]\n",
        "        vec    = vecs.mean(0)\n",
        "\n",
        "        alpha  = alpha_lookup(combo)\n",
        "        ste_np = acts_np + alpha * vec\n",
        "\n",
        "        ste_t  = torch.tensor(ste_np, dtype=torch.float32, device=device)\n",
        "        with torch.no_grad():\n",
        "            ste_logits = base_module(ste_t).sigmoid().cpu().numpy()\n",
        "\n",
        "        ste_score = ste_logits[:, tgt_idx].mean()\n",
        "        deltas.append(ste_score - base_score)\n",
        "\n",
        "    df_out[\"DCT\"] = deltas\n",
        "    return df_out\n",
        "\n",
        "async def sweep_alphas_for_dct(\n",
        "    *,\n",
        "    prompts            : List[str],\n",
        "    unique_labels      : List[str],\n",
        "    tone2dct           : Mapping[str, List[int]],\n",
        "    dct_vectors        : np.ndarray,\n",
        "    layer_idx          : int,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    alpha_dct_guess    : Tuple[float, float] = (1.0, 32.0),\n",
        "    tol                : float               = 0.05,\n",
        "    max_iters          : int                 = 10,\n",
        ") -> dict[Tuple[str, ...], float]:\n",
        "    combo2alpha = {}\n",
        "    for combo in combinations(unique_labels, 2):\n",
        "        vec_ids = [vid for lbl in combo for vid in tone2dct.get(lbl, [])]\n",
        "        if not vec_ids:\n",
        "            combo2alpha[combo] = 0.0\n",
        "            continue\n",
        "\n",
        "        vec = dct_vectors[vec_ids].mean(axis=0)\n",
        "\n",
        "        def _ood_check(alpha: float) -> bool:\n",
        "            hook = get_dct_hook(vec, alpha=alpha)\n",
        "            gens = batch_generate(\n",
        "                model, tokenizer, prompts,\n",
        "                layer_idx      = layer_idx,\n",
        "                hook_fn        = hook,\n",
        "                max_new_tokens = 24,\n",
        "            )\n",
        "            return is_ood(gens)\n",
        "\n",
        "        best_alpha = calibrate_alpha_ood_only(\n",
        "            _ood_check,\n",
        "            min_alpha = alpha_dct_guess[0],\n",
        "            max_alpha = alpha_dct_guess[1],\n",
        "            tol       = tol,\n",
        "            max_iters = max_iters,\n",
        "        )\n",
        "\n",
        "        combo2alpha[combo] = best_alpha\n",
        "\n",
        "    return combo2alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a9ea17-86cc-4565-8505-0a38fca7774f",
      "metadata": {
        "id": "a8a9ea17-86cc-4565-8505-0a38fca7774f"
      },
      "outputs": [],
      "source": [
        "# Compute DCT vectors\n",
        "dct_vectors = compute_dct_vectors_for_layers(source_layer=best_caa_layer, target_layer=best_caa_layer+5)\n",
        "\n",
        "# Map DCT vectors to labels\n",
        "tone2dct = await _map_dct_vectors(\n",
        "    dct_vectors     = dct_vectors,\n",
        "    prompts         = eval_prompts,\n",
        "    act_clf         = act_clf_eval,\n",
        "    layer_idx       = best_caa_layer,\n",
        "    base_act        = None,\n",
        "    unique_labels   = unique_labels,\n",
        "    tone2idx        = {t: i for i, t in enumerate(unique_labels)},\n",
        ")\n",
        "\n",
        "# Sweep alpha\n",
        "alpha2dct = await sweep_alphas_for_dct(\n",
        "    prompts            = eval_prompts,\n",
        "    unique_labels      = unique_labels,\n",
        "    tone2dct           = tone2dct,\n",
        "    dct_vectors        = dct_vectors,\n",
        "    layer_idx          = best_caa_layer,\n",
        "    model              = model,\n",
        "    tokenizer          = tokenizer,\n",
        "    alpha_dct_guess    = (0.1, 1024.0),\n",
        "    max_iters          = 12,\n",
        ")\n",
        "alpha_lookup = lambda combo: alpha2dct.get(combo, 0.0)\n",
        "\n",
        "# Write the DCT results\n",
        "df_with_dct = add_dct_column(\n",
        "    df               = df_best,\n",
        "    unique_labels    = unique_labels,\n",
        "    prompts          = eval_prompts,\n",
        "    dct_vectors      = dct_vectors,\n",
        "    tone2dct         = tone2dct,\n",
        "    alpha_lookup     = alpha_lookup,\n",
        "    layer_idx        = best_caa_layer,\n",
        "    act_clf          = act_clf_eval,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a8d306-f179-4aed-8bfa-2f0643dee8e9",
      "metadata": {
        "id": "15a8d306-f179-4aed-8bfa-2f0643dee8e9"
      },
      "outputs": [],
      "source": [
        "records = []\n",
        "for cell in df_with_dct['Targets']:\n",
        "    if isinstance(cell, str):\n",
        "        try:\n",
        "            combo = tuple(ast.literal_eval(cell))\n",
        "        except Exception:\n",
        "            combo = tuple(s.strip(\" '\\\"\") for s in cell.split(\",\") if s.strip())\n",
        "    else:\n",
        "        combo = tuple(cell)\n",
        "\n",
        "    α_grad = layer2alpha[best_k_layer].get(combo, (0.0, 0.0))[0]\n",
        "    α_caa  = layer2alpha[best_caa_layer].get(combo, (0.0, 0.0))[1]\n",
        "    α_dct  = alpha2dct.get(combo, 0.0)\n",
        "\n",
        "    records.append({\n",
        "        'Targets': combo,\n",
        "        'alpha_grad': α_grad,\n",
        "        'alpha_caa' : α_caa,\n",
        "        'alpha_dct' : α_dct,\n",
        "    })\n",
        "\n",
        "alphas_df = pd.DataFrame(records)\n",
        "\n",
        "df_with_dct.to_csv('qwen3-1.7b-3-tone-activations-classifier-results.csv', index=False)\n",
        "alphas_df.to_csv('qwen3-1.7b-3-tone-activations-classifier-alphas.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MLAwRB-g5xZg",
      "metadata": {
        "id": "MLAwRB-g5xZg"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jiWVuufUdFUv",
      "metadata": {
        "id": "jiWVuufUdFUv"
      },
      "outputs": [],
      "source": [
        "def plot_evaluation_bar(\n",
        "    df: pd.DataFrame,\n",
        "    combo_col: str | None = None,\n",
        "    title: str            = \"Steering Evaluation\",\n",
        "    x_title: str          = \"Label Combination\",\n",
        "    y_title: str          = \"Average Probability\",\n",
        "    output_path: str | Path | None = None,\n",
        "    width: int            = 900,\n",
        "    height: int           = 500,\n",
        "    show: bool            = True,\n",
        "):\n",
        "    if combo_col is None:\n",
        "        combo_col = df.select_dtypes(include=[\"object\", \"category\"]).columns[0]\n",
        "\n",
        "    method_cols = [c for c in df.columns if c != combo_col]\n",
        "\n",
        "    palette = ['#FF563F', '#F5C0B8',  '#55C89F', '#363432', '#F9DA81']\n",
        "    if len(method_cols) > len(palette):\n",
        "        repeats  = -(-len(method_cols) // len(palette))\n",
        "        palette *= repeats\n",
        "    palette = palette[:len(method_cols)]\n",
        "\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        x                = combo_col,\n",
        "        y                = method_cols,\n",
        "        color_discrete_sequence = palette,\n",
        "        template         = \"plotly_white\",\n",
        "        width            = width,\n",
        "        height           = height,\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            \"text\"  : title,\n",
        "            \"font\"  : {\"size\": 16, \"color\": \"#0c0c0c\", \"family\": \"Space Grotesk\"},\n",
        "            \"x\"     : 0.5, \"y\": 0.96, \"xanchor\": \"center\", \"yanchor\": \"top\",\n",
        "        },\n",
        "        font={\n",
        "            \"family\": \"Space Grotesk, Work Sans, sans-serif\",\n",
        "            \"color\" : \"#0c0c0c\",\n",
        "        },\n",
        "        barmode   = \"group\",\n",
        "        margin    = {\"l\": 40, \"r\": 40, \"t\": 100, \"b\": 80},\n",
        "        legend    = {\n",
        "            \"title\": {\"text\": \"\"},\n",
        "            \"orientation\": \"h\",\n",
        "            \"y\": 1.0, \"x\": 0.5,\n",
        "            \"xanchor\": \"center\", \"yanchor\": \"bottom\",\n",
        "            \"font\": {\"size\": 10, \"color\": \"#928e8b\"},\n",
        "        },\n",
        "        xaxis     = {\n",
        "            \"title\": {\"text\": x_title},\n",
        "            \"gridcolor\": \"#f5f5f5\",\n",
        "            \"linecolor\": \"#e5dfdf\",\n",
        "            \"linewidth\": 1.5,\n",
        "            \"tickfont\": {\"color\": \"#928E8B\"},\n",
        "            \"ticksuffix\": \"   \",\n",
        "        },\n",
        "        yaxis     = {\n",
        "            \"title\": {\"text\": y_title},\n",
        "            \"gridcolor\": \"#f5f5f5\",\n",
        "            \"linecolor\": \"#e5dfdf\",\n",
        "            \"linewidth\": 1.5,\n",
        "            \"tickfont\": {\"color\": \"#928E8B\"},\n",
        "            \"ticksuffix\": \"   \",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    fig.update_traces(\n",
        "        hoverlabel = {\n",
        "            \"bgcolor\": \"#0c0c0c\",\n",
        "            \"font_color\": \"#ffffff\",\n",
        "            \"font_family\": \"Work Sans\",\n",
        "        },\n",
        "        hovertemplate = \"&nbsp;%{x}<br>&nbsp;%{y:.3f}<extra></extra>\",\n",
        "    )\n",
        "\n",
        "    if output_path is not None:\n",
        "        output_path = Path(output_path)\n",
        "        try:\n",
        "            fig.write_image(str(output_path))\n",
        "            print(f\"Figure written to: {output_path.resolve()}\")\n",
        "        except ValueError as e:\n",
        "            if \"kaleido\" in str(e).lower():\n",
        "                raise RuntimeError(\n",
        "                    \"Static image export requires Kaleido. \"\n",
        "                    \"Install it with:\\n    pip install -U kaleido\"\n",
        "                ) from e\n",
        "            raise\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3zOEzlq9fb_A",
      "metadata": {
        "id": "3zOEzlq9fb_A"
      },
      "outputs": [],
      "source": [
        "plot_evaluation_bar(\n",
        "    df_with_dct,\n",
        "    title=\"Steering Performance VS Unsteered Models (Tones, Last Layer Activations Classifier)\",\n",
        "    output_path=\"df_gen.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FnGB2XiS7XS_",
      "metadata": {
        "id": "FnGB2XiS7XS_"
      },
      "source": [
        "# Manual Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xh9POYA-7fgw",
      "metadata": {
        "id": "Xh9POYA-7fgw"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def sample_steered_responses(\n",
        "    prompts: list[str],\n",
        "    target_tones: list[str] | str,\n",
        "    *,\n",
        "    steer_model_k = None,\n",
        "    layer_k       = None,\n",
        "    alpha_grad    = None,\n",
        "\n",
        "    caa_vectors   = None,\n",
        "    layer_caa     = None,\n",
        "    alpha_caa     = None,\n",
        "\n",
        "    max_new_tokens: int = 32,\n",
        "    batch_size    : int = 500,\n",
        "):\n",
        "    cache = getattr(evaluate_layers, \"_cache\", None)\n",
        "    if cache is None:\n",
        "        raise ValueError(\n",
        "            \"evaluate_layers._cache not found. Run evaluate_layers() first \"\n",
        "            \"or pass steer_model_k / caa_vectors / alphas explicitly.\"\n",
        "        )\n",
        "\n",
        "    if layer_k   is None: layer_k   = cache[\"best_k_layer\"]\n",
        "    if layer_caa is None: layer_caa = cache[\"best_caa_layer\"]\n",
        "\n",
        "    def _lookup_alpha(layer: int, is_caa=False):\n",
        "        tbl = cache[\"layer2alpha\"][layer]\n",
        "        combo_key = tuple(sorted(\n",
        "            target_tones if isinstance(target_tones, list)\n",
        "            else [target_tones]\n",
        "        ))\n",
        "        if combo_key not in tbl:\n",
        "            raise KeyError(f\"Combo {combo_key} not found in layer2alpha[{layer}].\")\n",
        "        αg, αc = tbl[combo_key]\n",
        "        return αc if is_caa else αg\n",
        "\n",
        "    if alpha_grad is None:\n",
        "        alpha_grad = _lookup_alpha(layer_k, is_caa=False)\n",
        "    if alpha_caa is None:\n",
        "        alpha_caa  = _lookup_alpha(layer_caa, is_caa=True)\n",
        "\n",
        "    if steer_model_k is None:\n",
        "        steer_model_k = cache[\"steer_models\"][layer_k]\n",
        "    if caa_vectors is None:\n",
        "        caa_vectors   = cache[\"caa_vecs\"][layer_caa]\n",
        "\n",
        "    tone2idx = {t: i for i, t in enumerate(unique_labels)}\n",
        "    tgt_list = (target_tones\n",
        "                if isinstance(target_tones, list)\n",
        "                else [target_tones])\n",
        "    tgt_idx  = [tone2idx[t] for t in tgt_list]\n",
        "\n",
        "    alpha_grad = 10000\n",
        "\n",
        "    grad_hook = get_gradient_hook(\n",
        "        steer_model_k, target_labels=tgt_idx,\n",
        "        avoid_labels=[], alpha=alpha_grad\n",
        "    )\n",
        "\n",
        "    caa_vec  = caa_vectors[tgt_idx].mean(axis=0)\n",
        "    caa_hook = get_caa_hook(caa_vec, alpha=alpha_caa)\n",
        "\n",
        "    unsteered = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx=layer_caa, hook_fn=None,\n",
        "        max_new_tokens=max_new_tokens, batch_size=batch_size,\n",
        "    )\n",
        "    ksteer    = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx=layer_k, hook_fn=grad_hook,\n",
        "        max_new_tokens=max_new_tokens, batch_size=batch_size,\n",
        "    )\n",
        "    caa_out   = batch_generate(\n",
        "        model, tokenizer, prompts,\n",
        "        layer_idx=layer_caa, hook_fn=caa_hook,\n",
        "        max_new_tokens=max_new_tokens, batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    def _strip_prompt(gen: str, prompt: str) -> str:\n",
        "        return gen[len(prompt):].lstrip() if gen.startswith(prompt) else gen\n",
        "\n",
        "    rows = []\n",
        "    for prompt, base, ktxt, ctxt in zip(prompts, unsteered, ksteer, caa_out):\n",
        "        rows.append({\n",
        "            \"prompt\"    : prompt,\n",
        "            \"unsteered\" : _strip_prompt(base, prompt),\n",
        "            \"k_steering\": _strip_prompt(ktxt, prompt),\n",
        "            \"caa\"       : _strip_prompt(ctxt, prompt),\n",
        "        })\n",
        "\n",
        "    for r in rows:\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(f\"PROMPT:\\n{r['prompt']}\\n\")\n",
        "        print(\"- Unsteered -------------------------------------------------\\n\"\n",
        "              + r[\"unsteered\"] + \"\\n\")\n",
        "        print(f\"- K-steering  (layer {layer_k}, α_grad = {alpha_grad:.3g})\\n\"\n",
        "              + r[\"k_steering\"] + \"\\n\")\n",
        "        print(f\"- CAA         (layer {layer_caa}, α_caa  = {alpha_caa:.3g})\\n\"\n",
        "              + r[\"caa\"] + \"\\n\")\n",
        "\n",
        "    return rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cvc_1iUo7ibI",
      "metadata": {
        "id": "cvc_1iUo7ibI"
      },
      "outputs": [],
      "source": [
        "sample_steered_responses(\n",
        "    prompts      = eval_prompts[:100],\n",
        "    target_tones = [\"cautious\", \"empathetic\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eLrEY9VP_HsS",
      "metadata": {
        "id": "eLrEY9VP_HsS"
      },
      "outputs": [],
      "source": [
        "df_best"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
